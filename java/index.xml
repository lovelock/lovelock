<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Javas on Me &amp; Web</title>
    <link>http://lovelock.coding.me/java/index.xml</link>
    <description>Recent content in Javas on Me &amp; Web</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) 2013-2016 Frost Wong. All rights reserved.</copyright>
    <lastBuildDate>Tue, 11 Oct 2016 16:41:18 +0800</lastBuildDate>
    <atom:link href="/java/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>一个真实Storm应用源码解析</title>
      <link>http://lovelock.coding.me/java/storm-demo-presentation/</link>
      <pubDate>Tue, 11 Oct 2016 16:41:18 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/storm-demo-presentation/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;这里是Storm分享的内容。我自己也是初学者，这里抛砖引玉，希望大家多多指教。为简单起见，本应用用的是Java实现，没有用到Storm的多语言支持和更高层面的Trident Topology。源码详见&lt;a href=&#34;https://github.com/lovelock/storm-demo&#34;&gt;storm-demo&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;理论&#34;&gt;理论&lt;/h2&gt;

&lt;h3 id=&#34;概述&#34;&gt;概述&lt;/h3&gt;

&lt;p&gt;Apache Storm是一个自由并且开源的&lt;strong&gt;分布式实时&lt;/strong&gt;计算系统.它使得像Hadoop做批处理一样做&lt;strong&gt;实时的&lt;/strong&gt;、&lt;strong&gt;无限量&lt;/strong&gt;的&lt;strong&gt;流数据&lt;/strong&gt;处理变得简单可靠.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://storm.apache.org/images/storm-flow.png&#34; alt=&#34;Apache Storm工作流程&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;概念解释&#34;&gt;概念解释&lt;/h3&gt;

&lt;h4 id=&#34;工作原理&#34;&gt;工作原理&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://www.tutorialspoint.com/apache_storm/images/zookeeper_framework.jpg&#34; alt=&#34;Apache Storm组件间关系&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Nimbus&lt;br /&gt;
 Nimbus是Storm集群的&lt;strong&gt;主节点master node&lt;/strong&gt;。Storm集群中除Nimbus节点之外的所有节点叫做&lt;strong&gt;工作节点worker nodes&lt;/strong&gt;。&lt;br /&gt;
 Nimbus负责三项工作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;向worker nodes分发数据&lt;/li&gt;
&lt;li&gt;向worker nodes分配tasks&lt;/li&gt;
&lt;li&gt;监控失败&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Supervisor&lt;br /&gt;
 接受Nimbus的指令的节点叫做Supervisors（监工），它有&lt;strong&gt;多个worker process&lt;/strong&gt;，并控制worker process完成Nimbus分配的tasks&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Worker Process&lt;br /&gt;
 Worker process执行指定Topology的tasks。&lt;strong&gt;worker process自己并不实际执行tasks，而是创建executors并由executors执行指定的task。&lt;/strong&gt;一个worker process可以由多个executor。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Executor&lt;br /&gt;
 Executor是由worker process创建的线程。一个executor执行一个或多个tasks，但只为&lt;strong&gt;一个指定的Spout或者Bolt工作&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Task&lt;br /&gt;
 Task是实际的数据处理工作，所以它可能是一个Spout或者Bolt。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;配套服务&#34;&gt;配套服务&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;ZooKeeper&lt;br /&gt;
&lt;a href=&#34;http://zookeeper.apache.org/&#34;&gt;ZooKeeper&lt;/a&gt;是一个分布式的配置分发服务。Storm和Kafka都是无状态的，它们的工作需要外部服务为其维持状态，如Storm从Kafka中取数据时需要的partition编号和offset偏移量等诸如此类的信息。ZooKeeper会综合分析Spout和Bolt发送来的ack或者fail请求来决定是否更新offset。如下图所示&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww3.sinaimg.cn/large/65e4f1e6jw1f8wd8tm94ij21kw097q5h.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kafka&lt;br /&gt;
&lt;a href=&#34;http://kafka.apache.org/&#34;&gt;Kafka&lt;/a&gt;是一个分布式的消息系统。支持&lt;strong&gt;点对点&lt;/strong&gt;和&lt;strong&gt;发布-订阅&lt;/strong&gt;两种消息模式。在和Storm配合中，充当&lt;strong&gt;数据来源&lt;/strong&gt;的角色。用&lt;a href=&#34;https://github.com/apache/storm/tree/master/external/storm-kafka&#34;&gt;KafkaSpout&lt;/a&gt;和Storm进行组合。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;本文只关注Storm，有关ZooKeeper和Kafka的介绍，可以访问&lt;a href=&#34;http://apache.org/&#34;&gt;官网&lt;/a&gt;、&lt;a href=&#34;http://www.tutorialspoint.com/&#34;&gt;TutorialsPoint&lt;/a&gt;或本博客的其他相关文章。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;拓扑作业&#34;&gt;拓扑作业&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Tuple&lt;br /&gt;
 Tuple是Topology中数据流的传输格式。它是&lt;strong&gt;不可变的键值对组&lt;/strong&gt;。既然是键值对，就需要设置键和值，典型的设置方式如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; // 设置键
 outputFieldsDeclarer.declare(new Fields(&amp;quot;timestamp&amp;quot;, &amp;quot;fieldvalues&amp;quot;));
 // 设置值
 collector.emit(tuple, new Values(timestamp, stringBuilder.toString()));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就会得到一个形如&lt;code&gt;(&amp;quot;timestamp&amp;quot;: timestamp, &amp;quot;fieldvalues&amp;quot;: xxxx&amp;quot;)&lt;/code&gt;这样的Tuple。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Spout&lt;br /&gt;
 Spout是Topology的数据来源，输出的数据以Tuple的形式传入下一个Bolt。具体到本例中，KafkaSpout会把它接收到的数据以类似&lt;code&gt;(0: message)&lt;/code&gt;这样的形式发射(emit)出来。所以，在KafkaSpout下游的Bolt需要这样获取整条数据(其实这里是可配置的)：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; String message = tuple.getString(0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对KafkaSpout而言，它也实现了多个方法，但我们这里只需要了解两个&lt;code&gt;ack&lt;/code&gt;和&lt;code&gt;fail&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww3.sinaimg.cn/large/65e4f1e6jw1f8wdqv4tuqj218y0ji41l.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这两个是回调方法，分别在acker向其发送ack或fail请求时被触发，一般而言，ack方法由于通知Kafka发送下一条数据，fail方法用于通知Kafka重发上一条数据。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Storm中有个特殊的task名叫acker，它们负责跟踪Spout发出的每一个Tuple的Tuple树（因为一个Tuple通过Spout发出了，经过每一个Bolt处理后，会生成一个新的Tuple发送出去）。当acker（框架自启动的task）发现一个Tuple树已经处理完成了，它会发送一个消息给产生这个Tuple的那个task。&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bolt&lt;br /&gt;
 Bolt是真正写处理逻辑的地方，比如在本例中，我们要做以下几件事：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;把message中的每个字段提取出来，&lt;/li&gt;
&lt;li&gt;从message的domain字段中过滤出以&lt;code&gt;.api.ksyun.com&lt;/code&gt;结尾的，其他的舍弃&lt;/li&gt;
&lt;li&gt;把domain字段的值以&lt;code&gt;.&lt;/code&gt;分割，取出index为0的部分，也就是第一段作为service字段&lt;/li&gt;
&lt;li&gt;把service最终输出Tuple的一个field写入输出结果&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一般情况下，要实现一个Bolt有几种方式&lt;/p&gt;

&lt;p&gt;​&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;实现&lt;code&gt;IRichBolt&lt;/code&gt;接口&lt;br /&gt;
  因为这个比较低级，要实现的方法有很多，而其中多数的方法不需要做特殊处理，所以一般会用第二种方式&lt;/li&gt;

&lt;li&gt;&lt;p&gt;集成&lt;code&gt;BaseRichBolt&lt;/code&gt;类&lt;br /&gt;
  这个基类实现了&lt;code&gt;IRichBolt&lt;/code&gt;中定义的几个不常用的方法，让我们只需要关注重点的几个方法即可。在这种方式中，我们需要自己实现三个方法：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;public void prepare(Map map, TopologyContext topologyContext, OutputCollector outputCollector)&lt;/code&gt;&lt;br /&gt;
  这个方法&lt;strong&gt;类似构造函数&lt;/strong&gt;，用来做一些准备工作，通常用于&lt;strong&gt;把上游传来的collector赋值给成员变量&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;public void execute(Tuple tuple)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这是最核心的方法。它负责：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;从上游传来的Tuple中读取感兴趣的字段&lt;/li&gt;
&lt;li&gt;把这些字段做一些处理后产生一组新的字段&lt;/li&gt;
&lt;li&gt;把这些值通过&lt;code&gt;OutputCollector::emit(new Values())&lt;/code&gt;方法发射出去&lt;/li&gt;
&lt;li&gt;向上游发送&lt;code&gt;OutputCollector::ack(Tuple tuple)&lt;/code&gt;或&lt;code&gt;OutputCollector::fail(Tuple tuple)&lt;/code&gt;，以告知上游本次Tuple处理是否成功。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;前面已经说过，Tuple是数据交流的格式，这个方法就是用来定义发送到下游的Tuple的字段名的。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Topology&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://storm.apache.org/releases/0.10.0/images/topology.png&#34; alt=&#34;一个典型的Topology&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上面这张图中有4个Topology，说明了几个问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一个Spout就是一个Topology的入口，从Spout分出几条线就有几个Topology&lt;/li&gt;
&lt;li&gt;一个Topology由一个Spout和若干个Bolt组成&lt;/li&gt;
&lt;li&gt;Topology之间可以共享Spout或者Bolt&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;创建一个Topology的典型过程：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    TopologyBuilder topologyBuilder = new TopologyBuilder();
    topologyBuilder.setSpout(KAFKA_SPOUT_ID, kafkaSpout, 10);
    topologyBuilder.setBolt(CROP_BOLT_ID, new CropBolt(), 10).shuffleGrouping(KAFKA_SPOUT_ID);
    topologyBuilder.setBolt(SPLIT_FIELDS_BOLT_ID, new SplitFieldsBolt(), 10).shuffleGrouping(CROP_BOLT_ID);
    topologyBuilder.setBolt(STORM_HDFS_BOLT_ID, hdfsBolt, 10).fieldsGrouping(SPLIT_FIELDS_BOLT_ID, new Fields(&amp;quot;timestamp&amp;quot;, &amp;quot;fieldvalues&amp;quot;));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的代码可以看到，&lt;code&gt;TopologyBuilder&lt;/code&gt;类通过&lt;code&gt;setSpout()&lt;/code&gt;和&lt;code&gt;setBolt()&lt;/code&gt;两个方法生动的反映了上图的工作流程。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;源码分析&#34;&gt;源码分析&lt;/h2&gt;

&lt;h3 id=&#34;cropbolt-java&#34;&gt;&lt;code&gt;CropBolt.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;主要关注&lt;code&gt;execute&lt;/code&gt;方法，它首先从上游发射来的Tuple中取出第一个字段，也就是整条消息作为一个字符串。根据对字符串的分析，我们知道该字符串是以&lt;code&gt;\t\t&lt;/code&gt;作为字段间分隔符，以&lt;code&gt;:&lt;/code&gt;作为键值分隔符的字符串，所以可以写一个方法来用这种规则解析出消息中的所有字段，并把它放在一个HashMap里。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    private HashMap makeMapOfMessage(String message) {
    String[] fields = message.split(ServerConfig.getFieldSeparator());
    HashMap&amp;lt;String, String&amp;gt; map = new HashMap&amp;lt;&amp;gt;();

    try {
        for (String field : fields) {
            String[] pair = field.split(ServerConfig.getPairSeparator(), 2);
            map.put(pair[0], pair[1]);
        }
    } catch (ArrayIndexOutOfBoundsException e) {
        LOG.warn(&amp;quot;makeMapOfMessage failed {}&amp;quot;, message);
        e.printStackTrace();
    }

    return map;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中&lt;code&gt;ServerConfig&lt;/code&gt;是一个工具类，它提供了简单的API，把处理逻辑和配置信息分离。在本例中我用的分隔符和实际项目并不一样，这个差别只需要在相应的properties配置文件中做修改即可。还需要注意异常处理，这个方法的返回值有可能是null，在调用该方法的地方需要做相应的判断。&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;execute&lt;/code&gt;方法中，从上述方法的返回值取出关心的字段，并按需求解析出需要的&lt;code&gt;service&lt;/code&gt;字段，并通过&lt;code&gt;collector.emit&lt;/code&gt;发送给下游的Bolt。&lt;/p&gt;

&lt;p&gt;这个方法中有三点需要注意：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;没有在&lt;code&gt;try&lt;/code&gt;子句中调用&lt;code&gt;ack&lt;/code&gt;方法&lt;/li&gt;
&lt;li&gt;没有在&lt;code&gt;catch&lt;/code&gt;子句中调用&lt;code&gt;fail&lt;/code&gt;方法&lt;/li&gt;
&lt;li&gt;在&lt;code&gt;finally&lt;/code&gt;子句中调用了&lt;code&gt;ack&lt;/code&gt;方法&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因为我们catch住的这种情况，是只有在输入的数据不满足我们约定要求的情况下才会发生的，比如某些必要的字段不存在等，而这种情况在当前的Topology中是不需要处理的，并且也不需要重试，因此，不需要调用&lt;code&gt;fail&lt;/code&gt;。同时，不管数据是否符合要求，我们都是需要通知Spout&lt;strong&gt;这里的处理已经完成&lt;/strong&gt;这个信息的，所以在&lt;code&gt;finally&lt;/code&gt;中调用&lt;code&gt;ack&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;splitfieldsbolt-java&#34;&gt;&lt;code&gt;SplitFieldsBolt.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;这步的功能很简单，就是把前面传过来的所有字段用一个特定的分隔符连接起来，变成一行数据。只有一个特殊，也就是&lt;code&gt;service&lt;/code&gt;字段，它不是直接取出来的，而是前面的Bolt通过一些处理得到的，所以这是&lt;code&gt;stringBuilder&lt;/code&gt;需要处理的一种特殊情况。&lt;/p&gt;

&lt;p&gt;最后把『时间戳』和『各个字段的值』发射给下游的&lt;code&gt;HdfsBolt&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;hdfsbolt&#34;&gt;&lt;code&gt;HdfsBolt&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;HdfsBolt&lt;/code&gt;是Storm到HDFS的一个中转层，配置一些规则，把Storm输出的数据写入HDFS。其中比较重要的配置有：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;DelimitedRecordFormat&lt;/code&gt; 要写入的字段 在本例中，『时间戳』只是用来划分目录的，所以不需要写入HDFS中&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CountSyncPolicy&lt;/code&gt; 指定当内存中超过多少条数据时cache到磁盘中&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FileSizeRotationPolicy&lt;/code&gt; 指定cache的文件超过多大时将文件写入文件系统，如果该值设置的较大，而数据流量又不太大的情况下，文件通常不会达到设置的值，因为当等待写入的文件未达到限制大小而先达到超时时间时，也会创建一个新的文件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DefaultFileNameFormat&lt;/code&gt; 指定文件写入HDFS中的根目录和文件后缀&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Partitioner&lt;/code&gt; 指定分块规则，在本例中，我们根据日志中&lt;code&gt;time_local&lt;/code&gt;字段划分相应的消息应该写入的HDFS目录，比如&lt;code&gt;31/Aug/2016:13:08:12 +0800&lt;/code&gt;，相应的记录就会写入&lt;code&gt;root/20160831/13&lt;/code&gt;目录中。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FsURL&lt;/code&gt; 当然需要指定正确的&lt;code&gt;HDFS&lt;/code&gt;服务。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;其实我们的KMR对应的Storm 0.10.0是不支持HDFS 的partition的，这里我是把Storm最新版的2.0.0-SNAPSHOT中相应的代码移植过来用的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;logstatisticstopology-java&#34;&gt;&lt;code&gt;LogStatisticsTopology.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;前面讲过，这是拓扑作业的入口，这里指定了一条消息要通过的路径。需要注意的有以下几点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;setSpout&lt;/code&gt;和&lt;code&gt;setBolt&lt;/code&gt;方法中的parallelism_hint(并行度建议)，前面说了，Spout和Bolt在Storm中是以executor的形式存在的，而这个值就是指定executor的数量。但又没有那么绝对，比如在KafkaSpout中，如果指定的Topic在Kafka中有10个partition，但这里的KafkaSpout指定了15个并行度，实际还是只有10个executor有意义，因为剩余的5个在前面10个都正常工作的情况下是分配不到任何数据的，由于ZooKeeper做了中间人，它是知道每个Topic有多少个partition的，所以这里设置多于partition数量的并行度也是不起作用的。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;grouping类型 Storm目前支持4种分组形式。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;随机分组 等量tuples随机分发给执行bolt的所有workers&lt;/li&gt;
&lt;li&gt;字段分组 把指定字段值相同的分配给同一个task,在wordCount应用中比较重要&lt;/li&gt;
&lt;li&gt;广播分组 给每个executor发送一个这个tuple的副本&lt;/li&gt;
&lt;li&gt;全局分组 把所有数据分发给bolt的executor中id最小的&lt;strong&gt;一个&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;无分组   目前基本等同于随机分组，会把tuple交给和它上游同一个线程内的下游bolt，以减少数据传递的开销&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;根据我们的需求，其实是不需要太关心分组的事情。&lt;/p&gt;

&lt;p&gt;关于优化，有几个方面可以考虑：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;考虑到后面需要用Hive分析数据，如果产生很多小的文件，就会产生过多的Map过程，影响性能，可以考虑同一小时的文件交给同一个executor来写，因为每个executor会打开一个hdfs文件，但这样可能会导致并发数过少&lt;/li&gt;
&lt;li&gt;既然这样，可以减少executor的数量，比如现在是10个，可以改成5个，在不触发FileSizeRotationPolicy的情况下，把生成的文件数量减少了一半，也就把Hive查询时Map过程的数量减少了一半&lt;/li&gt;
&lt;li&gt;分析需求，如果没有按照小时分组的需求，可以直接删除这个级别，直接用天作为区分，这样，在不触发FileSizeRotationPolicy的情况下产生的文件数量会变成1/24,相应的Hive查询中Map的过程也会变成1/24.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;本文主要介绍了Storm的工作流程，以及其与Kafka和HDFS的配合来进行日志分析的工作流程，并简单介绍了一些需要注意的点。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>在本地单机部署Hadoop/Storm运行环境</title>
      <link>http://lovelock.coding.me/java/deploy-pseudo-distributed-mode-hadoop/</link>
      <pubDate>Mon, 10 Oct 2016 17:53:14 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/deploy-pseudo-distributed-mode-hadoop/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;由于要在小组内做一个关于Storm的分享，涉及到我负责开发的大数据项目，本着开放的原则，把我做的准备工作记录下来，提前发给可能参会的同事。&lt;br /&gt;
要演示的项目目前为止用到了Apache的多个项目，包括Kafka, Storm, Hadoop(HDFS, Hive), ZooKeeper等，项目刚刚起步，很多基础设施还不完善，比如现在是在本地开发完成之后直接部署到线上环境的，这次演示可不能直接在线上环境做了，故而在本地的台式机上部署了一下&lt;strong&gt;伪集群&lt;/strong&gt;，用来作为演示和以后开发测试用的环境。&lt;/p&gt;

&lt;h2 id=&#34;准备工作&#34;&gt;准备工作&lt;/h2&gt;

&lt;p&gt;说明：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;以下工作全部基于Ubuntu 16.04。用其他的发行版或版本理论上应该都是可行的，可能有些命令需要微调。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;所有需要执行的命令前面都有一个&lt;code&gt;$&lt;/code&gt;，表示的是Bash的命令提示符。&lt;/li&gt;
&lt;li&gt;下载安装包时我使用了速度相对较快的国内镜像，如果你对此有任何异议，可以自行去中心镜像站点下载。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;默认情况下文中提到的所有如StormUI等控制后台访问的路径都是localhost，如果你需要从Linux主机外部访问，需要iptables放行相应的端口。在本文中，用的Web端口有三个，具体如下表：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;服务描述&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;端口号&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Storm UI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8080&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hadoop UI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50070&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hadoop Applications&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8088&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;以Ubuntu为例，需要执行以下命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo ufw allow 8080/tcp
$ sudo ufw allow 50070/tcp
$ sudo ufw allow 8088/tcp
$ sudo ufw reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CentOS/RHEL 7.0以下可能需要直接操作iptables，7.0以上可以使用&lt;code&gt;firewall-cmd&lt;/code&gt;进行类似的操作。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-创建独立的用户并赋予合适的权限&#34;&gt;1. 创建独立的用户并赋予合适的权限&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ sudo useradd hadoop
$ sudo passwd hadoop
$ sudo chsh hadoop
$ sudo mkdir /home/hadoop
$ sudo chown -R hadoop:hadoop /opt/apache
$ sudo chown -R hadoop:hadoop /home/hadoop
$ su - hadoop
$ ssh-keygen
$ cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys
$ chmod 0600 ~/.ssh/authorized_keys
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;FAQ：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;为什么需要chsh并且手动为用户创建家目录？&lt;br /&gt;
不知道为什么在 Ubuntu 环境中执行&lt;code&gt;useradd&lt;/code&gt;命令之后并不会给新建的用户创建家目录和设置shell，可能是为了安全吧，要稍微麻烦一些。&lt;/li&gt;
&lt;li&gt;为什么不给新用户赋予root权限？&lt;br /&gt;
这里是测试环境倒还好，如果你需要搭建生产环境，记住千万不要给hadoop用户赋予root权限，它需要哪些目录的权限就单独赋予即可，它需要运行的端口都是1024以上的，都不需要root权限。如果需要，执行&lt;code&gt;sudo gpasswd -a hadoop sudo&lt;/code&gt;即可。&lt;/li&gt;
&lt;li&gt;为什么要做一个密钥认证？&lt;br /&gt;
这是因为在后续的步骤中会有&lt;strong&gt;从本地用户登录本地用户&lt;/strong&gt;的需求，也就是执行了&lt;code&gt;ssh hadoop@localhost&lt;/code&gt;这个命令，如果不做密钥信任，会需要多次输入密码。&lt;/li&gt;
&lt;li&gt;为什么会有一个&lt;code&gt;/opt/apache&lt;/code&gt;目录？&lt;br /&gt;
往下看。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-下载所需安装包&#34;&gt;1. 下载所需安装包&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;下载Java&lt;br /&gt;
到&lt;a href=&#34;http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html&#34;&gt;Java官网&lt;/a&gt;下载适用于Linux的Java安装包（这里下载了jdk-8u101-linux-x64.tar.gz）。&lt;/li&gt;
&lt;li&gt;下载maven&lt;br /&gt;
点击&lt;a href=&#34;http://mirrors.aliyun.com/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.zip&#34;&gt;阿里云镜像站&lt;/a&gt;下载最新版Maven。&lt;/li&gt;
&lt;li&gt;下载Apache的Storm Hadoop Kafka ZooKeeper&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/storm/apache-storm-0.10.2/apache-storm-0.10.2.tar.gz&#34;&gt;点击下载Storm-0.10.2&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/hadoop/core/hadoop-2.6.4/hadoop-2.6.4.tar.gz&#34;&gt;点击下载Hadoop-2.6.4&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/kafka/0.8.2.2/kafka_2.10-0.8.2.2.tgz&#34;&gt;点击下载Kafka_2.10-0.8.2.2&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz&#34;&gt;点击下载ZooKeeper-3.4.6&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-创建所需目录&#34;&gt;2. 创建所需目录&lt;/h3&gt;

&lt;p&gt;把所有和此项目相关的文件都放在统一的位置。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ sudo mkdir -p /opt/apache/{jdk, storm,hadoop,kafka,zookeeper}&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-解压所有安装包-将相应的安装包放在对应的位置&#34;&gt;3. 解压所有安装包，将相应的安装包放在对应的位置&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mv jdk1.8.0_101/* /opt/jdk/.
$ sudo mv apache-storm-0.10.0/* /opt/apache/storm/.
$ sudo mv hadoop-2.6.4/* /opt/apache/hadoop/.
$ sudo mv kafka_2.10-0.8.2.2/* /opt/apache/kafka/.
$ sudo mv zookeeper-3.4.6/* /opt/apache/zookeeper
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-配置环境变量&#34;&gt;4. 配置环境变量&lt;/h3&gt;

&lt;p&gt;在~/.bashrc中添加下面的片段&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export JAVA_HOME=/opt/jdk
export APACHE_HOME=/opt/apache
export STORM_HOME=$APACHE_HOME/storm
export ZK_HOME=$APACHE_HOME/zookeeper
export KAFKA_HOME=$APACHE_HOME/kafka

export HADOOP_HOME=$APACHE_HOME/hadoop
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_INSTALL=$HADOOP_HOME

export PATH=$PATH:$JAVA_HOME/bin
export PATH=$PATH:$STORM_HOME/bin
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export PATH=$PATH:$ZK_HOME/bin
export PATH=$PATH:$KAFKA_HOME/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后执行&lt;code&gt;$ source ~/.bashrc&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;5-安装java&#34;&gt;5. 安装Java&lt;/h4&gt;

&lt;p&gt;Apache的这些东西都是直接放在对的地方就可以运行的，但Java需要稍微的配置一下，因为可能你的机器上已经装了OpenJDK。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ sudo update-alternatives --install /usr/local/bin/java java /opt/jdk/bin/java 10000&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这时再执行&lt;code&gt;$ java -version&lt;/code&gt;验证一下是否使用的时最新安装的JDK。&lt;/p&gt;

&lt;h2 id=&#34;2-启动服务&#34;&gt;2. 启动服务&lt;/h2&gt;

&lt;h3 id=&#34;1-启动zookeeper&#34;&gt;1. 启动ZooKeeper&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ cp $ZK_HOME/conf/zoo_sample.cfg $ZK_HOME/conf/zoo.cfg
$ zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-启动storm&#34;&gt;2. 启动Storm&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ storm nimbus
$ storm supervisor
$ storm ui
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在可以访问&lt;a href=&#34;http://localhost:8080&#34;&gt;Storm UI&lt;/a&gt;了。&lt;/p&gt;

&lt;h3 id=&#34;3-启动kafka-broker&#34;&gt;3. 启动Kafka Broker&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ cd $KAFKA_HOME
$ bin/kafka-server-start.sh -daemon config/server.properties
$ bin/kafka-topics.sh --list --zookeeper localhost:2181
$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 10 --topic storm-demo-topic
Created topic &amp;quot;storm-demo-topic&amp;quot;.
$ bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic storm-demo-topic
Topic:storm-demo-topic  PartitionCount:10       ReplicationFactor:1     Configs:
        Topic: storm-demo-topic Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 2    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 3    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 4    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 5    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 6    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 7    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 8    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 9    Leader: 0       Replicas: 0     Isr: 0
$ kafka-console-producer.sh --broker-list localhost:9092 --topic storm-demo-topic
$ kafka-console-consumer.sh --zookeeper localhost:2181 --topic storm-demo-topic --from-beginning
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注意前面有些命令仅仅是为了测试kafka broker运行的情况。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;4-启动hadoop-hdfs&#34;&gt;4. 启动Hadoop(HDFS)&lt;/h3&gt;

&lt;h4 id=&#34;1-修改hadoop的配置文件&#34;&gt;1. 修改Hadoop的配置文件&lt;/h4&gt;

&lt;p&gt;在&lt;code&gt;$HADOOP_HOME/etc/hadoop&lt;/code&gt;目录下有5个文件需要修改:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;core-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.default.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;hdfs-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.name.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/hadoop/hadoopinfra/hdfs/namenode&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.data.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/hadoop/hadoopinfra/hdfs/datanode&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;yarn-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;mapred-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;hadoop-env.sh&lt;/code&gt;
把hadoop-env.sh中的${JAVA_HOME}替换成路径,这里是&lt;code&gt;/opt/jdk&lt;/code&gt;，因为貌似会找不到正确的&lt;code&gt;JAVA_HOME&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;2-验证是否安装成功&#34;&gt;2. 验证是否安装成功&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ hadoop namenode -format
$ start-dfs.sh
$ start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行上面三行语句，观察有没有明显的报错信息。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:50070&#34;&gt;检查HadoopUI&lt;/a&gt;运行是否正常。&lt;br /&gt;
&lt;a href=&#34;http://localhost:8088&#34;&gt;检查Hadoop Applications&lt;/a&gt;(我自己取的名字)运行是否正常。&lt;/p&gt;

&lt;p&gt;至此已经搭建了一个可以运行的hadoop环境，可以移步这里查看关于Storm入门分享详情。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>slf4j配合log4j来给你的应用打log</title>
      <link>http://lovelock.coding.me/java/use-slf4j-and-log4j-to-log-your-applications/</link>
      <pubDate>Thu, 22 Sep 2016 14:16:06 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/use-slf4j-and-log4j-to-log-your-applications/</guid>
      <description>&lt;p&gt;最近刚开始接触Java，被折腾的很难受。因为PHP随便找个环境都能执行，只需要把代码传上去就OK，而Java还需要编译、打包，用mvn执行命令，本来不多的功能就高出一下上百兆的包，然后传到服务器上。后来在运维同学的配合下整了一套只需要我把代码提交到Git仓库，系统自动打包并上传到需要执行的机器上的工作流，虽然比之前好了很多，但还是没有PHP开发的过程流畅。&lt;/p&gt;

&lt;p&gt;说了这么多，是因为Java调试起来不容易，或者说成本高。所以就需要尽量在提交代码之前打尽可能多的日志，帮助后面查找问题。找了一圈，发现最通用的Java日志库是slf4j(Simple Logging Facade for Java)。
这名字都不喜欢，什么破玩意儿。而且这玩意儿其实自己并不记录日志，而只是一个日志的Facade，也就是说它是用来&lt;strong&gt;为其他真正执行记日志功能的类库提供一个标准接口&lt;/strong&gt;的。我也没有兴趣去研究它的代码，想想也是各种设计模式用的6到飞起了。
下面是记录一下怎么用最简单的方式把它添加到自己的项目中，以log4j为例。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;需要添加的dependencies&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;slf4j-log4j12&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;1.7.21&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;后面两个依赖并不是必需的，只需要第一个即可。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;在需要记日志的类中添加这样的一些代码片段&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package com.unixera.mvn;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class App 
{
    private static Logger LOG = LoggerFactory.getLogger(App.class);
    public static void main( String[] args )
    {
        LOG.info(&amp;quot;this is a log&amp;quot;);
        LOG.debug(&amp;quot;This is a log with some information {}&amp;quot;, args.toString());
        System.out.println( &amp;quot;Hello World!&amp;quot; );
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;执行一下，这时候会发现下面的警告信息。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;log4j:WARN No appenders could be found for logger (HelloWorld).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;虽然把我引导去了一篇FAQ，但看完我还是不知道是怎么回事。关于这个问题的答案一搜一大把，这也说明看了FAQ仍然不明白的人远远不止我一个。&lt;br /&gt;
首先要知道这里appender的意思。它其实就是上面说到的真正执行记录日志工作的类库，在这里就是log4j。那它指出的问题就是log4j需要一个初始化配置，而我们并没有给它指定初始化配置。所以这个appender就不知道该怎们工作。&lt;br /&gt;
其实这也很容易理解，毕竟要记日志，你不告诉它日志级别、记录日志的路径和格式，它怎么能帮你决定这些事情呢？&lt;/p&gt;

&lt;p&gt;『小声说两句，其实这也是我写Java的时候感受最深最痛苦的事情，Java太过于讲究设计模式了，把任务的职责分的太细，导致本来很小的一件事都要绕来绕去引入很多东西，虽然这保证了大量菜鸟写起来不容易出错，但也导致了开发效率的降低和开发者的心情问题。』&lt;/p&gt;

&lt;p&gt;言归正传，最简单的办法是需要在main里面新建一个目录&lt;code&gt;resources&lt;/code&gt;，新建文件log4j.properties，写入&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;log4j.rootLogger=TRACE, file, stdout

log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Target=System.out
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSS} %-5p [%c] - %m%n


log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.File=./log/javavillage.log
log4j.appender.file.MaxFileSize=10000KB
log4j.appender.file.MaxBackupIndex=10
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} [%t] %-5p:: %m%n
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这段配置文件做了以下几件事：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;第一行设置了日志级别TRACE，意思是记录TRACE和高于TRACE级别的所有日志，因为TRACE是最低的，所以这里设置的是所有日志都会记录。什么意思呢？log4j有这几个日志级别：TRACE,DEBUG,INFO,WARN,ERROR,FATAL，这几个级别从左到右依次升高。也越来越不详细。也就是说，如果设置了日志级别是INFO，那么&lt;code&gt;LOG.trace()&lt;/code&gt;和&lt;code&gt;LOG.debug()&lt;/code&gt;这种语句会被忽略，而后面四中是会正常执行的。&lt;/li&gt;
&lt;li&gt;日志输出的位置，这里设置的是文件和标准输出&lt;/li&gt;
&lt;li&gt;分别设置了两种输出位置的一些属性，比如输出到标准输出应该是什么样的格式，用什么标准来做文本替换，用什么样的时间格式等等；至于输出到文件的情况就比较复杂了，因为还牵涉到文件的路径，文件大小上限等。具体这个项需要怎么配置我也没有详细的研究，以后如果需要再用到Java并且有需求再说吧。毕竟我不太喜欢Java。需要的可以参考这里&lt;a href=&#34;https://www.tutorialspoint.com/log4j/log4j_logging_files.htm&#34;&gt;1&lt;/a&gt;。&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>使用maven创建和运行Java应用</title>
      <link>http://lovelock.coding.me/java/create-and-run-java-application-with-maven/</link>
      <pubDate>Thu, 22 Sep 2016 14:15:41 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/create-and-run-java-application-with-maven/</guid>
      <description>

&lt;p&gt;最近这段时间在研究Storm，虽然不是研究源码而是研究使用，也让我这个自认为会写Java HelloWorld的菜鸟感到了深深的无力感。尤其是打开一本书，上面第一行代码就执行报错时我的心情可想而知了。&lt;/p&gt;

&lt;h3 id=&#34;1-创建应用&#34;&gt;1. 创建应用&lt;/h3&gt;

&lt;p&gt;因为我最近的使用场景是创建一个普通项目（区别于Web项目），所以直接用&lt;code&gt;mvn archetype:generate&lt;/code&gt;根据提示如果默认一路点下来会生成一个简单应用的骨架。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;注意：如果你在哪里看到&lt;code&gt;mvn archetype:create&lt;/code&gt;这样的写法，而在你的机器上执行出错，不用怀疑，因为你看到的资料太老了，而你用的是新版的maven，按我的写法没有错。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://ww1.sinaimg.cn/large/006y8lVajw1f840c2rryxj31ey100n83.jpg&#34; alt=&#34;创建应用的过程&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如果需要生成webapp类型应用，比如一个基于SpringFramework的应用就不是831了，而是类似这样&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mvn archetype:generate -DarchetypeArtifactId=maven-archetype-webapp\
                        -DinteractiveMode=false \
                        -DgroupId=com.unixera.webapp \
                        -DartifactId=spring-example
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体再到里面怎么写应用这里就不展开了，如果有时间的话会有相关的文章单独来介绍。&lt;/p&gt;

&lt;h3 id=&#34;2-打包应用&#34;&gt;2. 打包应用&lt;/h3&gt;

&lt;p&gt;经过上面的&lt;code&gt;mvn archetype:generate&lt;/code&gt;命令之后，创建的目录类似这样
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f84hsklj4oj30g003ejrn.jpg&#34; alt=&#34;根目录结构&#34; /&gt;
如果再往深了看，是这样的
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f84huul3ihj30jq0j8ab7.jpg&#34; alt=&#34;树状结构&#34; /&gt;
其中最需要注意的就是&lt;code&gt;pom.xml&lt;/code&gt;这个文件，关于maven的简单使用可以参考我之前写的&lt;a href=&#34;http://unixera.com/java/mvn-tutorial-for-novice/&#34;&gt;给Java新手看的mvn指南&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;写完了应用当然是希望执行它，我们知道Java程序是需要编译成字节码之后才能执行的，当你学Java的HelloWorld时一般是告诉你&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;javac HelloWorld.java
java HelloWorld
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这没有问题，但问题是当我们用maven管理一个项目时当然就不能这么去操作了，就像写C代码时直接用gcc编译和写Makefile使用make来管理项目是一样的道理。&lt;/p&gt;

&lt;h4 id=&#34;普通的jar包&#34;&gt;普通的jar包&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;mvn compile&lt;/code&gt;&lt;br /&gt;
这时可以尝试在根目录里执行&lt;code&gt;mvn compile&lt;/code&gt;看看结果。
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f84hzh3knjj31bk0l6dmm.jpg&#34; alt=&#34;&#34; /&gt;
这相当于执行&lt;code&gt;javac&lt;/code&gt;，只不过根据mvn的默认配置，它把编译生成的class文件放在了指定的位置，那它究竟生成了哪些文件呢？
&lt;img src=&#34;http://ww1.sinaimg.cn/large/006y8lVajw1f84i209hshj30xu0x241u.jpg&#34; alt=&#34;&#34; /&gt;
可以看到，它并没有生成我们希望的&lt;strong&gt;可以发布的jar包&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn package&lt;/code&gt;&lt;br /&gt;
我们知道，其实jar包的本质就是zip，是把项目执行需要的资源全部打包（此处不准确，后面会谈）在一起发布的方式。而&lt;code&gt;mvn package&lt;/code&gt;执行的就是打包的过程。
&lt;img src=&#34;http://ww1.sinaimg.cn/large/006y8lVajw1f84i6llp9cj31di194k5p.jpg&#34; alt=&#34;&#34; /&gt;
这里的输出结果也验证了之前的文章中提到的说法。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;compile test package install&lt;/code&gt;是一套流程，执行后面的命令时会重复执行前面的命令&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;再来看&lt;code&gt;mvn package&lt;/code&gt;生成了哪些文件（只看target目录即可）
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f84ibl3z03j30qm0xw78g.jpg&#34; alt=&#34;&#34; /&gt;
重点关注红线标注的jar包，这是我们需要的。
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f84iezqgjrj313c0h0jvy.jpg&#34; alt=&#34;&#34; /&gt;
这就是jar包中的所有东西。你可能知道执行一个jar包需要的命令时&lt;code&gt;java -jar xxxx.jar&lt;/code&gt;，然并卵，这时执行这个是会出错的。解决方法后面会说。
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f84iggkm9nj30vi02at9g.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;使用mvn生成main-class&#34;&gt;使用mvn生成Main-Class&lt;/h4&gt;

&lt;p&gt;下面来解释一下为什么简单的打包并不能生成可以直接执行的jar包。
首先需要了解一点Manifest的知识&lt;a href=&#34;https://docs.oracle.com/javase/tutorial/deployment/jar/manifestindex.html&#34;&gt;2&lt;/a&gt;。简单来说，就是一个jar包需要Manifest文件中包含指定的内容才可以执行。那我们根据前面的经验，用&lt;code&gt;mvn package&lt;/code&gt;生成的jar包中是包含&lt;code&gt;META-INF/MANIFEST.MF&lt;/code&gt;的，实际上jar包运行需要的就是这个所谓的Manifest文件。
打开它看一下
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f88hw52bhvj30kg06caax.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;根据Java SE官方文档&lt;a href=&#34;https://docs.oracle.com/javase/tutorial/deployment/jar/appman.html&#34;&gt;3&lt;/a&gt;, 一个Manifest文件中至少需要包含&lt;code&gt;Main-Class&lt;/code&gt;字段才可以使之使用&lt;code&gt;java -jar&lt;/code&gt;命令执行。&lt;/p&gt;

&lt;p&gt;那我们来试着修改一下
1. 把jar包解压：
&lt;img src=&#34;http://ww2.sinaimg.cn/large/006y8lVagw1f88i2b79rzj30zq0d00wv.jpg&#34; alt=&#34;&#34; /&gt;
2. 修改&lt;code&gt;META-INF/MANIFEST.MF&lt;/code&gt;文件，改成
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f88i3lfb2fj30pc08c0u5.jpg&#34; alt=&#34;&#34; /&gt;
（其中红框中的部分根据自己的实际报名填写）
3. 重新打包
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f88id79j1pj311a0cejv9.jpg&#34; alt=&#34;&#34; /&gt;
4. 再来执行一下
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f88ig6mioaj30ew020q32.jpg&#34; alt=&#34;&#34; /&gt;
没错，成功了。&lt;/p&gt;

&lt;p&gt;所以我们知道了直接生成的jar包不能执行是因为Manifest中缺少了指定Main-Class的指令。那么既然我们使用了mvn，依赖了pom.xml，那mvn当然是能帮我们直接解决这个问题的，不然要自己每次解压、修改再压缩得累死了。&lt;/p&gt;

&lt;p&gt;根据这个答案&lt;a href=&#34;http://stackoverflow.com/questions/574594/how-can-i-create-an-executable-jar-with-dependencies-using-maven&#34;&gt;4&lt;/a&gt;, 在&lt;code&gt;pom.xml&lt;/code&gt;中添加plugin配置即可&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependencies&amp;gt;
...
&amp;lt;/dependencies&amp;gt;

 &amp;lt;build&amp;gt;
    &amp;lt;plugins&amp;gt;
      &amp;lt;plugin&amp;gt;
        &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;maven-assembly-plugin&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;2.6&amp;lt;/version&amp;gt;
        &amp;lt;configuration&amp;gt;
          &amp;lt;archive&amp;gt;
            &amp;lt;manifest&amp;gt;
              &amp;lt;mainClass&amp;gt;com.unixera.mvn.App&amp;lt;/mainClass&amp;gt;
            &amp;lt;/manifest&amp;gt;
          &amp;lt;/archive&amp;gt;
        &amp;lt;/configuration&amp;gt;
      &amp;lt;/plugin&amp;gt;
    &amp;lt;/plugins&amp;gt;
  &amp;lt;/build&amp;gt;
&amp;lt;/project&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再执行&lt;code&gt;mvn package&lt;/code&gt;生成的jar包的Manifest中就会带有Main-Class的信息了。&lt;/p&gt;

&lt;h4 id=&#34;jar-with-dependencies&#34;&gt;jar-with-dependencies&lt;/h4&gt;

&lt;p&gt;现在我们终于有了一个可以正常工作的类了，不妨给它添加一个依赖吧。比如我在另外一篇文章中提到的slf4j&lt;a href=&#34;http://unixera.com/java/use-slf4j-and-log4j-to-log-your-applications/&#34;&gt;5&lt;/a&gt;。
具体做法可以参考该文章。这里只谈打包的问题。现在我们的pom.xml文件中在dependencies段中应该包含这样一段：
&lt;img src=&#34;http://ww2.sinaimg.cn/large/006y8lVajw1f96nuir9vnj30m405ygmi.jpg&#34; alt=&#34;&#34; /&gt;
我在App.java中添加了slf4j的用例。按照之前的做法，仍然
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f88lgk9cxxj31cs1787fv.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f88lgxno8yj311u090jv3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;怎么回事？明明已经引入了需要的包了，为什么会找不到类呢？
问题还是出在jar包的打包方式上。
有PHP使用经验并且用过Composer的同学可能知道，Composer管理依赖的方式非常简单，就是把你的项目需要的代码下载到你项目的目录中，然后通过Composer的Autoload功能把它们加载到使用它们的地方。
但Java不是这样，或者说mvn不是这样。
首先，mvn把所有的依赖的包都放在了用户的根目录下，默认是&lt;code&gt;$HOME/.m2/repository&lt;/code&gt;，在这个目录下可以看到各个vendor的各种版本的包。但是在目前我们配置的这种模式下，打成的jar包并不会包含这些东西，而且在执行jar包时，也不会去相应的目录去查找需要的包。
&lt;strong&gt;其实就是动态加载&lt;/strong&gt;。和写C时用到的.so文件是一个道理。如果希望我们的程序能到处能运行的话，最好把它的依赖都打成.a文件，然后和项目代码打成一个完整的包，所有依赖的类库都在同一个包里就不存在这种问题了。
所以需要引入一个新的打包方式&lt;code&gt;jar-with-dependencies&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;根据同样根据上面那个答案,还需要添加如下的配置
&lt;img src=&#34;http://ww2.sinaimg.cn/large/006y8lVajw1f96nstiz0qj30uy0ssn0y.jpg&#34; alt=&#34;&#34; /&gt;
再重新执行上面的过程，可以运行了。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;本来在上面的文章中引用的是maven的官方文档，后来在实际使用中发现那种方式经常失效，对照自己试验成功后的文章也不奏效，于是找到了前面提到的答案，看来即使是官方文档，也还是需要民间的工程师们来发现最佳实践啊。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;3-执行应用&#34;&gt;3. 执行应用&lt;/h3&gt;

&lt;p&gt;执行应用就很简单了，直接从java -help就可以获取很多信息，就不展开说了。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;java -cp $CLASSPATH -jar /path/to/jar-with-dependencies.jar&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;本文旨在引导读者一步一步创建可执行的jar包，包括工程骨架的创建，依赖管理，打包方式，重点谈了下打包方式对生成的jar包功能的影响。引用了不少官方文档，本文只是简略的描述了一下整个过程，更详细的配置可以追随我引用的文档继续研究。&lt;/p&gt;

&lt;p&gt;可能有读者会问为什么我用截图而不是代码块的方式来演示，其实我是怕你们偷懒哈哈哈。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>给Java新手看的mvn指南</title>
      <link>http://lovelock.coding.me/java/mvn-tutorial-for-novice/</link>
      <pubDate>Sun, 28 Aug 2016 14:29:16 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/mvn-tutorial-for-novice/</guid>
      <description>

&lt;h2 id=&#34;官方定义&#34;&gt;官方定义&lt;/h2&gt;

&lt;p&gt;Maven是基于项目对象模型，可以通过一小段描述信息来管理项目的构建、报告和文档的软件管理工具。&lt;/p&gt;

&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;

&lt;p&gt;Maven的使用过程中最经常用到的就是依赖管理了，一个依赖也就是一个包，是包含了几个属性的
- &lt;code&gt;groupId&lt;/code&gt; 通常是公司域名的反写加上项目名，比如&lt;code&gt;com.unixera.mvndemo&lt;/code&gt;
- &lt;code&gt;artifactId&lt;/code&gt; 模块名，比如&lt;code&gt;project1&lt;/code&gt;
- &lt;code&gt;version&lt;/code&gt; 版本号，经常见到的是形如&lt;code&gt;1.0.0-SNAPSHOT&lt;/code&gt;这种，即快照版本，还有&lt;code&gt;RELEASE&lt;/code&gt;等。&lt;/p&gt;

&lt;h2 id=&#34;规定&#34;&gt;规定&lt;/h2&gt;

&lt;p&gt;它规定的目录结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-src 
 -main
  -java
   -packagename
 -test
  -java
   -packagename
 -resource
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;基础命令&#34;&gt;基础命令&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mvn compile&lt;/code&gt; 编译项目&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn test&lt;/code&gt; 测试&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn package&lt;/code&gt; 打包&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn clean&lt;/code&gt; 删除已经生成的测试报告和字节码文件，其实就是删除target文件夹&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn install&lt;/code&gt; 安装jar包到本地目录中&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面这5个过程如果执行后面的，前面的也会自动执行。也就是说后面的命令是依赖前面的命令的。&lt;/p&gt;

&lt;h2 id=&#34;经常遇到的问题&#34;&gt;经常遇到的问题&lt;/h2&gt;

&lt;h3 id=&#34;1-间接依赖&#34;&gt;1. 间接依赖&lt;/h3&gt;

&lt;p&gt;A依赖B，B依赖C，那么A就间接的依赖了C，如果要显式的声明A不依赖C，可以在A的pom.xml中加入&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;
&amp;lt;dependecy&amp;gt;
	&amp;lt;groupId&amp;gt;BgroupId&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;BartifactId&amp;lt;/artifactId&amp;gt;
	&amp;lt;version&amp;gt;1.2.3&amp;lt;/version&amp;gt;
	&amp;lt;exclusions&amp;gt;
		&amp;lt;exclusion&amp;gt;
			&amp;lt;groupId&amp;gt;CgroupId&amp;lt;/groupId&amp;gt;
			&amp;lt;artifactId&amp;gt;CartifactId&amp;lt;/artifactId&amp;gt;
			&amp;lt;version&amp;gt;1.2.3&amp;lt;/version&amp;gt;
		&amp;lt;/exclusion&amp;gt;
	&amp;lt;/exclusions&amp;gt;
&amp;lt;/dependecy&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-如何添加依赖&#34;&gt;2. 如何添加依赖&lt;/h3&gt;

&lt;p&gt;比如项目要使用servlet，那就去&lt;a href=&#34;http://search.maven.org/&#34;&gt;全球中央仓库&lt;/a&gt;查找包名和相应的版本号,如图所示&lt;img src=&#34;http://ww4.sinaimg.cn/large/7853084cjw1f79btj2nb8j20fl0f9q4b.jpg&#34; alt=&#34;&#34; /&gt;。从中复制Apache Maven下面的一段XML粘贴到相应的&lt;code&gt;&amp;lt;dependencies&amp;gt;&amp;lt;/dependencies&amp;gt;&lt;/code&gt;中即可。&lt;/p&gt;

&lt;h3 id=&#34;3-变量的使用&#34;&gt;3. 变量的使用&lt;/h3&gt;

&lt;p&gt;有时在一个pom.xml文件中会看到有&lt;code&gt;${project.version}&lt;/code&gt;这种写法，那一看就是一个引用，这个东西是在&lt;code&gt;&amp;lt;properties&amp;gt;&amp;lt;/properties&amp;gt;&lt;/code&gt;中定义的，比如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;properties&amp;gt;
    &amp;lt;maven.compile.source&amp;gt;1.5&amp;lt;/maven.compile.source&amp;gt;
    &amp;lt;maven.compile.target&amp;gt;1.5&amp;lt;/maven.compile.target&amp;gt;
&amp;lt;/properties&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样定义了之后在后面就可以用&lt;code&gt;${maven.compile.source}&lt;/code&gt;来引用了。&lt;/p&gt;

&lt;h3 id=&#34;4-一个项目下多个模块重复依赖一个包&#34;&gt;4. 一个项目下多个模块重复依赖一个包&lt;/h3&gt;

&lt;p&gt;下面着重说一下如何利用Maven的继承关系简化项目的POM配置。&lt;/p&gt;

&lt;h4 id=&#34;在项目的根目录下创建pom-xml&#34;&gt;在项目的根目录下创建pom.xml&lt;/h4&gt;

&lt;p&gt;还以上面的项目名为例，比如root目录是project,则在project目录里创建pom.xml&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;project xmlns=&amp;quot;http://maven.apache.org/POM/4.0.0&amp;quot; xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot;
	xsi:schemaLocation=&amp;quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;quot;&amp;gt;
	&amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;
	&amp;lt;groupId&amp;gt;com.unixera&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;root&amp;lt;/artifactId&amp;gt;
	&amp;lt;version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/version&amp;gt;
	&amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt;
	
	&amp;lt;properties&amp;gt;
	    &amp;lt;project.version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/project.version&amp;gt;
	    &amp;lt;junit.version&amp;gt;4.10&amp;lt;/junit.version&amp;gt;
	    &amp;lt;jmock.version&amp;gt;2.8.2&amp;lt;/jmock.version&amp;gt;
	&amp;lt;/properties&amp;gt;
	
	&amp;lt;dependencies&amp;gt;
	    &amp;lt;dependency&amp;gt;
			&amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;
			&amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;
			&amp;lt;version&amp;gt;${junit.version}&amp;lt;/version&amp;gt;
			&amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
		&amp;lt;/dependency&amp;gt;
		&amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.jmock&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;jmock&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;${jmock.version}&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
	&amp;lt;/dependencies&amp;gt;
&amp;lt;/project&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就声明了该项目需要依赖junit，那么里面的子项目就用&lt;code&gt;mvn archetype:generate&lt;/code&gt;来交互式的生成，比如&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Choose org.apache.maven.archetypes:maven-archetype-quickstart version:
1: 1.0-alpha-1
2: 1.0-alpha-2
3: 1.0-alpha-3
4: 1.0-alpha-4
5: 1.0
6: 1.1
Choose a number: 6: 6
Define value for property &#39;groupId&#39;: : com.unixera.mvndemo
Define value for property &#39;artifactId&#39;: : project1
Define value for property &#39;version&#39;:  1.0-SNAPSHOT: :
Define value for property &#39;package&#39;:  com.unixera.mvndemo: :
Confirm properties configuration:
groupId: com.unixera.mvndemo
artifactId: project1
version: 1.0-SNAPSHOT
package: com.unixera.mvndemo
 Y: :
[INFO] ----------------------------------------------------------------------------
[INFO] Using following parameters for creating project from Old (1.x) Archetype: maven-archetype-quickstart:1.1
[INFO] ----------------------------------------------------------------------------
[INFO] Parameter: basedir, Value: /Users/frost/IdeaProjects
[INFO] Parameter: package, Value: com.unixera.mvndemo
[INFO] Parameter: groupId, Value: com.unixera.mvndemo
[INFO] Parameter: artifactId, Value: project1
[INFO] Parameter: packageName, Value: com.unixera.mvndemo
[INFO] Parameter: version, Value: 1.0-SNAPSHOT
[INFO] project created from Old (1.x) Archetype in dir: /Users/frost/IdeaProjects/project1
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 35.492 s
[INFO] Finished at: 2016-08-28T14:16:28+08:00
[INFO] Final Memory: 13M/201M
[INFO] ------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入&lt;code&gt;project&lt;/code&gt;目录，打开&lt;code&gt;pom.xml&lt;/code&gt;，可以看到mvn生成的项目已经默认依赖了junit，那我们来修改一下让它依赖parent所定义的junit。
首先加上&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;parent&amp;gt;
	&amp;lt;groupId&amp;gt;com.unixera.mvdemo&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;root&amp;lt;/artifactId&amp;gt;
	&amp;lt;version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/version&amp;gt;
&amp;lt;/parent&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就可以把junit的依赖放心的删掉了，因为它已经认了root做parent，parent的依赖就是它的依赖了。&lt;br /&gt;
那如果parent的某些依赖它并不需要呢？可以在子项目中添加&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependencyManagement&amp;gt;
    &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;com.unixera.mvndemo&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;root&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/version&amp;gt;
            &amp;lt;exclusions&amp;gt;
                &amp;lt;exclusion&amp;gt;
                    &amp;lt;groupId&amp;gt;org.jmock&amp;lt;/groupId&amp;gt;
                    &amp;lt;artifactId&amp;gt;jmock&amp;lt;/artifactId&amp;gt;
                    &amp;lt;version&amp;gt;2.8.2&amp;lt;/version&amp;gt;
                &amp;lt;/exclusion&amp;gt;
            &amp;lt;/exclusions&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;
&amp;lt;/dependencyManagement&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样子项目就不依赖jmock模块了。&lt;/p&gt;

&lt;p&gt;当然mvn的使用远远不止这些，这里记录一些目前使用到的，后面如果还继续回写Java的话会再更新一下。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
