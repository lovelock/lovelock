<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hdfs on Me &amp; Web</title>
    <link>http://lovelock.coding.me/tags/hdfs/</link>
    <description>Recent content in Hdfs on Me &amp; Web</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) 2013-2016 Frost Wong. All rights reserved.</copyright>
    <lastBuildDate>Wed, 11 Jan 2017 14:27:46 +0800</lastBuildDate>
    <atom:link href="/tags/hdfs/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>清理HDFS的脏数据</title>
      <link>http://lovelock.coding.me/bigdata/cleanup-dirty-data-in-hdfs/</link>
      <pubDate>Wed, 11 Jan 2017 14:27:46 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/bigdata/cleanup-dirty-data-in-hdfs/</guid>
      <description>

&lt;p&gt;周末同事在群里用由我维护的Hive里查数据，发现完全对不上了，我简单查了一下，发现是预计下一期上的日志格式提前上了，而我的Topology还没有跟上，导致数据字段完全错乱。我马上停掉相应的Topology，避免产生更多的脏数据，周一到公司在给新版的Topology做了严格测试准备上线。&lt;/p&gt;

&lt;p&gt;接下来面对的就是怎么把脏数据清除掉，把被错误处理的数据重新处理一遍，并且后续的数据不受影响。&lt;/p&gt;

&lt;h2 id=&#34;步骤&#34;&gt;步骤&lt;/h2&gt;

&lt;h3 id=&#34;1-找到脏数据的offset-最好向前移动一些-以保证所有脏数据都能被处理&#34;&gt;1. 找到脏数据的offset，最好向前移动一些，以保证所有脏数据都能被处理&lt;/h3&gt;

&lt;p&gt;在数据处理节点（我们这里是core节点）上找到kafka-broker的安装目录，执行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh bin/kafka-simple-consumer-shell.sh --topic online_userbehaviortrack --offset -2 --broker-list 10.68.160.52:6667,10.68.160.53:6667,10.68.160.54:6667 --print-offsets --partition 9
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的命令会输出类似&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;next offset = 3381
{&amp;quot;message&amp;quot;:&amp;quot;2017-01-11T14:40:55+0800`1484116855552`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;的结果，从中可以很详细的看到每条message的offset，结合管道和less就可以根据时间找到出现脏数据的offset，然后确定一个时间点，比如下午2点，在每个partition中分别找到2点之前的最后一个offset，找个地方记下来。&lt;/p&gt;

&lt;h3 id=&#34;2-到zookeeper中找到每个对应的partiton-用步骤1的offset结果覆盖partiton中的offset字段&#34;&gt;2. 到ZooKeeper中找到每个对应的Partiton，用步骤1的offset结果覆盖Partiton中的offset字段&lt;/h3&gt;

&lt;p&gt;因为我的KafkaSpout是这么写的&lt;code&gt;SpoutConfig kafkaSpoutConfig = new SpoutConfig(brokerHosts, topic, &amp;quot;/&amp;quot; + topic, client_id);&lt;/code&gt;，所以在我的ZooKeeper中我应该去&lt;code&gt;/mytopic/mytopologyname/&lt;/code&gt;中找到所有的partiton，这个需要根据你自己的代码来确定。&lt;/p&gt;

&lt;p&gt;以partition_9为例，结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[zk: localhost:2181(CONNECTED) 2] get /mytopic/fe_analyze/partition_9
{&amp;quot;topology&amp;quot;:{&amp;quot;id&amp;quot;:&amp;quot;c75ac929-1a8e-4958-a637-ead9a95436ca&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;mytopologyname&amp;quot;},&amp;quot;offset&amp;quot;:3384,&amp;quot;partition&amp;quot;:9,&amp;quot;broker&amp;quot;:{&amp;quot;host&amp;quot;:&amp;quot;kmr-9a387314-gn-6bb9c438-core-1-002.ksc.com&amp;quot;,&amp;quot;port&amp;quot;:6667},&amp;quot;topic&amp;quot;:&amp;quot;mytopic&amp;quot;}
cZxid = 0x1017bd837
ctime = Mon Dec 26 15:06:19 CST 2016
mZxid = 0x101cbb4ec
mtime = Wed Jan 11 14:49:40 CST 2017
pZxid = 0x1017bd837
cversion = 0
dataVersion = 2173
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 223
numChildren = 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因为我们只需要设置partiton的offset值，而它接收一个JSON类型的值，所以就需要这样&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[zk: localhost:2181(CONNECTED) 4] set /mytopic/mytopologyname/partition_9 {&amp;quot;topology&amp;quot;:{&amp;quot;id&amp;quot;:&amp;quot;c75ac929-1a8e-4958-a637-ead9a95436ca&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;fe_analyze&amp;quot;},&amp;quot;offset&amp;quot;:3386,&amp;quot;partition&amp;quot;:9,&amp;quot;broker&amp;quot;:{&amp;quot;host&amp;quot;:&amp;quot;kmr-9a387314-gn-6bb9c438-core-1-002.ksc.com&amp;quot;,&amp;quot;port&amp;quot;:6667},&amp;quot;topic&amp;quot;:&amp;quot;mytopic&amp;quot;}
cZxid = 0x1017bd837
ctime = Mon Dec 26 15:06:19 CST 2016
mZxid = 0x101cbba18
mtime = Wed Jan 11 14:54:29 CST 2017
pZxid = 0x1017bd837
cversion = 0
dataVersion = 2176
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 223
numChildren = 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;把其中的offset的值替换成在步骤1中拿到的partiton 9的offset值。&lt;/p&gt;

&lt;h3 id=&#34;3-写脚本删除hdfs中对应topology出现脏数据以后的所有数据&#34;&gt;3. 写脚本删除HDFS中对应Topology出现脏数据以后的所有数据&lt;/h3&gt;

&lt;p&gt;我的设计是每天分成24个partition，类似(yyyymmddhh=2017011010)这种，所以就可以写个类似这样的脚本：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/usr/bin/env bash

DAY=$(date -d &amp;quot;-1 day&amp;quot; +%Y%m%d)

for HH in {00..23}
do
    hdfs dfs -rm -r -f /path/to/topology/yyyymmddhh=${DAY}${HH}
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个脚本可以删除前一天的所有24个partiton的数据。&lt;/p&gt;

&lt;h3 id=&#34;4-如果新的topology对应的hive-table也有变化-需要先修改hive的表结构&#34;&gt;4. 如果新的Topology对应的Hive table也有变化，需要先修改Hive的表结构&lt;/h3&gt;

&lt;p&gt;Hive表结构的修改和MySQL的差不多，不过还是有些差别：比如新添加的列只能放在所有真实列的最后，partiton伪列的前面。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;alter table xxxx add columns (string coln, string colm);&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;注意是&lt;strong&gt;&lt;code&gt;columns&lt;/code&gt;&lt;/strong&gt;而不是&lt;code&gt;column&lt;/code&gt;。而且也不能指定after哪个column。&lt;/p&gt;

&lt;h3 id=&#34;5-重新添加所有受影响的partiton到hive-table&#34;&gt;5. 重新添加所有受影响的partiton到Hive table&lt;/h3&gt;

&lt;p&gt;因为我们这里用的是external table（当我提到HDFS的时候你就应该知道了），所以所有新数据对应的partiton都应该删除后重新添加，以yyyymmddhh=2017011020为例，&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;删除partition &lt;code&gt;alter table xxxx drop if exists partiton (yyyymmddhh= 2017011020);&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;添加partition &lt;code&gt;alter table xxxx add if not exists partition (yyyymmddhh= 2017011020);&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这样就可以对新加进来的数据进行搜索了。你可以试一下，如果少了这步操作，在新的Hive table里新加的列的值会全部是NULL。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;步骤很多，但操作还是挺简单的，而且需要细心，不能出错，尤其这里每一步都是线上的操作，一次微小的出错都可能酿成事故。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;找到每个partiton出现脏数据时的offset&lt;/li&gt;
&lt;li&gt;把当前每个partiton的offset设置成出现脏数据时的offset&lt;/li&gt;
&lt;li&gt;清除出错的脏数据&lt;/li&gt;
&lt;li&gt;修改Hive table（如果需要）&lt;/li&gt;
&lt;li&gt;删除并重新添加受影响的partition(如果需要)&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>
