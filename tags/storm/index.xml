<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Storm on Me &amp; Web</title>
    <link>http://lovelock.coding.me/tags/storm/index.xml</link>
    <description>Recent content in Storm on Me &amp; Web</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) 2013-2016 Frost Wong. All rights reserved.</copyright>
    <atom:link href="/tags/storm/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>一个真实Storm应用源码解析</title>
      <link>http://lovelock.coding.me/java/storm-demo-presentation/</link>
      <pubDate>Tue, 11 Oct 2016 16:41:18 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/storm-demo-presentation/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;这里是Storm分享的内容。我自己也是初学者，这里抛砖引玉，希望大家多多指教。为简单起见，本应用用的是Java实现，没有用到Storm的多语言支持和更高层面的Trident Topology。源码详见&lt;a href=&#34;https://github.com/lovelock/storm-demo&#34;&gt;storm-demo&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;理论&#34;&gt;理论&lt;/h2&gt;

&lt;h3 id=&#34;概述&#34;&gt;概述&lt;/h3&gt;

&lt;p&gt;Apache Storm是一个自由并且开源的&lt;strong&gt;分布式实时&lt;/strong&gt;计算系统.它使得像Hadoop做批处理一样做&lt;strong&gt;实时的&lt;/strong&gt;、&lt;strong&gt;无限量&lt;/strong&gt;的&lt;strong&gt;流数据&lt;/strong&gt;处理变得简单可靠.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://storm.apache.org/images/storm-flow.png&#34; alt=&#34;Apache Storm工作流程&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;概念解释&#34;&gt;概念解释&lt;/h3&gt;

&lt;h4 id=&#34;工作原理&#34;&gt;工作原理&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://www.tutorialspoint.com/apache_storm/images/zookeeper_framework.jpg&#34; alt=&#34;Apache Storm组件间关系&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Nimbus&lt;br /&gt;
 Nimbus是Storm集群的&lt;strong&gt;主节点master node&lt;/strong&gt;。Storm集群中除Nimbus节点之外的所有节点叫做&lt;strong&gt;工作节点worker nodes&lt;/strong&gt;。&lt;br /&gt;
 Nimbus负责三项工作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;向worker nodes分发数据&lt;/li&gt;
&lt;li&gt;向worker nodes分配tasks&lt;/li&gt;
&lt;li&gt;监控失败&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Supervisor&lt;br /&gt;
 接受Nimbus的指令的节点叫做Supervisors（监工），它有&lt;strong&gt;多个worker process&lt;/strong&gt;，并控制worker process完成Nimbus分配的tasks&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Worker Process&lt;br /&gt;
 Worker process执行指定Topology的tasks。&lt;strong&gt;worker process自己并不实际执行tasks，而是创建executors并由executors执行指定的task。&lt;/strong&gt;一个worker process可以由多个executor。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Executor&lt;br /&gt;
 Executor是由worker process创建的线程。一个executor执行一个或多个tasks，但只为&lt;strong&gt;一个指定的Spout或者Bolt工作&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Task&lt;br /&gt;
 Task是实际的数据处理工作，所以它可能是一个Spout或者Bolt。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;配套服务&#34;&gt;配套服务&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;ZooKeeper&lt;br /&gt;
&lt;a href=&#34;http://zookeeper.apache.org/&#34;&gt;ZooKeeper&lt;/a&gt;是一个分布式的配置分发服务。Storm和Kafka都是无状态的，它们的工作需要外部服务为其维持状态，如Storm从Kafka中取数据时需要的partition编号和offset偏移量等诸如此类的信息。ZooKeeper会综合分析Spout和Bolt发送来的ack或者fail请求来决定是否更新offset。如下图所示&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww3.sinaimg.cn/large/65e4f1e6jw1f8wd8tm94ij21kw097q5h.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kafka&lt;br /&gt;
&lt;a href=&#34;http://kafka.apache.org/&#34;&gt;Kafka&lt;/a&gt;是一个分布式的消息系统。支持&lt;strong&gt;点对点&lt;/strong&gt;和&lt;strong&gt;发布-订阅&lt;/strong&gt;两种消息模式。在和Storm配合中，充当&lt;strong&gt;数据来源&lt;/strong&gt;的角色。用&lt;a href=&#34;https://github.com/apache/storm/tree/master/external/storm-kafka&#34;&gt;KafkaSpout&lt;/a&gt;和Storm进行组合。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;本文只关注Storm，有关ZooKeeper和Kafka的介绍，可以访问&lt;a href=&#34;http://apache.org/&#34;&gt;官网&lt;/a&gt;、&lt;a href=&#34;http://www.tutorialspoint.com/&#34;&gt;TutorialsPoint&lt;/a&gt;或本博客的其他相关文章。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;拓扑作业&#34;&gt;拓扑作业&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Tuple&lt;br /&gt;
 Tuple是Topology中数据流的传输格式。它是&lt;strong&gt;不可变的键值对组&lt;/strong&gt;。既然是键值对，就需要设置键和值，典型的设置方式如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; // 设置键
 outputFieldsDeclarer.declare(new Fields(&amp;quot;timestamp&amp;quot;, &amp;quot;fieldvalues&amp;quot;));
 // 设置值
 collector.emit(tuple, new Values(timestamp, stringBuilder.toString()));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就会得到一个形如&lt;code&gt;(&amp;quot;timestamp&amp;quot;: timestamp, &amp;quot;fieldvalues&amp;quot;: xxxx&amp;quot;)&lt;/code&gt;这样的Tuple。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Spout&lt;br /&gt;
 Spout是Topology的数据来源，输出的数据以Tuple的形式传入下一个Bolt。具体到本例中，KafkaSpout会把它接收到的数据以类似&lt;code&gt;(0: message)&lt;/code&gt;这样的形式发射(emit)出来。所以，在KafkaSpout下游的Bolt需要这样获取整条数据(其实这里是可配置的)：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; String message = tuple.getString(0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对KafkaSpout而言，它也实现了多个方法，但我们这里只需要了解两个&lt;code&gt;ack&lt;/code&gt;和&lt;code&gt;fail&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww3.sinaimg.cn/large/65e4f1e6jw1f8wdqv4tuqj218y0ji41l.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这两个是回调方法，分别在acker向其发送ack或fail请求时被触发，一般而言，ack方法由于通知Kafka发送下一条数据，fail方法用于通知Kafka重发上一条数据。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Storm中有个特殊的task名叫acker，它们负责跟踪Spout发出的每一个Tuple的Tuple树（因为一个Tuple通过Spout发出了，经过每一个Bolt处理后，会生成一个新的Tuple发送出去）。当acker（框架自启动的task）发现一个Tuple树已经处理完成了，它会发送一个消息给产生这个Tuple的那个task。&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bolt&lt;br /&gt;
 Bolt是真正写处理逻辑的地方，比如在本例中，我们要做以下几件事：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;把message中的每个字段提取出来，&lt;/li&gt;
&lt;li&gt;从message的domain字段中过滤出以&lt;code&gt;.api.ksyun.com&lt;/code&gt;结尾的，其他的舍弃&lt;/li&gt;
&lt;li&gt;把domain字段的值以&lt;code&gt;.&lt;/code&gt;分割，取出index为0的部分，也就是第一段作为service字段&lt;/li&gt;
&lt;li&gt;把service最终输出Tuple的一个field写入输出结果&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一般情况下，要实现一个Bolt有几种方式&lt;/p&gt;

&lt;p&gt;​&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;实现&lt;code&gt;IRichBolt&lt;/code&gt;接口&lt;br /&gt;
  因为这个比较低级，要实现的方法有很多，而其中多数的方法不需要做特殊处理，所以一般会用第二种方式&lt;/li&gt;

&lt;li&gt;&lt;p&gt;集成&lt;code&gt;BaseRichBolt&lt;/code&gt;类&lt;br /&gt;
  这个基类实现了&lt;code&gt;IRichBolt&lt;/code&gt;中定义的几个不常用的方法，让我们只需要关注重点的几个方法即可。在这种方式中，我们需要自己实现三个方法：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;public void prepare(Map map, TopologyContext topologyContext, OutputCollector outputCollector)&lt;/code&gt;&lt;br /&gt;
  这个方法&lt;strong&gt;类似构造函数&lt;/strong&gt;，用来做一些准备工作，通常用于&lt;strong&gt;把上游传来的collector赋值给成员变量&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;public void execute(Tuple tuple)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这是最核心的方法。它负责：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;从上游传来的Tuple中读取感兴趣的字段&lt;/li&gt;
&lt;li&gt;把这些字段做一些处理后产生一组新的字段&lt;/li&gt;
&lt;li&gt;把这些值通过&lt;code&gt;OutputCollector::emit(new Values())&lt;/code&gt;方法发射出去&lt;/li&gt;
&lt;li&gt;向上游发送&lt;code&gt;OutputCollector::ack(Tuple tuple)&lt;/code&gt;或&lt;code&gt;OutputCollector::fail(Tuple tuple)&lt;/code&gt;，以告知上游本次Tuple处理是否成功。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;前面已经说过，Tuple是数据交流的格式，这个方法就是用来定义发送到下游的Tuple的字段名的。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Topology&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://storm.apache.org/releases/0.10.0/images/topology.png&#34; alt=&#34;一个典型的Topology&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上面这张图中有4个Topology，说明了几个问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一个Spout就是一个Topology的入口，从Spout分出几条线就有几个Topology&lt;/li&gt;
&lt;li&gt;一个Topology由一个Spout和若干个Bolt组成&lt;/li&gt;
&lt;li&gt;Topology之间可以共享Spout或者Bolt&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;创建一个Topology的典型过程：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    TopologyBuilder topologyBuilder = new TopologyBuilder();
    topologyBuilder.setSpout(KAFKA_SPOUT_ID, kafkaSpout, 10);
    topologyBuilder.setBolt(CROP_BOLT_ID, new CropBolt(), 10).shuffleGrouping(KAFKA_SPOUT_ID);
    topologyBuilder.setBolt(SPLIT_FIELDS_BOLT_ID, new SplitFieldsBolt(), 10).shuffleGrouping(CROP_BOLT_ID);
    topologyBuilder.setBolt(STORM_HDFS_BOLT_ID, hdfsBolt, 10).fieldsGrouping(SPLIT_FIELDS_BOLT_ID, new Fields(&amp;quot;timestamp&amp;quot;, &amp;quot;fieldvalues&amp;quot;));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的代码可以看到，&lt;code&gt;TopologyBuilder&lt;/code&gt;类通过&lt;code&gt;setSpout()&lt;/code&gt;和&lt;code&gt;setBolt()&lt;/code&gt;两个方法生动的反映了上图的工作流程。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;源码分析&#34;&gt;源码分析&lt;/h2&gt;

&lt;h3 id=&#34;cropbolt-java&#34;&gt;&lt;code&gt;CropBolt.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;主要关注&lt;code&gt;execute&lt;/code&gt;方法，它首先从上游发射来的Tuple中取出第一个字段，也就是整条消息作为一个字符串。根据对字符串的分析，我们知道该字符串是以&lt;code&gt;\t\t&lt;/code&gt;作为字段间分隔符，以&lt;code&gt;:&lt;/code&gt;作为键值分隔符的字符串，所以可以写一个方法来用这种规则解析出消息中的所有字段，并把它放在一个HashMap里。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    private HashMap makeMapOfMessage(String message) {
    String[] fields = message.split(ServerConfig.getFieldSeparator());
    HashMap&amp;lt;String, String&amp;gt; map = new HashMap&amp;lt;&amp;gt;();

    try {
        for (String field : fields) {
            String[] pair = field.split(ServerConfig.getPairSeparator(), 2);
            map.put(pair[0], pair[1]);
        }
    } catch (ArrayIndexOutOfBoundsException e) {
        LOG.warn(&amp;quot;makeMapOfMessage failed {}&amp;quot;, message);
        e.printStackTrace();
    }

    return map;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中&lt;code&gt;ServerConfig&lt;/code&gt;是一个工具类，它提供了简单的API，把处理逻辑和配置信息分离。在本例中我用的分隔符和实际项目并不一样，这个差别只需要在相应的properties配置文件中做修改即可。还需要注意异常处理，这个方法的返回值有可能是null，在调用该方法的地方需要做相应的判断。&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;execute&lt;/code&gt;方法中，从上述方法的返回值取出关心的字段，并按需求解析出需要的&lt;code&gt;service&lt;/code&gt;字段，并通过&lt;code&gt;collector.emit&lt;/code&gt;发送给下游的Bolt。&lt;/p&gt;

&lt;p&gt;这个方法中有三点需要注意：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;没有在&lt;code&gt;try&lt;/code&gt;子句中调用&lt;code&gt;ack&lt;/code&gt;方法&lt;/li&gt;
&lt;li&gt;没有在&lt;code&gt;catch&lt;/code&gt;子句中调用&lt;code&gt;fail&lt;/code&gt;方法&lt;/li&gt;
&lt;li&gt;在&lt;code&gt;finally&lt;/code&gt;子句中调用了&lt;code&gt;ack&lt;/code&gt;方法&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因为我们catch住的这种情况，是只有在输入的数据不满足我们约定要求的情况下才会发生的，比如某些必要的字段不存在等，而这种情况在当前的Topology中是不需要处理的，并且也不需要重试，因此，不需要调用&lt;code&gt;fail&lt;/code&gt;。同时，不管数据是否符合要求，我们都是需要通知Spout&lt;strong&gt;这里的处理已经完成&lt;/strong&gt;这个信息的，所以在&lt;code&gt;finally&lt;/code&gt;中调用&lt;code&gt;ack&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;splitfieldsbolt-java&#34;&gt;&lt;code&gt;SplitFieldsBolt.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;这步的功能很简单，就是把前面传过来的所有字段用一个特定的分隔符连接起来，变成一行数据。只有一个特殊，也就是&lt;code&gt;service&lt;/code&gt;字段，它不是直接取出来的，而是前面的Bolt通过一些处理得到的，所以这是&lt;code&gt;stringBuilder&lt;/code&gt;需要处理的一种特殊情况。&lt;/p&gt;

&lt;p&gt;最后把『时间戳』和『各个字段的值』发射给下游的&lt;code&gt;HdfsBolt&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;hdfsbolt&#34;&gt;&lt;code&gt;HdfsBolt&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;HdfsBolt&lt;/code&gt;是Storm到HDFS的一个中转层，配置一些规则，把Storm输出的数据写入HDFS。其中比较重要的配置有：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;DelimitedRecordFormat&lt;/code&gt; 要写入的字段 在本例中，『时间戳』只是用来划分目录的，所以不需要写入HDFS中&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CountSyncPolicy&lt;/code&gt; 指定当内存中超过多少条数据时cache到磁盘中&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FileSizeRotationPolicy&lt;/code&gt; 指定cache的文件超过多大时将文件写入文件系统，如果该值设置的较大，而数据流量又不太大的情况下，文件通常不会达到设置的值，因为当等待写入的文件未达到限制大小而先达到超时时间时，也会创建一个新的文件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DefaultFileNameFormat&lt;/code&gt; 指定文件写入HDFS中的根目录和文件后缀&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Partitioner&lt;/code&gt; 指定分块规则，在本例中，我们根据日志中&lt;code&gt;time_local&lt;/code&gt;字段划分相应的消息应该写入的HDFS目录，比如&lt;code&gt;31/Aug/2016:13:08:12 +0800&lt;/code&gt;，相应的记录就会写入&lt;code&gt;root/20160831/13&lt;/code&gt;目录中。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FsURL&lt;/code&gt; 当然需要指定正确的&lt;code&gt;HDFS&lt;/code&gt;服务。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;其实我们的KMR对应的Storm 0.10.0是不支持HDFS 的partition的，这里我是把Storm最新版的2.0.0-SNAPSHOT中相应的代码移植过来用的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;logstatisticstopology-java&#34;&gt;&lt;code&gt;LogStatisticsTopology.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;前面讲过，这是拓扑作业的入口，这里指定了一条消息要通过的路径。需要注意的有以下几点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;setSpout&lt;/code&gt;和&lt;code&gt;setBolt&lt;/code&gt;方法中的parallelism_hint(并行度建议)，前面说了，Spout和Bolt在Storm中是以executor的形式存在的，而这个值就是指定executor的数量。但又没有那么绝对，比如在KafkaSpout中，如果指定的Topic在Kafka中有10个partition，但这里的KafkaSpout指定了15个并行度，实际还是只有10个executor有意义，因为剩余的5个在前面10个都正常工作的情况下是分配不到任何数据的，由于ZooKeeper做了中间人，它是知道每个Topic有多少个partition的，所以这里设置多于partition数量的并行度也是不起作用的。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;grouping类型 Storm目前支持4种分组形式。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;随机分组 等量tuples随机分发给执行bolt的所有workers&lt;/li&gt;
&lt;li&gt;字段分组 把指定字段值相同的分配给同一个task,在wordCount应用中比较重要&lt;/li&gt;
&lt;li&gt;广播分组 给每个executor发送一个这个tuple的副本&lt;/li&gt;
&lt;li&gt;全局分组 把所有数据分发给bolt的executor中id最小的&lt;strong&gt;一个&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;无分组   目前基本等同于随机分组，会把tuple交给和它上游同一个线程内的下游bolt，以减少数据传递的开销&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;根据我们的需求，其实是不需要太关心分组的事情。&lt;/p&gt;

&lt;p&gt;关于优化，有几个方面可以考虑：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;考虑到后面需要用Hive分析数据，如果产生很多小的文件，就会产生过多的Map过程，影响性能，可以考虑同一小时的文件交给同一个executor来写，因为每个executor会打开一个hdfs文件，但这样可能会导致并发数过少&lt;/li&gt;
&lt;li&gt;既然这样，可以减少executor的数量，比如现在是10个，可以改成5个，在不触发FileSizeRotationPolicy的情况下，把生成的文件数量减少了一半，也就把Hive查询时Map过程的数量减少了一半&lt;/li&gt;
&lt;li&gt;分析需求，如果没有按照小时分组的需求，可以直接删除这个级别，直接用天作为区分，这样，在不触发FileSizeRotationPolicy的情况下产生的文件数量会变成1/24,相应的Hive查询中Map的过程也会变成1/24.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;本文主要介绍了Storm的工作流程，以及其与Kafka和HDFS的配合来进行日志分析的工作流程，并简单介绍了一些需要注意的点。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>在本地单机部署Hadoop/Storm运行环境</title>
      <link>http://lovelock.coding.me/java/deploy-pseudo-distributed-mode-hadoop/</link>
      <pubDate>Mon, 10 Oct 2016 17:53:14 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/deploy-pseudo-distributed-mode-hadoop/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;由于要在小组内做一个关于Storm的分享，涉及到我负责开发的大数据项目，本着开放的原则，把我做的准备工作记录下来，提前发给可能参会的同事。&lt;br /&gt;
要演示的项目目前为止用到了Apache的多个项目，包括Kafka, Storm, Hadoop(HDFS, Hive), ZooKeeper等，项目刚刚起步，很多基础设施还不完善，比如现在是在本地开发完成之后直接部署到线上环境的，这次演示可不能直接在线上环境做了，故而在本地的台式机上部署了一下&lt;strong&gt;伪集群&lt;/strong&gt;，用来作为演示和以后开发测试用的环境。&lt;/p&gt;

&lt;h2 id=&#34;准备工作&#34;&gt;准备工作&lt;/h2&gt;

&lt;p&gt;说明：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;以下工作全部基于Ubuntu 16.04。用其他的发行版或版本理论上应该都是可行的，可能有些命令需要微调。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;所有需要执行的命令前面都有一个&lt;code&gt;$&lt;/code&gt;，表示的是Bash的命令提示符。&lt;/li&gt;
&lt;li&gt;下载安装包时我使用了速度相对较快的国内镜像，如果你对此有任何异议，可以自行去中心镜像站点下载。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;默认情况下文中提到的所有如StormUI等控制后台访问的路径都是localhost，如果你需要从Linux主机外部访问，需要iptables放行相应的端口。在本文中，用的Web端口有三个，具体如下表：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;服务描述&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;端口号&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Storm UI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8080&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hadoop UI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50070&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hadoop Applications&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8088&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;以Ubuntu为例，需要执行以下命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo ufw allow 8080/tcp
$ sudo ufw allow 50070/tcp
$ sudo ufw allow 8088/tcp
$ sudo ufw reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CentOS/RHEL 7.0以下可能需要直接操作iptables，7.0以上可以使用&lt;code&gt;firewall-cmd&lt;/code&gt;进行类似的操作。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-创建独立的用户并赋予合适的权限&#34;&gt;1. 创建独立的用户并赋予合适的权限&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ sudo useradd hadoop
$ sudo passwd hadoop
$ sudo chsh hadoop
$ sudo mkdir /home/hadoop
$ sudo chown -R hadoop:hadoop /opt/apache
$ sudo chown -R hadoop:hadoop /home/hadoop
$ su - hadoop
$ ssh-keygen
$ cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys
$ chmod 0600 ~/.ssh/authorized_keys
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;FAQ：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;为什么需要chsh并且手动为用户创建家目录？&lt;br /&gt;
不知道为什么在 Ubuntu 环境中执行&lt;code&gt;useradd&lt;/code&gt;命令之后并不会给新建的用户创建家目录和设置shell，可能是为了安全吧，要稍微麻烦一些。&lt;/li&gt;
&lt;li&gt;为什么不给新用户赋予root权限？&lt;br /&gt;
这里是测试环境倒还好，如果你需要搭建生产环境，记住千万不要给hadoop用户赋予root权限，它需要哪些目录的权限就单独赋予即可，它需要运行的端口都是1024以上的，都不需要root权限。如果需要，执行&lt;code&gt;sudo gpasswd -a hadoop sudo&lt;/code&gt;即可。&lt;/li&gt;
&lt;li&gt;为什么要做一个密钥认证？&lt;br /&gt;
这是因为在后续的步骤中会有&lt;strong&gt;从本地用户登录本地用户&lt;/strong&gt;的需求，也就是执行了&lt;code&gt;ssh hadoop@localhost&lt;/code&gt;这个命令，如果不做密钥信任，会需要多次输入密码。&lt;/li&gt;
&lt;li&gt;为什么会有一个&lt;code&gt;/opt/apache&lt;/code&gt;目录？&lt;br /&gt;
往下看。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-下载所需安装包&#34;&gt;1. 下载所需安装包&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;下载Java&lt;br /&gt;
到&lt;a href=&#34;http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html&#34;&gt;Java官网&lt;/a&gt;下载适用于Linux的Java安装包（这里下载了jdk-8u101-linux-x64.tar.gz）。&lt;/li&gt;
&lt;li&gt;下载maven&lt;br /&gt;
点击&lt;a href=&#34;http://mirrors.aliyun.com/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.zip&#34;&gt;阿里云镜像站&lt;/a&gt;下载最新版Maven。&lt;/li&gt;
&lt;li&gt;下载Apache的Storm Hadoop Kafka ZooKeeper&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/storm/apache-storm-0.10.2/apache-storm-0.10.2.tar.gz&#34;&gt;点击下载Storm-0.10.2&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/hadoop/core/hadoop-2.6.4/hadoop-2.6.4.tar.gz&#34;&gt;点击下载Hadoop-2.6.4&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/kafka/0.8.2.2/kafka_2.10-0.8.2.2.tgz&#34;&gt;点击下载Kafka_2.10-0.8.2.2&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz&#34;&gt;点击下载ZooKeeper-3.4.6&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-创建所需目录&#34;&gt;2. 创建所需目录&lt;/h3&gt;

&lt;p&gt;把所有和此项目相关的文件都放在统一的位置。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ sudo mkdir -p /opt/apache/{jdk, storm,hadoop,kafka,zookeeper}&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-解压所有安装包-将相应的安装包放在对应的位置&#34;&gt;3. 解压所有安装包，将相应的安装包放在对应的位置&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mv jdk1.8.0_101/* /opt/jdk/.
$ sudo mv apache-storm-0.10.0/* /opt/apache/storm/.
$ sudo mv hadoop-2.6.4/* /opt/apache/hadoop/.
$ sudo mv kafka_2.10-0.8.2.2/* /opt/apache/kafka/.
$ sudo mv zookeeper-3.4.6/* /opt/apache/zookeeper
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-配置环境变量&#34;&gt;4. 配置环境变量&lt;/h3&gt;

&lt;p&gt;在~/.bashrc中添加下面的片段&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export JAVA_HOME=/opt/jdk
export APACHE_HOME=/opt/apache
export STORM_HOME=$APACHE_HOME/storm
export ZK_HOME=$APACHE_HOME/zookeeper
export KAFKA_HOME=$APACHE_HOME/kafka

export HADOOP_HOME=$APACHE_HOME/hadoop
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_INSTALL=$HADOOP_HOME

export PATH=$PATH:$JAVA_HOME/bin
export PATH=$PATH:$STORM_HOME/bin
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export PATH=$PATH:$ZK_HOME/bin
export PATH=$PATH:$KAFKA_HOME/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后执行&lt;code&gt;$ source ~/.bashrc&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;5-安装java&#34;&gt;5. 安装Java&lt;/h4&gt;

&lt;p&gt;Apache的这些东西都是直接放在对的地方就可以运行的，但Java需要稍微的配置一下，因为可能你的机器上已经装了OpenJDK。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ sudo update-alternatives --install /usr/local/bin/java java /opt/jdk/bin/java 10000&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这时再执行&lt;code&gt;$ java -version&lt;/code&gt;验证一下是否使用的时最新安装的JDK。&lt;/p&gt;

&lt;h2 id=&#34;2-启动服务&#34;&gt;2. 启动服务&lt;/h2&gt;

&lt;h3 id=&#34;1-启动zookeeper&#34;&gt;1. 启动ZooKeeper&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ cp $ZK_HOME/conf/zoo_sample.cfg $ZK_HOME/conf/zoo.cfg
$ zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-启动storm&#34;&gt;2. 启动Storm&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ storm nimbus
$ storm supervisor
$ storm ui
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在可以访问&lt;a href=&#34;http://localhost:8080&#34;&gt;Storm UI&lt;/a&gt;了。&lt;/p&gt;

&lt;h3 id=&#34;3-启动kafka-broker&#34;&gt;3. 启动Kafka Broker&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ cd $KAFKA_HOME
$ bin/kafka-server-start.sh -daemon config/server.properties
$ bin/kafka-topics.sh --list --zookeeper localhost:2181
$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 10 --topic storm-demo-topic
Created topic &amp;quot;storm-demo-topic&amp;quot;.
$ bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic storm-demo-topic
Topic:storm-demo-topic  PartitionCount:10       ReplicationFactor:1     Configs:
        Topic: storm-demo-topic Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 2    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 3    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 4    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 5    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 6    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 7    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 8    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 9    Leader: 0       Replicas: 0     Isr: 0
$ kafka-console-producer.sh --broker-list localhost:9092 --topic storm-demo-topic
$ kafka-console-consumer.sh --zookeeper localhost:2181 --topic storm-demo-topic --from-beginning
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注意前面有些命令仅仅是为了测试kafka broker运行的情况。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;4-启动hadoop-hdfs&#34;&gt;4. 启动Hadoop(HDFS)&lt;/h3&gt;

&lt;h4 id=&#34;1-修改hadoop的配置文件&#34;&gt;1. 修改Hadoop的配置文件&lt;/h4&gt;

&lt;p&gt;在&lt;code&gt;$HADOOP_HOME/etc/hadoop&lt;/code&gt;目录下有5个文件需要修改:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;core-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.default.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;hdfs-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.name.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/hadoop/hadoopinfra/hdfs/namenode&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.data.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/hadoop/hadoopinfra/hdfs/datanode&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;yarn-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;mapred-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;hadoop-env.sh&lt;/code&gt;
把hadoop-env.sh中的${JAVA_HOME}替换成路径,这里是&lt;code&gt;/opt/jdk&lt;/code&gt;，因为貌似会找不到正确的&lt;code&gt;JAVA_HOME&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;2-验证是否安装成功&#34;&gt;2. 验证是否安装成功&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ hadoop namenode -format
$ start-dfs.sh
$ start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行上面三行语句，观察有没有明显的报错信息。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:50070&#34;&gt;检查HadoopUI&lt;/a&gt;运行是否正常。&lt;br /&gt;
&lt;a href=&#34;http://localhost:8088&#34;&gt;检查Hadoop Applications&lt;/a&gt;(我自己取的名字)运行是否正常。&lt;/p&gt;

&lt;p&gt;至此已经搭建了一个可以运行的hadoop环境，可以移步这里查看关于Storm入门分享详情。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
