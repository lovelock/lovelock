<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Me &amp; Web on Me &amp; Web</title>
    <link>http://lovelock.coding.me/index.xml</link>
    <description>Recent content in Me &amp; Web on Me &amp; Web</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) 2013-2016 Frost Wong. All rights reserved.</copyright>
    <lastBuildDate>Thu, 09 Feb 2017 10:31:45 +0800</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>set docker image mirror</title>
      <link>http://lovelock.coding.me/linux/set-docker-image-mirror/</link>
      <pubDate>Thu, 09 Feb 2017 10:31:45 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/linux/set-docker-image-mirror/</guid>
      <description>

&lt;p&gt;今天想着复习一下Nginx的反向代理，又懒得再配置多台机器了，正好手里有已经安装了Docker的台式机，于是就想用Nginx的Docker image来做实验了。&lt;/p&gt;

&lt;p&gt;由于众所周知的原因，我们在圈内访问&lt;a href=&#34;https://hub.docker.com/&#34;&gt;docker官方镜像&lt;/a&gt;是很慢的，好在包括&lt;a href=&#34;https://www.daocloud.io/&#34;&gt;DaoCloud&lt;/a&gt;和&lt;a href=&#34;https://dev.aliyun.com/search.html&#34;&gt;阿里云&lt;/a&gt;为我们提供了而苏稳定的镜像服务。废话不多说，下面总结了一下使用国内镜像加速Docker镜像下载的方式。&lt;/p&gt;

&lt;h2 id=&#34;获取专属的加速地址&#34;&gt;获取专属的加速地址&lt;/h2&gt;

&lt;p&gt;上面提到的两个镜像服务提供者都是需要注册才能用的，注册后你会拿到一个形如&lt;code&gt;http://78a2f85b.m.daocloud.io&lt;/code&gt;的地址（阿里的我没有尝试，应该是类似的），这就是专属你的加速地址了。说是专属，但其实并没有身份认证，任何人都是可以直接用的，除非你要把自己创建的镜像提交到DaoCloud才会做身份认证。&lt;/p&gt;

&lt;h2 id=&#34;本地配置&#34;&gt;本地配置&lt;/h2&gt;

&lt;p&gt;DaoCloud是搞了一个配置脚本来为我们自动搞定这个工作的，怎奈不知道为什么这个脚本一直没有更新，对于用systemd的发行版来说已经不适用了。对于使用systemd的发行版，有以下两种方法实现加速：&lt;/p&gt;

&lt;h3 id=&#34;1-修改service文件&#34;&gt;1. 修改service文件&lt;/h3&gt;

&lt;p&gt;安装docker后，会在&lt;code&gt;/lib/systemd/system&lt;/code&gt;目录下生成一个&lt;code&gt;docker.service&lt;/code&gt;的文件，对于Ubuntu 16.04内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target docker.socket
Requires=docker.socket

[Service]
Type=notify
# the default is not to use systemd for cgroups because the delegate issues still
# exists and systemd currently does not support the cgroup feature set required
# for containers run by docker
ExecStart=/usr/bin/dockerd -H fd://
ExecReload=/bin/kill -s HUP $MAINPID
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0
# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes
# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;找到其中的&lt;code&gt;ExecStart=/usr/bin/dockerd -H fd://&lt;/code&gt;行，改成&lt;code&gt;ExecStart=/usr/bin/dockerd -H fd:// --registry-mirror=http://78a2f85b.m.daocloud.io&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;因为你手动修改了service文件，当然要执行以下命令了:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo systemctl daemon-reload
sudo systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果还想查看一下docker的运行状态，就再执行一下&lt;code&gt;sudo systemctl status docker&lt;/code&gt;即可。&lt;/p&gt;

&lt;h3 id=&#34;2-修改daemon-json文件&#34;&gt;2. 修改daemon.json文件&lt;/h3&gt;

&lt;p&gt;默认是没有这个文件的，可以自行创建：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo vim /etc/docker/daemon.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;文件内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;registry-mirrors&amp;quot;: [
            &amp;quot;http://78a2f85b.m.daocloud.io&amp;quot;
        ],
    &amp;quot;insecure-registries&amp;quot;: []
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后执行&lt;code&gt;sudo systemctl restart docker&lt;/code&gt;。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;执行上面两种方法中的一种，即可享受国内良心厂商带给我们的加速服务了。注意我在本文中没有区分一个说法：镜像。有的地方镜像指的是Docker 的Image，有的地方是指加速服务的mirrors，请读者自行区分。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>关于PHP接口特性的一个发现</title>
      <link>http://lovelock.coding.me/php/about-php-interface/</link>
      <pubDate>Thu, 19 Jan 2017 15:21:43 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/php/about-php-interface/</guid>
      <description>&lt;p&gt;这两天看一本PHP的进阶书，发现了一些之前没有注意的特性。比如PHP接口的设计方式和它对实现该接口的类的约束就和通常的语言(比如Java）不一样。&lt;/p&gt;

&lt;p&gt;举一个简单的例子，要写一个配置管理类，这个类为了适配不同的配置文件格式，比如&lt;code&gt;ini&lt;/code&gt;,&lt;code&gt;yaml&lt;/code&gt;等，就需要一个接口来约束这些具体的实现。代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;&amp;lt;?php
  
  interface ConfigInterface
  {
    public function get($name);
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;&amp;lt;?php
  class IniConfig implements ConfigInterface
  {
    public function get($name)
      {
        xxxxx;
      }
  
  	public function fetch($name)
      {
        xxxxxx;
      }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;&amp;lt;?php
  class YamlConfig implements ConfigInterface
  {
    public function get($name)
      {
        xxxxxx;
      }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;&amp;lt;?php
  function check(ConfigInterface $config)
  {
    $config-&amp;gt;fetch(&#39;foo&#39;);
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你按类似上面的结构写完执行你就会发现一个很神奇的特性，这段代码竟然是可以执行的（忽略我为了偷懒省略了具体实现吧）。&lt;/p&gt;

&lt;p&gt;但是仔细想想，我在方法&lt;code&gt;check&lt;/code&gt;里面用接口解耦的目的是什么呢？就是为了接受不同实现，而如果这些实现自己的独有的方法在这里都可以调用，这个约束的存在还有什么意义呢？所以，我理解的PHP的接口的作用仅仅限于两点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;规定每个实现一定要实现相应的方法&lt;/li&gt;
&lt;li&gt;方便IDE进行自动提示和补全&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;也就是说，PHP的接口更多意义上是一个&lt;strong&gt;约定&lt;/strong&gt;，而不是&lt;strong&gt;规定&lt;/strong&gt;。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>创建变量(PHP5.x扩展)</title>
      <link>http://lovelock.coding.me/php/internals/create-variables/</link>
      <pubDate>Wed, 18 Jan 2017 18:08:53 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/php/internals/create-variables/</guid>
      <description>

&lt;p&gt;这里记录一下如何在PHP5的扩展中创建变量，包括局部变量和全局变量。&lt;/p&gt;

&lt;h2 id=&#34;必备知识&#34;&gt;必备知识&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;PHP内部有符号表的概念，其中局部变量存放在指针&lt;code&gt;active_symbol_table&lt;/code&gt;中，而全局变量存放在非指针（真实值）&lt;code&gt;symbol_table&lt;/code&gt;中。&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;MAKE_STD_ZVAL&lt;/code&gt;宏创建变量。&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;ZVAL_xxxx&lt;/code&gt;宏为创建的变量赋值，当然也可以不赋值，而只是声明。&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;ZEND_SET_SYMBOL&lt;/code&gt;宏设置变量设置成全局还是局部。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-局部变量&#34;&gt;1. 局部变量&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;zval *new_var;
MAKE_STD_ZVAL(new_var);
ZVAL_LONG(new_var, 2000);
ZEND_SET_SYMBOL(EG(active_symbol_table), &amp;quot;aVar&amp;quot;, new_var);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的代码会创建一个名为&lt;code&gt;$aVar&lt;/code&gt;的&lt;strong&gt;局部变量&lt;/strong&gt;，它的值是2000。&lt;/p&gt;

&lt;h3 id=&#34;2-全局变量&#34;&gt;2. 全局变量&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;zval *new_var;
MAKE_STD_ZVAL(new_var);
ZVAL_LONG(new_var, 2000);
ZEND_SET_SYMBOL(&amp;amp;EG(symbol_table), &amp;quot;aVar&amp;quot;, new_var);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的代码会创建一个名为&lt;code&gt;$aVar&lt;/code&gt;的全局变量，它的值是2000。在PHP中没有什么是一个宏实现不了的，如果有，那就两个————所以，你看创建一个全局变量要那么多字符，干脆再包装一个宏算了，于是就可以把最后一行替换成&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;ZEND_SET_GLOBAL_VAR(&amp;quot;aVar&amp;quot;, new_var);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ww3.sinaimg.cn/large/006tNbRwly1fbuyfmvy90j30z403q0tk.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>没有参数的函数（区别于类的方法）</title>
      <link>http://lovelock.coding.me/php/internals/a-function-without-arguments/</link>
      <pubDate>Tue, 17 Jan 2017 15:48:42 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/php/internals/a-function-without-arguments/</guid>
      <description>&lt;p&gt;距离上一次写PHP扩展相关的内容已经很久很久了，这两天又想着写一个真正意义上的扩展了，所以又要重新学习了。&lt;/p&gt;

&lt;p&gt;先从写一个最简单的函数说起，从我现在的理解来说这个函数是全局的。比如我要实现一个最简单的&lt;code&gt;helloworld&lt;/code&gt;函数。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;这里说一个小插曲，最后不要用dash(-)作为扩展名字的一部分，会出现乱七八糟的麻烦。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如图所示，&lt;img src=&#34;https://ww4.sinaimg.cn/large/006tNc79ly1fbtoytl1g7j31ks0jswjf.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;需要注意的是&lt;code&gt;PHP_FUNCTION(helloworld)&lt;/code&gt;这段需要放在&lt;code&gt;const&lt;/code&gt;这段前面，因为相当于前面是定义了&lt;code&gt;helloworld&lt;/code&gt;这个函数名，后面是把它注册到『可用函数列表』中，如果都没有定义，怎么注册呢，对吧？&lt;/p&gt;

&lt;p&gt;至于编译的细节，请看我之前的文章。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>清理HDFS的脏数据</title>
      <link>http://lovelock.coding.me/bigdata/cleanup-dirty-data-in-hdfs/</link>
      <pubDate>Wed, 11 Jan 2017 14:27:46 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/bigdata/cleanup-dirty-data-in-hdfs/</guid>
      <description>

&lt;p&gt;周末同事在群里用由我维护的Hive里查数据，发现完全对不上了，我简单查了一下，发现是预计下一期上的日志格式提前上了，而我的Topology还没有跟上，导致数据字段完全错乱。我马上停掉相应的Topology，避免产生更多的脏数据，周一到公司在给新版的Topology做了严格测试准备上线。&lt;/p&gt;

&lt;p&gt;接下来面对的就是怎么把脏数据清除掉，把被错误处理的数据重新处理一遍，并且后续的数据不受影响。&lt;/p&gt;

&lt;h2 id=&#34;步骤&#34;&gt;步骤&lt;/h2&gt;

&lt;h3 id=&#34;1-找到脏数据的offset-最好向前移动一些-以保证所有脏数据都能被处理&#34;&gt;1. 找到脏数据的offset，最好向前移动一些，以保证所有脏数据都能被处理&lt;/h3&gt;

&lt;p&gt;在数据处理节点（我们这里是core节点）上找到kafka-broker的安装目录，执行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh bin/kafka-simple-consumer-shell.sh --topic online_userbehaviortrack --offset -2 --broker-list 10.68.160.52:6667,10.68.160.53:6667,10.68.160.54:6667 --print-offsets --partition 9
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的命令会输出类似&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;next offset = 3381
{&amp;quot;message&amp;quot;:&amp;quot;2017-01-11T14:40:55+0800`1484116855552`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;的结果，从中可以很详细的看到每条message的offset，结合管道和less就可以根据时间找到出现脏数据的offset，然后确定一个时间点，比如下午2点，在每个partition中分别找到2点之前的最后一个offset，找个地方记下来。&lt;/p&gt;

&lt;h3 id=&#34;2-到zookeeper中找到每个对应的partiton-用步骤1的offset结果覆盖partiton中的offset字段&#34;&gt;2. 到ZooKeeper中找到每个对应的Partiton，用步骤1的offset结果覆盖Partiton中的offset字段&lt;/h3&gt;

&lt;p&gt;因为我的KafkaSpout是这么写的&lt;code&gt;SpoutConfig kafkaSpoutConfig = new SpoutConfig(brokerHosts, topic, &amp;quot;/&amp;quot; + topic, client_id);&lt;/code&gt;，所以在我的ZooKeeper中我应该去&lt;code&gt;/mytopic/mytopologyname/&lt;/code&gt;中找到所有的partiton，这个需要根据你自己的代码来确定。&lt;/p&gt;

&lt;p&gt;以partition_9为例，结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[zk: localhost:2181(CONNECTED) 2] get /mytopic/fe_analyze/partition_9
{&amp;quot;topology&amp;quot;:{&amp;quot;id&amp;quot;:&amp;quot;c75ac929-1a8e-4958-a637-ead9a95436ca&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;mytopologyname&amp;quot;},&amp;quot;offset&amp;quot;:3384,&amp;quot;partition&amp;quot;:9,&amp;quot;broker&amp;quot;:{&amp;quot;host&amp;quot;:&amp;quot;kmr-9a387314-gn-6bb9c438-core-1-002.ksc.com&amp;quot;,&amp;quot;port&amp;quot;:6667},&amp;quot;topic&amp;quot;:&amp;quot;mytopic&amp;quot;}
cZxid = 0x1017bd837
ctime = Mon Dec 26 15:06:19 CST 2016
mZxid = 0x101cbb4ec
mtime = Wed Jan 11 14:49:40 CST 2017
pZxid = 0x1017bd837
cversion = 0
dataVersion = 2173
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 223
numChildren = 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因为我们只需要设置partiton的offset值，而它接收一个JSON类型的值，所以就需要这样&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[zk: localhost:2181(CONNECTED) 4] set /mytopic/mytopologyname/partition_9 {&amp;quot;topology&amp;quot;:{&amp;quot;id&amp;quot;:&amp;quot;c75ac929-1a8e-4958-a637-ead9a95436ca&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;fe_analyze&amp;quot;},&amp;quot;offset&amp;quot;:3386,&amp;quot;partition&amp;quot;:9,&amp;quot;broker&amp;quot;:{&amp;quot;host&amp;quot;:&amp;quot;kmr-9a387314-gn-6bb9c438-core-1-002.ksc.com&amp;quot;,&amp;quot;port&amp;quot;:6667},&amp;quot;topic&amp;quot;:&amp;quot;mytopic&amp;quot;}
cZxid = 0x1017bd837
ctime = Mon Dec 26 15:06:19 CST 2016
mZxid = 0x101cbba18
mtime = Wed Jan 11 14:54:29 CST 2017
pZxid = 0x1017bd837
cversion = 0
dataVersion = 2176
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 223
numChildren = 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;把其中的offset的值替换成在步骤1中拿到的partiton 9的offset值。&lt;/p&gt;

&lt;h3 id=&#34;3-写脚本删除hdfs中对应topology出现脏数据以后的所有数据&#34;&gt;3. 写脚本删除HDFS中对应Topology出现脏数据以后的所有数据&lt;/h3&gt;

&lt;p&gt;我的设计是每天分成24个partition，类似(yyyymmddhh=2017011010)这种，所以就可以写个类似这样的脚本：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/usr/bin/env bash

DAY=$(date -d &amp;quot;-1 day&amp;quot; +%Y%m%d)

for HH in {00..23}
do
    hdfs dfs -rm -r -f /path/to/topology/yyyymmddhh=${DAY}${HH}
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个脚本可以删除前一天的所有24个partiton的数据。&lt;/p&gt;

&lt;h3 id=&#34;4-如果新的topology对应的hive-table也有变化-需要先修改hive的表结构&#34;&gt;4. 如果新的Topology对应的Hive table也有变化，需要先修改Hive的表结构&lt;/h3&gt;

&lt;p&gt;Hive表结构的修改和MySQL的差不多，不过还是有些差别：比如新添加的列只能放在所有真实列的最后，partiton伪列的前面。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;alter table xxxx add columns (string coln, string colm);&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;注意是&lt;strong&gt;&lt;code&gt;columns&lt;/code&gt;&lt;/strong&gt;而不是&lt;code&gt;column&lt;/code&gt;。而且也不能指定after哪个column。&lt;/p&gt;

&lt;h3 id=&#34;5-重新添加所有受影响的partiton到hive-table&#34;&gt;5. 重新添加所有受影响的partiton到Hive table&lt;/h3&gt;

&lt;p&gt;因为我们这里用的是external table（当我提到HDFS的时候你就应该知道了），所以所有新数据对应的partiton都应该删除后重新添加，以yyyymmddhh=2017011020为例，&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;删除partition &lt;code&gt;alter table xxxx drop if exists partiton (yyyymmddhh= 2017011020);&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;添加partition &lt;code&gt;alter table xxxx add if not exists partition (yyyymmddhh= 2017011020);&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这样就可以对新加进来的数据进行搜索了。你可以试一下，如果少了这步操作，在新的Hive table里新加的列的值会全部是NULL。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;步骤很多，但操作还是挺简单的，而且需要细心，不能出错，尤其这里每一步都是线上的操作，一次微小的出错都可能酿成事故。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;找到每个partiton出现脏数据时的offset&lt;/li&gt;
&lt;li&gt;把当前每个partiton的offset设置成出现脏数据时的offset&lt;/li&gt;
&lt;li&gt;清除出错的脏数据&lt;/li&gt;
&lt;li&gt;修改Hive table（如果需要）&lt;/li&gt;
&lt;li&gt;删除并重新添加受影响的partition(如果需要)&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>不用root修改一加三的DPI</title>
      <link>http://lovelock.coding.me/fxxkmyphone/change-dpi-of-oneplus3/</link>
      <pubDate>Tue, 13 Dec 2016 15:25:03 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/fxxkmyphone/change-dpi-of-oneplus3/</guid>
      <description>&lt;p&gt;之前也听说过有修改DPI的，但不知道修改了会有什么变化。后来直接升级了7.0（官方的OxygenOS OpenBeta version 4.0)，稳定性不行，耗电也非常大。忍了几天实在忍不了，于是乎就刷回目前使用最稳定的稳定版3.2.8了。&lt;/p&gt;

&lt;p&gt;但在用7.0期间，最吸引我的一个特性还是让我怀念不已，就是修改“显示大小”，这就是包装过的修改DPI功能了。但那是7.0及以上才标配的功能，为了解决厂商调整的DPI不符合用户习惯的问题。当然现在这个问题在审美不是一般差劲的一加ROM上是很大的问题了，我简直没有见过字体那么大的手机，但直接修改字体大小其实没什么用的，因为包括列表在内的一些组件的高度和宽度是没有变的，修改字体大小只是让字体在屏幕上显得更小了。而且我还不想解锁，不想root。于是就找到了下面的方法。&lt;/p&gt;

&lt;p&gt;首先开启“开发者选项”。
执行 &lt;code&gt;adb shell wm density 400 &amp;amp;&amp;amp; adb reboot&lt;/code&gt; 其实就够了，不过如果你想直到默认的是多少，我可以告诉你是480，简直太大了。我觉得400是一个比较合理的大小。具体多少你可以自己调整，200-600之间都是可以的，不过200太小了。&lt;/p&gt;

&lt;p&gt;好久没有更新博客了，发现自己好啰嗦啊。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;更新：现在升级了官方的氢3.0 测试版，用了原生的修改DPI功能，相当稳定了，已经快一个月没有刷机了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>用Bash编写漂亮的命令行程序</title>
      <link>http://lovelock.coding.me/linux/handle-with-bash-options/</link>
      <pubDate>Fri, 14 Oct 2016 15:40:58 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/linux/handle-with-bash-options/</guid>
      <description>

&lt;p&gt;我学着写这篇是因为前面写了一个&lt;a href=&#34;http://unixera.com/virtualization/create-a-virtual-machine-with-vboxmanage/&#34;&gt;使用VBoxManage创建虚拟机&lt;/a&gt;，后来我发现这个过程太繁琐，就写了一个脚本，但脚本里面写死太多东西就没有了灵活性，所以就需要支持各种选项和参数。而因为这些命令都是很直观的命令，用Shell脚本就已经很完美的实现了这些功能。&lt;/p&gt;

&lt;p&gt;代码可以在&lt;a href=&#34;https://github.com/lovelock/bash_opts&#34;&gt;这里&lt;/a&gt;下载。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;本文基于&lt;a href=&#34;http://stackoverflow.com/questions/192249/how-do-i-parse-command-line-arguments-in-bash&#34;&gt;StackOverFlow&lt;/a&gt;上的这篇答案。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;首先要知道几个内建变量&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;内建变量&lt;/th&gt;
&lt;th&gt;意义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;执行的脚本文件名&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$1/$2&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;这些带数字（&amp;gt;0）的表示执行脚本后面对应的第N个参数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$#&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;脚本执行时的参数个数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$@&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;所有参数作为一个类似数组的结构&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$*&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;和&lt;code&gt;$@&lt;/code&gt;对比，前面的是一个数组结构，这个是用空格分开的多个变量&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$-&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;当前脚本执行时的附加参数，比如&lt;code&gt;-x&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$_&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;最近的参数（或者当前脚本执行时所在的目录）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$IFS&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;输入字段分隔符，一般是空格&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$!&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;最近的后台执行的命令，这个很常用，在vim中按Ctrl-z会把vim放在后台，在同样的终端中按&lt;code&gt;%!&lt;/code&gt;就会把他切回到前台&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$$&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;当前脚本的pid（进程号）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$?&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;脚本执行后的返回值，一般0代表成功，这个0就是我们用C写程序时&lt;code&gt;main&lt;/code&gt;方法中最后的&lt;code&gt;return 0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;使用空格分隔选项和相应的参数&#34;&gt;使用空格分隔选项和相应的参数&lt;/h2&gt;

&lt;p&gt;用法: &lt;code&gt;bash script.sh -e .php --path .&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/usr/bin/env bash

while [[ $# -gt 1 ]]
do
    KEY=$1

    case $KEY in
        -e|--extension)
            EXTENSION=$2
            shift
            ;;
        -s|--search-path)
            SEARCHPATH=$2
            shift
            ;;
        *)
            ;;
    esac
    shift


done

echo FILE_EXTENSION=${EXTENSION}
echo SEARCH_PATH=${SEARCHPATH}
echo &amp;quot;Number files in ${SEARCH_PATH} with ${EXTENSION}:&amp;quot; $(ls -1 &amp;quot;${SEARCHPATH}&amp;quot;/*.&amp;quot;${EXTENSION}&amp;quot; | wc -l)

if [[ -n $1 ]]; then
    echo &amp;quot;Last line of file specified as non-opt/last argument:&amp;quot;
    tail -1 $1
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该脚本接收两个参数，可以用&lt;strong&gt;长参数(&amp;ndash;extension)&lt;/strong&gt;也可以用&lt;strong&gt;短参数(-e)&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;示例： &lt;code&gt;$ bash space.sh -e py --search-path .&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;使用等号分隔选项和参数&#34;&gt;使用等号分隔选项和参数&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/usr/bin/env bash

for i in $@
do
    case $i in
        -e=*|--extension=*)
            EXTENSION=&amp;quot;${i#*=}&amp;quot;
            shift # past argument=value
            ;;
        -s=*|--searchpath=*)
            SEARCHPATH=&amp;quot;${i#*=}&amp;quot;
            shift # past argument=value
            ;;
        *)
            # unknown option
            ;;
    esac
done

echo &amp;quot;FILE EXTENSION  = ${EXTENSION}&amp;quot;
echo &amp;quot;SEARCH PATH     = ${SEARCHPATH}&amp;quot;
echo &amp;quot;Number files in SEARCH PATH with EXTENSION:&amp;quot; $(ls -1 &amp;quot;${SEARCHPATH}&amp;quot;/*.&amp;quot;${EXTENSION}&amp;quot; | wc -l)

if [[ -n $1 ]]; then
    echo &amp;quot;Last line of file specified as non-opt/last argument:&amp;quot;
    tail -1 $1
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该脚本接收两个参数，可以用&lt;strong&gt;长参数(&amp;ndash;extension)&lt;/strong&gt;也可以用&lt;strong&gt;短参数(-e)&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;示例： &lt;code&gt;$ bash space.sh -e=php --search-path=.&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;使用-getops&#34;&gt;使用&lt;code&gt;getops&lt;/code&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/usr/bin/env bash

# A POSIX variable
OPTIND=1         # Reset in case getopts has been used previously in the shell.

# Initialize our own variables:
EXTENSION=&amp;quot;&amp;quot;
VERBOSE=&amp;quot;-1&amp;quot;

while getopts &amp;quot;h?ve:&amp;quot; opt; do
    case &amp;quot;${opt}&amp;quot; in
        h|\?)
            show_help
            exit 0
            ;;
        v)  VERBOSE=&amp;quot;-l&amp;quot;
            ;;
        e)  EXTENSION=$OPTARG
            ;;
    esac
done

shift $((OPTIND-1))

[ &amp;quot;$1&amp;quot; = &amp;quot;--&amp;quot; ] &amp;amp;&amp;amp; shift

ls ${VERBOSE} *.${EXTENSION}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这种方式只能使用短参数不支持长参数，其中&lt;code&gt;${OPTARG}&lt;/code&gt;表示对应的这条选项的值。&lt;strong&gt;如果该选项后面会带参数，就要在其后面带&lt;code&gt;:&lt;/code&gt;&lt;/strong&gt;，比如在本例中，&lt;code&gt;-e&lt;/code&gt;选项后面需要带参数，那么&lt;code&gt;while getopts &amp;quot;h?ve:&amp;quot; opt; do&lt;/code&gt;这行&lt;code&gt;e&lt;/code&gt;的后面就有一个冒号了，不然你的在代码中是无法取到参数的。&lt;/p&gt;

&lt;p&gt;示例： &lt;code&gt;bash getopts.sh -v -e php&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;关于getopts的更多内容可以使用&lt;code&gt;help getopts&lt;/code&gt;查看。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用VBoxManage创建虚拟机</title>
      <link>http://lovelock.coding.me/virtualization/create-a-virtual-machine-with-vboxmanage/</link>
      <pubDate>Thu, 13 Oct 2016 16:35:22 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/virtualization/create-a-virtual-machine-with-vboxmanage/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;最近没有产品需求，就深入的研究一下大数据吧，第一步先要搭建一个集群，前面已经写了一篇关于搭建“伪集群”的文章，还是希望更完整的理解这套东西，还是弄一套真正的集群吧。但是没有机器，就只能拿本地的台式机搞起来了。&lt;/p&gt;

&lt;p&gt;本文主要介绍了如何使用VirtualBox命令行工具VBoxManage创建和维护虚拟机。官方文档中说到VBoxManage的功能是比GUI的VirtualBox要更完整的，但其实我也用不到那么完整的功能，我能想到的主要有以下几点，参照官方文档来逐个完成。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;创建一个虚拟机&lt;/li&gt;
&lt;li&gt;给虚拟机配置网络、CPU核心、内存、磁盘驱动器&lt;/li&gt;
&lt;li&gt;复制（clone）虚拟机&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我使用的环境如下：
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/machine.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;##
&amp;gt; 看到这张图片，我想说一句关于字体的，Windows下绝对是Consolas最耐看；Linux下SourceCodePro最好看；Mac下命令行用Monaco，但IDE里面用Monaco最觉得不能认真写代码了，太花了，还是SourceCodePro比较正常一点，呼呼&lt;/p&gt;

&lt;p&gt;下面开搞吧。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一定要确认你的VirtualBox安装了Extension Pack， 如果没有马上根据你的发行版或者去官网下载之后安装，否则无法远程连接虚拟机。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;创建虚拟机&#34;&gt;创建虚拟机&lt;/h2&gt;

&lt;h3 id=&#34;知识&#34;&gt;知识&lt;/h3&gt;

&lt;h4 id=&#34;1-vboxmanage-createmedium&#34;&gt;1. &lt;code&gt;VBoxManage createmedium&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;首先要创建一块磁盘。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;--filename &amp;lt;name&amp;gt;&lt;/code&gt; 创建的设备的名字&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--format VDI|VMDK|VHD&lt;/code&gt; 创建的设备的格式，默认是vdi，当年我做云主机运维的时候还测试过各种虚拟化磁盘格式的性能，vdi的性能是所有可选项里面最快的，值得信赖&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--size &amp;lt;megabytes&amp;gt;&lt;/code&gt; 创建的磁盘的大小，以M为单位&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;注意这个命令创建的磁盘是位于你当前所在的目录的，所以为了避免后面的问题，你最好在你想放在的位置执行这个命令。&lt;/p&gt;

&lt;h4 id=&#34;2-vboxmanage-createvm&#34;&gt;2. &lt;code&gt;VBoxManage createvm&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;然后创建一个虚拟机。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;--name &amp;lt;name&amp;gt;&lt;/code&gt; 指定虚拟机的名字，还会在&lt;code&gt;~/.config/VirtualBox/Machines&lt;/code&gt;目录下创建同名的xml文件，如果该虚拟机被重命名，该xml文件也会被自动重命名。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--basefolder &amp;lt;path&amp;gt;&lt;/code&gt; 指定上述的Machines目录，如果指定了这个目录，新创建时还是会在这个目录下产生xml文件，但当虚拟机被重命名时，该xml不会被重命名。所以这里我觉得还是不要改为好，虽然通常也不会去重命名虚拟机。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--groups &amp;lt;group&amp;gt;&lt;/code&gt; 指定虚拟机组，总是从&lt;code&gt;/&lt;/code&gt;开始，可以嵌套，默认是&lt;code&gt;/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--ostype &amp;lt;ostype&amp;gt;&lt;/code&gt; 指定虚拟机的操作系统类型，具体支持的操作系统类型可以使用&lt;code&gt;VBoxManage list ostypes&lt;/code&gt;来查看。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--uuid &amp;lt;uuid&amp;gt;&lt;/code&gt; 指定虚拟机的UUID，这个id在宿主机的命名空间内必须是唯一的，如果指定了虚拟机组，则在组内必须是唯一的，如果不指定，会自动生成，所以这个其实也每必要指定。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;默认情况下，这个命令只会创建一个xml文件，而并不会把虚拟机注册到系统中，可以使用&lt;code&gt;--register&lt;/code&gt;选项或者单独执行&lt;code&gt;VBoxManage register &amp;lt;uuid&amp;gt;&lt;/code&gt;来执行注册。&lt;/p&gt;

&lt;h4 id=&#34;3-vboxmanage-storagectl&#34;&gt;3. &lt;code&gt;VBoxManage storagectl&lt;/code&gt;&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;uuid|vmname&amp;gt;&lt;/code&gt; 指定要操作的虚拟机，可以使用前面创建时指定的名字，或者自动生成的uuid&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--name &amp;lt;name&amp;gt;&lt;/code&gt; 要创建的控制器的名字&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--controller&lt;/code&gt; 控制器，这个我也不太懂，一般电脑上是ACHI，这里就选IntelAHCI吧&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--add&lt;/code&gt; 添加的控制器类型，因为我们要创建的是磁盘驱动器，所以选择sata&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;这里其实是瞎说的，我也不太懂电脑硬件，这些概念不了解，就照着熟悉的来吧。需要创建两种类型的设备控制器，一个是磁盘控制器，用来管理硬盘，一个是光驱，用来管理ISO文件。这个很容易理解，这一步是创建控制器，而而这控制的东西，磁盘是前面创建的，iso是先前下载好的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;4-vboxmanage-storageattach&#34;&gt;4. &lt;code&gt;VBoxManage storageattach&lt;/code&gt;&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;uuid|vmname&amp;gt;&lt;/code&gt; 指定要操作的虚拟机，可以使用前面创建时指定的名字，或者自动生成的uuid&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--storagectl &amp;lt;name&amp;gt;&lt;/code&gt; 这就是上面那个&lt;code&gt;storagectl&lt;/code&gt;命令时的&lt;code&gt;--name&lt;/code&gt;选项指定的参数了&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--port&lt;/code&gt; 端口号&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--device&lt;/code&gt; 设备号&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--type&lt;/code&gt; 设备类型&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--medium&lt;/code&gt; 指定创建磁盘文件，即vdi文件&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;把创建的磁盘驱动器和虚拟机、磁盘连接起来。&lt;/p&gt;

&lt;h4 id=&#34;5-vboxmanage-list-hdds&#34;&gt;5. &lt;code&gt;VBoxManage list hdds&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;这时就可以查看注册过的磁盘了。&lt;/p&gt;

&lt;h3 id=&#34;操作&#34;&gt;操作&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;// 创建磁盘
$ VBoxManage createmedium disk --filename CentOS7.vdi --size 50000
0%...10%...20%...30%...40%...50%...60%...70%...80%...90%...100%
Medium created. UUID: 1cc3b870-7180-4eea-8263-f82a783d1478

// 创建虚拟机配置
$ cd ~/cluster
$ VBoxManage createvm --name CentOS7 --ostype RedHat_64 --register
Virtual machine &#39;CentOS7&#39; is created and registered.
UUID: 4afd6d6d-9cee-4efe-89a6-b752644711f0
Settings file: &#39;/home/hadoop/VirtualBox VMs/CentOS7/CentOS7.vbox&#39;

// 创建磁盘控制器
$ VBoxManage storagectl CentOS7 --add sata --controller IntelAHCI --name &amp;quot;SATA Controller&amp;quot;

// 绑定磁盘控制器
$ VBoxManage storageattach CentOS7 --storagectl &amp;quot;SATA Controller&amp;quot; --port 0 --device 0 --type hdd --medium CentOS7.vdi

// 创建光盘驱动器
$ VBoxManage storagectl CentOS7 --name &amp;quot;IDE Controller&amp;quot; --add ide

// 绑定光盘控制器
$ VBoxManage storageattach CentOS7 --storagectl &amp;quot;IDE Controller&amp;quot; --port 0 --device 0 --type dvddrive --medium ~/Downloads/CentOS-7-x86_64-Minimal-1511.iso

// 设置网络连接方式为桥接
$ VBoxManage modifyvm CentOS7 --nic1 bridged --bridgeadapter1 eno1 --vrde on --vrdeaddress 0.0.0.0 --vrdeport 5010 --memory 1024 --cpus 1

$ VBoxManage startvm CentOS7 --type=headless

&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注意：在我的操作系统下，执行createvm会在~/VirtualBox VMs/目录下生成&lt;code&gt;CentOS7.vbox&lt;/code&gt;文件，其实就是一个xml文件。而所谓的注册操作，就是在&lt;code&gt;~/.config/VirtualBox&lt;/code&gt;目录下生成一个VirtualBox.xml文件，里面有注册过的虚拟机的信息，类似下图所示：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/virtualbox.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;连接虚拟机&#34;&gt;连接虚拟机&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;这里我又要牢骚两句，网上有些人啊，觉得用命令行就是为了装13，根本不从问题的出发点去考虑。我为什么要用VirtualBox的命令行来安装虚拟机？图形界面不是更简单么？那是因为我的工作站没有图形界面啊！有些人上来就说连接你新创建的虚拟机要用&lt;code&gt;rdesktop -N localhost:3389&lt;/code&gt;，简直是bullshit，我要是用带图形环境的工作站，就根本就不用费那么大力气搞这个了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;言归正传，现在有了两种选择，Windows可以用自带的“远程桌面连接”应用进行连接，需要注意的是，以上面的命令为例，在填写主机时就需要写&amp;rdquo;192.168.159.3:5010&amp;rdquo;（其中IP是我用的工作站的IP，具体根据你的实际情况写），如果是Linux桌面就用&lt;code&gt;rdesktop -N 192.168.159.3:5010&lt;/code&gt;。至于Mac我好像也没有找到可以用的。&lt;/p&gt;

&lt;h2 id=&#34;复制虚拟机&#34;&gt;复制虚拟机&lt;/h2&gt;

&lt;p&gt;毕竟资源不是无限的，咱们创建虚拟机建集群也不能太浪费资源。我的理解是，如果要赋值虚拟机，最好用&amp;rdquo;link&amp;rdquo;形式，也就是说，复制虚拟机的快照，系统通过两个虚拟机的diff来区分二者。具体到VirtualBox的操作是这样的&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;为模板虚拟机创建一个snapshot&lt;/li&gt;
&lt;li&gt;复制snapshot并命名&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这两步就可以创建一个以前面的虚拟机为基础的虚拟机，而系统又不会占用两套存储空间，也步要求它有多高的性能，只要能说名问题即可。&lt;/p&gt;

&lt;p&gt;先查看一下当前有哪些虚拟机（注意：snapshot是另外一种实体，查看vm的命令是查看不到snapshot的）
&lt;img src=&#34;http://ww1.sinaimg.cn/large/65e4f1e6gw1f8v1dqo36oj20yw05etat.jpg&#34; alt=&#34;&#34; /&gt;
看一下指定的虚拟机是否已经有snapshot(这里只是不想给已经有snapshot的虚拟机再创建新的，其实是没有问题的)
&lt;img src=&#34;http://ww1.sinaimg.cn/large/65e4f1e6gw1f8v1ffm5tcj216002omy7.jpg&#34; alt=&#34;&#34; /&gt;
创建新的snapshot并查看是否创建成功
&lt;img src=&#34;http://ww1.sinaimg.cn/large/65e4f1e6gw1f8v1ig2xsuj21kw07en04.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;VBoxManage clonevm Debian-original --options link --name Debian-cluster-01 --register&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这样就克隆了一个新的虚拟机，并且注册到VirtualBox中，下面启动新的虚拟机的步骤就和前面直接创建新虚拟机一样了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ZooKeeper原理简介和简单使用</title>
      <link>http://lovelock.coding.me/bigdata/zookeeper-simple-practice/</link>
      <pubDate>Wed, 12 Oct 2016 23:36:09 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/bigdata/zookeeper-simple-practice/</guid>
      <description>

&lt;h2 id=&#34;什么是分布式应用&#34;&gt;什么是分布式应用&lt;/h2&gt;

&lt;p&gt;分布式应用运行在其上的一组系统被称为『集群』(cluster)，运行在集群中的每个机器被称为『节点』(node)。&lt;/p&gt;

&lt;h3 id=&#34;分布式应用的优点&#34;&gt;分布式应用的优点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;可靠性 单机或少量机器的故障不会导致整个系统不可用。&lt;/li&gt;
&lt;li&gt;可扩展性 不用停机只需要做很少的配置就可以根据需求通过增加机器来提升系统的性能。&lt;/li&gt;
&lt;li&gt;透明性 隐藏了系统的复杂性，对外值暴露单一的入口/应用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;分布式应用需要解决的难点&#34;&gt;分布式应用需要解决的难点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;竞争条件 两个或多个机器都尝试去执行同一个任务，而该任务在任意时刻都应该只被一台机器执行。比如，共享的资源在某一时刻应该只能被一台机器修改。&lt;/li&gt;
&lt;li&gt;死锁 两个或多个操作无限期的相互等待对方完成。&lt;/li&gt;
&lt;li&gt;不一致性 数据的部分错误。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;zookeeper简介&#34;&gt;ZooKeeper简介&lt;/h2&gt;

&lt;p&gt;ZooKeeper是一个&lt;strong&gt;分布式的&lt;/strong&gt;、用来管理大量主机的&lt;strong&gt;协调服务&lt;/strong&gt;。
在分布式环境中协调和管理一个服务是很复杂的工作，而ZooKeeper用简单的架构和API解决了这个问题，它用&lt;code&gt;fail-safe synchronization&lt;/code&gt;机制解决了竞争和死锁的问题, 用&lt;code&gt;atomicity(原子性)&lt;/code&gt;解决了数据的一致性问题。它屏蔽了分布式环境中的复杂性，让开发人员可以专注于核心应用功能的开发，而不用去关心分布式环境的太多细节。&lt;/p&gt;

&lt;h3 id=&#34;zookeeper提供的服务&#34;&gt;ZooKeeper提供的服务&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;名字服务 在一个集群内根据name找到主机，类似DNS服务&lt;/li&gt;
&lt;li&gt;配置管理 集中管理某个节点的最新配置&lt;/li&gt;
&lt;li&gt;集群管理 管理一个集群中某一节点的加入和离开&lt;/li&gt;
&lt;li&gt;主节点选举 协调一个集群选举中一个新的主节点&lt;/li&gt;
&lt;li&gt;加锁和同步服务 在数据被修改时给其加锁，这种机制可以帮助你在连接到其他如HBase的分布式服务时实现自动错误恢复&lt;/li&gt;
&lt;li&gt;存放高可用数据 可以保证在一个或多个节点出故障时保证数据的可用性&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;zookeeper的优点&#34;&gt;ZooKeeper的优点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;简单的分布式协调过程&lt;/li&gt;
&lt;li&gt;同步 服务器进程间的互斥和协作&lt;/li&gt;
&lt;li&gt;有序的消息&lt;/li&gt;
&lt;li&gt;序列化 用指定的规则编码数据。保证你的应用一致的运行。这种方式可以用在MapReduce中来协调对来执行线程&lt;/li&gt;
&lt;li&gt;可靠性&lt;/li&gt;
&lt;li&gt;原子性 数据传输要么成功要么失败，不存在中间状态&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;zookeeper的架构&#34;&gt;ZooKeeper的架构&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8mN6jw1f7alv0grqej30fw04zdgg.jpg&#34; alt=&#34;ZooKeeper架构图&#34; /&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;概念&lt;/th&gt;
&lt;th&gt;职责和作用&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Client&lt;/td&gt;
&lt;td&gt;Client定时向Server发送消息通知Server该Client是alive众泰，同时Server会返回Response给Client，如果Client发送Message后没有收到Response，则会自动重定向到其他Server&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Server&lt;/td&gt;
&lt;td&gt;ZooKeeper集群中的一个节点，提供给Clients所有的服务&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Ensemble&lt;/td&gt;
&lt;td&gt;一个可以提供ZooKeeper服务的集群，如果要达到高可用性，至少需要三个节点&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Leader&lt;/td&gt;
&lt;td&gt;节点故障时执行自动恢复的节点，启动时选举出的&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Follower&lt;/td&gt;
&lt;td&gt;根据Leader的指示执行任务&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;层级的命名空间&#34;&gt;层级的命名空间&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8mN6jw1f7ayltmo57j30go0ce0t8.jpg&#34; alt=&#34;ZooKeeper的层级的命名空间&#34; /&gt;&lt;/p&gt;

&lt;p&gt;层级结构中的每个节点叫做znode, 每个znode维护一个&lt;code&gt;stat&lt;/code&gt;结构。这个&lt;code&gt;stat&lt;/code&gt;仅仅提供一个znode的元信息，其中包括版本号(Version number)、行为控制列表(Action Control List, ACL)、时间戳(Timestamp)、数据长度(Data Lenght)。&lt;/p&gt;

&lt;p&gt;下面来就实例看一下一个znode有哪些信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8mN6jw1f8r0ho7jkhj31320h6ad1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这样一看就很明显了吧。&lt;/p&gt;

&lt;h3 id=&#34;znode的类型&#34;&gt;znode的类型&lt;/h3&gt;

&lt;p&gt;znode分为三种类型：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;永久型 永久型节点当客户端断开连接之后仍然存在，默认情况下创建的节点都是永久型节点&lt;/li&gt;
&lt;li&gt;临时型 只有client保持alive时才存在的节点叫临时节点，当client从ZooKeeper集群断开时，节点被自动删除。所以临时节点不允许有子节点。如果一个临时节点被删除了，下一个合适的节点会填充它的位置。临时节点在Leader的选取中起到重要作用。&lt;/li&gt;
&lt;li&gt;顺序型 序列型节点可以是永久的也可以是临时的。当一个znode被创建为顺序型时，ZooKeeper在它原来的name后面加上十位的十进制数字。如果两个顺序型节点是并发创建的，ZooKeeper会保证两个节点的name不同。顺序型节点在锁和同步中起到重要作用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;会话-sessions&#34;&gt;会话（Sessions）&lt;/h3&gt;

&lt;p&gt;一个会话中的请求是按照FIFO的顺序执行的。当一个client连接上一个server，一个会话就创建成功了并且会生成一个session id给client。&lt;br /&gt;
client会按一个时间间隔给server发送heartbeat来保证session的有效性。如果在一个session的生命周期内没有收到client的heartbeat，它就会认为这个client已经死掉了。&lt;br /&gt;
Session超时通常用ms表示。当一个session不管由于什么原因结束时，在session中创建的临时节点都会被删除掉。&lt;/p&gt;

&lt;h3 id=&#34;watches&#34;&gt;Watches&lt;/h3&gt;

&lt;p&gt;Watches是用来保证client能在znode上的数据发生变化时收到通知的一种简单机制。client在读取znode的数据时可以设置一个watches给一个特定的znode，当这个znode上的数据或者它的子节点发生变化时都会触发watches给client发送通知。&lt;br /&gt;
watches只会被触发一次，如果client还需要通知，那就需要另外一次的读取操作了。当一个client和server之间的会话过期时，它们之间的连接就断开了，同时watches也会被移除。&lt;/p&gt;

&lt;h3 id=&#34;工作流程&#34;&gt;工作流程&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;client读取数据 client发送一个&lt;strong&gt;读取请求&lt;/strong&gt;给ZooKeeper的一个节点，该节点根据请求中的path信息读取&lt;strong&gt;自己数据库中的数据&lt;/strong&gt;返回znode的信息给client。所以读取操作在ZooKeeper集群中是很快的。&lt;/li&gt;
&lt;li&gt;client写数据 如果收到请求的是Follower，它会先把请求转发给Leader，由Leader再发送写请求给Followers。只有&lt;strong&gt;大多数节点&lt;/strong&gt;正确响应时，写请求才会成功并且返回正确的返回码给client。否则写请求就会失败。这个严格的&lt;strong&gt;大多数节点&lt;/strong&gt;被称为&lt;strong&gt;Quorum（法定人数)&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;zookeeper中的节点数量&#34;&gt;ZooKeeper中的节点数量&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;当只有一个节点时，没有大多数&lt;/li&gt;
&lt;li&gt;只有两个节点，一个出故障时，也没有大多数&lt;/li&gt;
&lt;li&gt;当有三个节点，有一个出了故障，那2个就是大多数&lt;/li&gt;
&lt;li&gt;当有四个节点，2个出故障了，那也是没有大多数的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以，ZooKeeper集群的中节点的数量不要太多，不然写的性能会有下降。同时节点的数量是3/5/7这种奇数，而不要是偶数。&lt;/p&gt;

&lt;h3 id=&#34;小结&#34;&gt;小结&lt;/h3&gt;

&lt;p&gt;看了上面的这么一大套理论，可能还是对ZooKeeper做的事情云里雾里，因为它做的事情太抽象了，好像实际它什么都没做，但又发现好像每个组件比如Kafka/Storm都要和ZooKeeper配合才能用。到底为什么呢？&lt;/p&gt;

&lt;p&gt;上面讲过，ZooKeeper其实是一个配置分发服务，也就是具体的应用如Kafka和Storm都是&lt;strong&gt;无状态&lt;/strong&gt;的，它本身为了保持&lt;strong&gt;容错&lt;/strong&gt;的特性，而容错很重要的一项特性就是应用Down掉之后重启还要能从之前结束时的地方继续。既然是无状态，其实是&lt;strong&gt;自己不存储状态&lt;/strong&gt;，那要实现的这个特性肯定是&lt;strong&gt;需要知道&lt;/strong&gt;应用Down掉之前的状态的，那么好，我就把状态存在ZooKeeper里。&lt;/p&gt;

&lt;p&gt;举个生动的例子，假设有一个很长的（水）槽，Kafka会每秒把一个玻璃球放在槽里，这样的结果就是最先放进去的玻璃球在最前面。而Storm就是&lt;strong&gt;计数工&lt;/strong&gt;，（注意&lt;strong&gt;不是搬运工&lt;/strong&gt;，因为它数了之后并不会真实的改变玻璃球的位置）极端一点这个游戏是在一个战场上，Storm随时会死掉，它怎么保证它的后来者来到之后马上知道它之前数到哪个位置了？自己当然是不可靠的，因为它死掉之后这个信息就丢失了，所以它&lt;strong&gt;每数一个&lt;/strong&gt;就朝ZooKeeper大喊一声（发送写请求）告诉它数到哪个位置了，而Storm又是个健忘症（无状态），刚数完的自己就忘了，更不用说后面来的人了，那么当它把位置信息告诉ZooKeeper之后其实它和自己的后来者就没有区别了，因为不管是谁，在计数之前都需要先去ZooKeeper读取一下前面数到的位置。这样的好处就是每个Storm随时都可以死掉，只要能有新的应用随时可以起来即可。那么存到了ZooKeeper就万无一失了么？考虑前面ZooKeeper处理写请求的特点，它是把相同的信息在集群中所有的机器上都写了一份，即使其中的一台或几台宕掉了，除非在这几台重启之前仅剩的一台也宕掉了，服务是不受影响的。如果全宕掉了，那真的没办法了，你把整个机房的电源拔掉，肯定会丢数据的。&lt;/p&gt;

&lt;p&gt;也可以理解为把状态和应用做的解耦。&lt;/p&gt;

&lt;p&gt;那么问题来了，为什么是在战场上？为什么好好的一个应用会无缘无故的Down掉呢？这就要从分布式应用的特点说起了。我们知道以前的所谓大型机、小型机都是很大很昂贵的特殊机器，是区别于普通的硬件的，包括CPU、内存、硬盘都是特制的，所以一台机器上百万甚至千万的都很常见，这种机器宕机的几率很小，但如果宕机的话影响也会相当严重。所以可以说这些机器的费用里其实也包含了保险费，因为机器宕机导致的损失，供应商是要负责任的。&lt;/p&gt;

&lt;p&gt;但现在不同了，现在是用大量普通（廉价）的机器组成集群来替代之前特殊的机器，既然是普通，那出错的几率当然就更高了，这也就是为什么诸如Storm这些系统在设计之初就特别注重&lt;strong&gt;容错&lt;/strong&gt;和&lt;strong&gt;无状态&lt;/strong&gt;了。&lt;/p&gt;

&lt;h2 id=&#34;zookeeper的使用&#34;&gt;ZooKeeper的使用&lt;/h2&gt;

&lt;h3 id=&#34;安装和配置&#34;&gt;安装和配置&lt;/h3&gt;

&lt;h4 id=&#34;安装&#34;&gt;安装&lt;/h4&gt;

&lt;p&gt;大数据的这套东西安装起来都是很简单，因为都是编译好的包，直接解压之后就可以以默认配置执行了。不过ZooKeeper有点特殊，因为它需要读取的配置文件是&lt;code&gt;conf/zoo.cfg&lt;/code&gt;，而默认的发行包里面是有个&lt;code&gt;conf/zoo_sample.cfg&lt;/code&gt;，不过好在只需要重命名一下即可。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost zookeeper-3.4.8]# cp conf/zoo_sample.cfg conf/zoo.cfg
[root@localhost zookeeper-3.4.8]# bin/zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /root/packages/zookeeper-3.4.8/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
[root@localhost zookeeper-3.4.8]# bin/zkServer.sh status
Mode: standalone
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注意这里的Mode，表示单点模式，区别于集群模式&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;配置&#34;&gt;配置&lt;/h4&gt;

&lt;p&gt;前面只讲了基础配置，这样的配置是没法跑集群环境的，下面先从默认配置出发，一步一步搭建一个集群环境。
先贴默认配置：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tickTime=2000
initLimit=10
syncLimit=5
dataDir=/tmp/zookeeper
clientPort=2181
#maxClientCnxns=60
#autopurge.snapRetainCount=3
#autopurge.purgeInterval=1
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;tickTime&lt;/code&gt;： ZooKeeper服务器或客户端与服务器之间维持心跳的时间间隔，也就是每个tickTime就会发送一条心跳&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dataDir&lt;/code&gt; 顾名思义就是ZooKeeper保存数据的目录&lt;/li&gt;
&lt;li&gt;&lt;code&gt;clientPort&lt;/code&gt; ZooKeeper对外提供服务的端口，即客户端通过该端口与ZooKeeper通信&lt;/li&gt;
&lt;li&gt;&lt;code&gt;initLimit&lt;/code&gt; ZooKeeper集群中的Leader忍受Follower多少个心跳间隔不发送心跳。从这里的默认配置推算，10个心跳间隔，每个心跳间隔2秒钟，也就是当Leader经过2*10秒还收不到Follower的信条时就认为这个Follower已经挂了&lt;/li&gt;
&lt;li&gt;&lt;code&gt;syncLimit&lt;/code&gt; Leader和Follower之间发送消息时，请求和应答的时间长度，默认5，及10秒&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;从上面的描述就可以看到，从第4条开始就是集群需要的配置了，然而仅仅在每个机器上这样配置并不能变成一个集群，还需要一个重要的配置，形如&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server.1=c1:2888:3888
server.2=c2:2888:3888
server.3=c3:2888:3888
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中的&lt;code&gt;server.n&lt;/code&gt;中的n表示节点的编号，那么问题来了，编号从哪里定义呢？我觉得这个设计其实不太好，当然我也想不到更好的方式来解决这个问题了。我们还需要在&lt;code&gt;dataDir&lt;/code&gt;中写入一个名为&lt;code&gt;myid&lt;/code&gt;的文件，其中填写当前机器的编号，操作如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd /path/to/dataDir
echo 1 &amp;gt; myid
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;c1的位置是节点机器的hostname或者IP地址，这样写当然还是不行的，因为它们并不知道c1是什么鬼，所以还需要修改&lt;code&gt;/etc/hosts&lt;/code&gt;，以我当前的本地集群为例，在该文件中添加&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;192.168.1.111 c1
192.168.1.110 c2
192.168.1.112 c3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2888是默认的Follower与Leader交换信息的端口，3888是用于选举Leader的端口，当Leader挂了，当然需要选举一个新的Leader来继续它未竟的事业了。&lt;/p&gt;

&lt;h3 id=&#34;启动集群&#34;&gt;启动集群&lt;/h3&gt;

&lt;p&gt;这时可以在三台机器上同时执行&lt;code&gt;bin/zkServer.sh start&lt;/code&gt;了。如果看到和前面一样的结果（注意把刚才已经启动的服务先关掉，执行&lt;code&gt;bin/zkServer.sh stop&lt;/code&gt;），恭喜你成功了一半了。
这时再执行&lt;code&gt;bin/zkServer.sh status&lt;/code&gt;你会惊奇的发现其中一台会显示&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost zookeeper-3.4.8]# bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /root/packages/zookeeper-3.4.8/bin/../conf/zoo.cfg
Mode: leader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外两台显示&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost zookeeper-3.4.8]# bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /root/packages/zookeeper-3.4.8/bin/../conf/zoo.cfg
Mode: follower
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了证明Leader节点是自动选举的，可以把Leader手动关掉，再分别看看另外两台的&lt;code&gt;status&lt;/code&gt;。是不是有一个变成了Leader了？&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;几天前写这篇文章时没有问题，但今天继续编写Kafka部分时，因为之前重启过这几台虚拟机，IP变了，重启所有虚拟机之后发现虽然已经在本地启动了ZooKeeper服务，但执行&lt;code&gt;zkServer.sh status&lt;/code&gt;时总是提示没有运行，而如果你再执行&lt;code&gt;start&lt;/code&gt;指令，它又会提示说进程已经在运行了。根据&lt;a href=&#34;http://stackoverflow.com/questions/29909191/zookeeper-it-is-probably-not-running&#34;&gt;StackOverFlow的答案&lt;/a&gt;，把&lt;code&gt;/root/packages/zookeeper-3.4.8/bin&lt;/code&gt;添加至&lt;code&gt;$PATH&lt;/code&gt;中即可。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vim /etc/profile.d/zookeeper.sh
export ZK_HOME=/root/packages/zookeeper-3.4.8
export PATH=$PATH:$ZK_HOME/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后执行&lt;code&gt;source /etc/profile.d/zookeeper.sh&lt;/code&gt;即可直接在系统的任何地方执行&lt;code&gt;zkServer.sh start&lt;/code&gt;了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;通过动态的选举Leader节点，就解决了&lt;strong&gt;主从系统的单点故障问题&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&#34;简单使用&#34;&gt;简单使用&lt;/h3&gt;

&lt;p&gt;前面说了启动服务，细心的你可能还发现在bin目录里面还有一个zkCli.sh（请自动无视zkCli.cmd，因为那明显是给Windows用的，而我觉得也没有人会在Windows上跑这些服务），这就是ZooKeeper的命令行客户端。&lt;/p&gt;

&lt;p&gt;而我要说的只有两个最简单的命令。&lt;/p&gt;

&lt;h4 id=&#34;1-ls&#34;&gt;1. &lt;code&gt;ls&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;ls&lt;/code&gt;顾名思义就是查看指定path下的数据，前面我已经演示过了，要注意的一点是&lt;strong&gt;如果&lt;code&gt;ls&lt;/code&gt;后跟的是一个叶子节点，返回的结果是&lt;code&gt;[]&lt;/code&gt;&lt;/strong&gt;，这时你应该很敏锐的意识到应该换用&lt;code&gt;get&lt;/code&gt;来操作这个节点从而查看它的详细信息了。&lt;/p&gt;

&lt;h4 id=&#34;2-get&#34;&gt;2. &lt;code&gt;get&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;get&lt;/code&gt;当然就是用来查看指定节点的详细信息用的了。&lt;/p&gt;

&lt;p&gt;ZooKeeper提供的借口当然远远不止这两个，但起码到目前为止我还没有用到需要自行调用ZooKeeper接口的地方。因为实际上ZooKeeper是一个很底层的服务，它是用来为Storm和Kafka这类系统提供服务的，而我们通常不直接使用它们。在前两天一次查问题的过程中，发现数据一直在重复写入HDFS，查到了一个症状是ZooKeeper中的offset从一次重启发布之后一直没有更新过，导致系统一直反复读取该时间点之后的数据。这期间也就只用了这两个命令，至于对各种语言的binding，这里就不多说了，如果你要使用ZooKeeper给你的应用提供服务，那也不是看我的这篇文章就能搞明白的：）&lt;/p&gt;

&lt;p&gt;Happy Coding!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;本文大量参考了&lt;a href=&#34;https://www.tutorialspoint.com//zookeeper/index.htm&#34;&gt;https://www.tutorialspoint.com/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>一个真实Storm应用源码解析</title>
      <link>http://lovelock.coding.me/java/storm-demo-presentation/</link>
      <pubDate>Tue, 11 Oct 2016 16:41:18 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/storm-demo-presentation/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;这里是Storm分享的内容。我自己也是初学者，这里抛砖引玉，希望大家多多指教。为简单起见，本应用用的是Java实现，没有用到Storm的多语言支持和更高层面的Trident Topology。源码详见&lt;a href=&#34;https://github.com/lovelock/storm-demo&#34;&gt;storm-demo&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;理论&#34;&gt;理论&lt;/h2&gt;

&lt;h3 id=&#34;概述&#34;&gt;概述&lt;/h3&gt;

&lt;p&gt;Apache Storm是一个自由并且开源的&lt;strong&gt;分布式实时&lt;/strong&gt;计算系统.它使得像Hadoop做批处理一样做&lt;strong&gt;实时的&lt;/strong&gt;、&lt;strong&gt;无限量&lt;/strong&gt;的&lt;strong&gt;流数据&lt;/strong&gt;处理变得简单可靠.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://storm.apache.org/images/storm-flow.png&#34; alt=&#34;Apache Storm工作流程&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;概念解释&#34;&gt;概念解释&lt;/h3&gt;

&lt;h4 id=&#34;工作原理&#34;&gt;工作原理&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://www.tutorialspoint.com/apache_storm/images/zookeeper_framework.jpg&#34; alt=&#34;Apache Storm组件间关系&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Nimbus&lt;br /&gt;
 Nimbus是Storm集群的&lt;strong&gt;主节点master node&lt;/strong&gt;。Storm集群中除Nimbus节点之外的所有节点叫做&lt;strong&gt;工作节点worker nodes&lt;/strong&gt;。&lt;br /&gt;
 Nimbus负责三项工作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;向worker nodes分发数据&lt;/li&gt;
&lt;li&gt;向worker nodes分配tasks&lt;/li&gt;
&lt;li&gt;监控失败&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Supervisor&lt;br /&gt;
 接受Nimbus的指令的节点叫做Supervisors（监工），它有&lt;strong&gt;多个worker process&lt;/strong&gt;，并控制worker process完成Nimbus分配的tasks&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Worker Process&lt;br /&gt;
 Worker process执行指定Topology的tasks。&lt;strong&gt;worker process自己并不实际执行tasks，而是创建executors并由executors执行指定的task。&lt;/strong&gt;一个worker process可以由多个executor。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Executor&lt;br /&gt;
 Executor是由worker process创建的线程。一个executor执行一个或多个tasks，但只为&lt;strong&gt;一个指定的Spout或者Bolt工作&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Task&lt;br /&gt;
 Task是实际的数据处理工作，所以它可能是一个Spout或者Bolt。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;配套服务&#34;&gt;配套服务&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;ZooKeeper&lt;br /&gt;
&lt;a href=&#34;http://zookeeper.apache.org/&#34;&gt;ZooKeeper&lt;/a&gt;是一个分布式的配置分发服务。Storm和Kafka都是无状态的，它们的工作需要外部服务为其维持状态，如Storm从Kafka中取数据时需要的partition编号和offset偏移量等诸如此类的信息。ZooKeeper会综合分析Spout和Bolt发送来的ack或者fail请求来决定是否更新offset。如下图所示&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww3.sinaimg.cn/large/65e4f1e6jw1f8wd8tm94ij21kw097q5h.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kafka&lt;br /&gt;
&lt;a href=&#34;http://kafka.apache.org/&#34;&gt;Kafka&lt;/a&gt;是一个分布式的消息系统。支持&lt;strong&gt;点对点&lt;/strong&gt;和&lt;strong&gt;发布-订阅&lt;/strong&gt;两种消息模式。在和Storm配合中，充当&lt;strong&gt;数据来源&lt;/strong&gt;的角色。用&lt;a href=&#34;https://github.com/apache/storm/tree/master/external/storm-kafka&#34;&gt;KafkaSpout&lt;/a&gt;和Storm进行组合。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;本文只关注Storm，有关ZooKeeper和Kafka的介绍，可以访问&lt;a href=&#34;http://apache.org/&#34;&gt;官网&lt;/a&gt;、&lt;a href=&#34;http://www.tutorialspoint.com/&#34;&gt;TutorialsPoint&lt;/a&gt;或本博客的其他相关文章。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;拓扑作业&#34;&gt;拓扑作业&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Tuple&lt;br /&gt;
 Tuple是Topology中数据流的传输格式。它是&lt;strong&gt;不可变的键值对组&lt;/strong&gt;。既然是键值对，就需要设置键和值，典型的设置方式如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; // 设置键
 outputFieldsDeclarer.declare(new Fields(&amp;quot;timestamp&amp;quot;, &amp;quot;fieldvalues&amp;quot;));
 // 设置值
 collector.emit(tuple, new Values(timestamp, stringBuilder.toString()));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就会得到一个形如&lt;code&gt;(&amp;quot;timestamp&amp;quot;: timestamp, &amp;quot;fieldvalues&amp;quot;: xxxx&amp;quot;)&lt;/code&gt;这样的Tuple。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Spout&lt;br /&gt;
 Spout是Topology的数据来源，输出的数据以Tuple的形式传入下一个Bolt。具体到本例中，KafkaSpout会把它接收到的数据以类似&lt;code&gt;(0: message)&lt;/code&gt;这样的形式发射(emit)出来。所以，在KafkaSpout下游的Bolt需要这样获取整条数据(其实这里是可配置的)：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; String message = tuple.getString(0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对KafkaSpout而言，它也实现了多个方法，但我们这里只需要了解两个&lt;code&gt;ack&lt;/code&gt;和&lt;code&gt;fail&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww3.sinaimg.cn/large/65e4f1e6jw1f8wdqv4tuqj218y0ji41l.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这两个是回调方法，分别在acker向其发送ack或fail请求时被触发，一般而言，ack方法由于通知Kafka发送下一条数据，fail方法用于通知Kafka重发上一条数据。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Storm中有个特殊的task名叫acker，它们负责跟踪Spout发出的每一个Tuple的Tuple树（因为一个Tuple通过Spout发出了，经过每一个Bolt处理后，会生成一个新的Tuple发送出去）。当acker（框架自启动的task）发现一个Tuple树已经处理完成了，它会发送一个消息给产生这个Tuple的那个task。&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bolt&lt;br /&gt;
 Bolt是真正写处理逻辑的地方，比如在本例中，我们要做以下几件事：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;把message中的每个字段提取出来，&lt;/li&gt;
&lt;li&gt;从message的domain字段中过滤出以&lt;code&gt;.api.ksyun.com&lt;/code&gt;结尾的，其他的舍弃&lt;/li&gt;
&lt;li&gt;把domain字段的值以&lt;code&gt;.&lt;/code&gt;分割，取出index为0的部分，也就是第一段作为service字段&lt;/li&gt;
&lt;li&gt;把service最终输出Tuple的一个field写入输出结果&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一般情况下，要实现一个Bolt有几种方式&lt;/p&gt;

&lt;p&gt;​&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;实现&lt;code&gt;IRichBolt&lt;/code&gt;接口&lt;br /&gt;
  因为这个比较低级，要实现的方法有很多，而其中多数的方法不需要做特殊处理，所以一般会用第二种方式&lt;/li&gt;

&lt;li&gt;&lt;p&gt;集成&lt;code&gt;BaseRichBolt&lt;/code&gt;类&lt;br /&gt;
  这个基类实现了&lt;code&gt;IRichBolt&lt;/code&gt;中定义的几个不常用的方法，让我们只需要关注重点的几个方法即可。在这种方式中，我们需要自己实现三个方法：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;public void prepare(Map map, TopologyContext topologyContext, OutputCollector outputCollector)&lt;/code&gt;&lt;br /&gt;
  这个方法&lt;strong&gt;类似构造函数&lt;/strong&gt;，用来做一些准备工作，通常用于&lt;strong&gt;把上游传来的collector赋值给成员变量&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;public void execute(Tuple tuple)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这是最核心的方法。它负责：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;从上游传来的Tuple中读取感兴趣的字段&lt;/li&gt;
&lt;li&gt;把这些字段做一些处理后产生一组新的字段&lt;/li&gt;
&lt;li&gt;把这些值通过&lt;code&gt;OutputCollector::emit(new Values())&lt;/code&gt;方法发射出去&lt;/li&gt;
&lt;li&gt;向上游发送&lt;code&gt;OutputCollector::ack(Tuple tuple)&lt;/code&gt;或&lt;code&gt;OutputCollector::fail(Tuple tuple)&lt;/code&gt;，以告知上游本次Tuple处理是否成功。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;前面已经说过，Tuple是数据交流的格式，这个方法就是用来定义发送到下游的Tuple的字段名的。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Topology&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://storm.apache.org/releases/0.10.0/images/topology.png&#34; alt=&#34;一个典型的Topology&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上面这张图中有4个Topology，说明了几个问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一个Spout就是一个Topology的入口，从Spout分出几条线就有几个Topology&lt;/li&gt;
&lt;li&gt;一个Topology由一个Spout和若干个Bolt组成&lt;/li&gt;
&lt;li&gt;Topology之间可以共享Spout或者Bolt&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;创建一个Topology的典型过程：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    TopologyBuilder topologyBuilder = new TopologyBuilder();
    topologyBuilder.setSpout(KAFKA_SPOUT_ID, kafkaSpout, 10);
    topologyBuilder.setBolt(CROP_BOLT_ID, new CropBolt(), 10).shuffleGrouping(KAFKA_SPOUT_ID);
    topologyBuilder.setBolt(SPLIT_FIELDS_BOLT_ID, new SplitFieldsBolt(), 10).shuffleGrouping(CROP_BOLT_ID);
    topologyBuilder.setBolt(STORM_HDFS_BOLT_ID, hdfsBolt, 10).fieldsGrouping(SPLIT_FIELDS_BOLT_ID, new Fields(&amp;quot;timestamp&amp;quot;, &amp;quot;fieldvalues&amp;quot;));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的代码可以看到，&lt;code&gt;TopologyBuilder&lt;/code&gt;类通过&lt;code&gt;setSpout()&lt;/code&gt;和&lt;code&gt;setBolt()&lt;/code&gt;两个方法生动的反映了上图的工作流程。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;源码分析&#34;&gt;源码分析&lt;/h2&gt;

&lt;h3 id=&#34;cropbolt-java&#34;&gt;&lt;code&gt;CropBolt.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;主要关注&lt;code&gt;execute&lt;/code&gt;方法，它首先从上游发射来的Tuple中取出第一个字段，也就是整条消息作为一个字符串。根据对字符串的分析，我们知道该字符串是以&lt;code&gt;\t\t&lt;/code&gt;作为字段间分隔符，以&lt;code&gt;:&lt;/code&gt;作为键值分隔符的字符串，所以可以写一个方法来用这种规则解析出消息中的所有字段，并把它放在一个HashMap里。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    private HashMap makeMapOfMessage(String message) {
    String[] fields = message.split(ServerConfig.getFieldSeparator());
    HashMap&amp;lt;String, String&amp;gt; map = new HashMap&amp;lt;&amp;gt;();

    try {
        for (String field : fields) {
            String[] pair = field.split(ServerConfig.getPairSeparator(), 2);
            map.put(pair[0], pair[1]);
        }
    } catch (ArrayIndexOutOfBoundsException e) {
        LOG.warn(&amp;quot;makeMapOfMessage failed {}&amp;quot;, message);
        e.printStackTrace();
    }

    return map;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中&lt;code&gt;ServerConfig&lt;/code&gt;是一个工具类，它提供了简单的API，把处理逻辑和配置信息分离。在本例中我用的分隔符和实际项目并不一样，这个差别只需要在相应的properties配置文件中做修改即可。还需要注意异常处理，这个方法的返回值有可能是null，在调用该方法的地方需要做相应的判断。&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;execute&lt;/code&gt;方法中，从上述方法的返回值取出关心的字段，并按需求解析出需要的&lt;code&gt;service&lt;/code&gt;字段，并通过&lt;code&gt;collector.emit&lt;/code&gt;发送给下游的Bolt。&lt;/p&gt;

&lt;p&gt;这个方法中有三点需要注意：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;没有在&lt;code&gt;try&lt;/code&gt;子句中调用&lt;code&gt;ack&lt;/code&gt;方法&lt;/li&gt;
&lt;li&gt;没有在&lt;code&gt;catch&lt;/code&gt;子句中调用&lt;code&gt;fail&lt;/code&gt;方法&lt;/li&gt;
&lt;li&gt;在&lt;code&gt;finally&lt;/code&gt;子句中调用了&lt;code&gt;ack&lt;/code&gt;方法&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因为我们catch住的这种情况，是只有在输入的数据不满足我们约定要求的情况下才会发生的，比如某些必要的字段不存在等，而这种情况在当前的Topology中是不需要处理的，并且也不需要重试，因此，不需要调用&lt;code&gt;fail&lt;/code&gt;。同时，不管数据是否符合要求，我们都是需要通知Spout&lt;strong&gt;这里的处理已经完成&lt;/strong&gt;这个信息的，所以在&lt;code&gt;finally&lt;/code&gt;中调用&lt;code&gt;ack&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;splitfieldsbolt-java&#34;&gt;&lt;code&gt;SplitFieldsBolt.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;这步的功能很简单，就是把前面传过来的所有字段用一个特定的分隔符连接起来，变成一行数据。只有一个特殊，也就是&lt;code&gt;service&lt;/code&gt;字段，它不是直接取出来的，而是前面的Bolt通过一些处理得到的，所以这是&lt;code&gt;stringBuilder&lt;/code&gt;需要处理的一种特殊情况。&lt;/p&gt;

&lt;p&gt;最后把『时间戳』和『各个字段的值』发射给下游的&lt;code&gt;HdfsBolt&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;hdfsbolt&#34;&gt;&lt;code&gt;HdfsBolt&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;HdfsBolt&lt;/code&gt;是Storm到HDFS的一个中转层，配置一些规则，把Storm输出的数据写入HDFS。其中比较重要的配置有：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;DelimitedRecordFormat&lt;/code&gt; 要写入的字段 在本例中，『时间戳』只是用来划分目录的，所以不需要写入HDFS中&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CountSyncPolicy&lt;/code&gt; 指定当内存中超过多少条数据时cache到磁盘中&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FileSizeRotationPolicy&lt;/code&gt; 指定cache的文件超过多大时将文件写入文件系统，如果该值设置的较大，而数据流量又不太大的情况下，文件通常不会达到设置的值，因为当等待写入的文件未达到限制大小而先达到超时时间时，也会创建一个新的文件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DefaultFileNameFormat&lt;/code&gt; 指定文件写入HDFS中的根目录和文件后缀&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Partitioner&lt;/code&gt; 指定分块规则，在本例中，我们根据日志中&lt;code&gt;time_local&lt;/code&gt;字段划分相应的消息应该写入的HDFS目录，比如&lt;code&gt;31/Aug/2016:13:08:12 +0800&lt;/code&gt;，相应的记录就会写入&lt;code&gt;root/20160831/13&lt;/code&gt;目录中。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FsURL&lt;/code&gt; 当然需要指定正确的&lt;code&gt;HDFS&lt;/code&gt;服务。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;其实我们的KMR对应的Storm 0.10.0是不支持HDFS 的partition的，这里我是把Storm最新版的2.0.0-SNAPSHOT中相应的代码移植过来用的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;logstatisticstopology-java&#34;&gt;&lt;code&gt;LogStatisticsTopology.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;前面讲过，这是拓扑作业的入口，这里指定了一条消息要通过的路径。需要注意的有以下几点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;setSpout&lt;/code&gt;和&lt;code&gt;setBolt&lt;/code&gt;方法中的parallelism_hint(并行度建议)，前面说了，Spout和Bolt在Storm中是以executor的形式存在的，而这个值就是指定executor的数量。但又没有那么绝对，比如在KafkaSpout中，如果指定的Topic在Kafka中有10个partition，但这里的KafkaSpout指定了15个并行度，实际还是只有10个executor有意义，因为剩余的5个在前面10个都正常工作的情况下是分配不到任何数据的，由于ZooKeeper做了中间人，它是知道每个Topic有多少个partition的，所以这里设置多于partition数量的并行度也是不起作用的。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;grouping类型 Storm目前支持4种分组形式。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;随机分组 等量tuples随机分发给执行bolt的所有workers&lt;/li&gt;
&lt;li&gt;字段分组 把指定字段值相同的分配给同一个task,在wordCount应用中比较重要&lt;/li&gt;
&lt;li&gt;广播分组 给每个executor发送一个这个tuple的副本&lt;/li&gt;
&lt;li&gt;全局分组 把所有数据分发给bolt的executor中id最小的&lt;strong&gt;一个&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;无分组   目前基本等同于随机分组，会把tuple交给和它上游同一个线程内的下游bolt，以减少数据传递的开销&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;根据我们的需求，其实是不需要太关心分组的事情。&lt;/p&gt;

&lt;p&gt;关于优化，有几个方面可以考虑：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;考虑到后面需要用Hive分析数据，如果产生很多小的文件，就会产生过多的Map过程，影响性能，可以考虑同一小时的文件交给同一个executor来写，因为每个executor会打开一个hdfs文件，但这样可能会导致并发数过少&lt;/li&gt;
&lt;li&gt;既然这样，可以减少executor的数量，比如现在是10个，可以改成5个，在不触发FileSizeRotationPolicy的情况下，把生成的文件数量减少了一半，也就把Hive查询时Map过程的数量减少了一半&lt;/li&gt;
&lt;li&gt;分析需求，如果没有按照小时分组的需求，可以直接删除这个级别，直接用天作为区分，这样，在不触发FileSizeRotationPolicy的情况下产生的文件数量会变成1/24,相应的Hive查询中Map的过程也会变成1/24.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;本文主要介绍了Storm的工作流程，以及其与Kafka和HDFS的配合来进行日志分析的工作流程，并简单介绍了一些需要注意的点。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>在本地单机部署Hadoop/Storm运行环境</title>
      <link>http://lovelock.coding.me/java/deploy-pseudo-distributed-mode-hadoop/</link>
      <pubDate>Mon, 10 Oct 2016 17:53:14 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/deploy-pseudo-distributed-mode-hadoop/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;由于要在小组内做一个关于Storm的分享，涉及到我负责开发的大数据项目，本着开放的原则，把我做的准备工作记录下来，提前发给可能参会的同事。&lt;br /&gt;
要演示的项目目前为止用到了Apache的多个项目，包括Kafka, Storm, Hadoop(HDFS, Hive), ZooKeeper等，项目刚刚起步，很多基础设施还不完善，比如现在是在本地开发完成之后直接部署到线上环境的，这次演示可不能直接在线上环境做了，故而在本地的台式机上部署了一下&lt;strong&gt;伪集群&lt;/strong&gt;，用来作为演示和以后开发测试用的环境。&lt;/p&gt;

&lt;h2 id=&#34;准备工作&#34;&gt;准备工作&lt;/h2&gt;

&lt;p&gt;说明：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;以下工作全部基于Ubuntu 16.04。用其他的发行版或版本理论上应该都是可行的，可能有些命令需要微调。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;所有需要执行的命令前面都有一个&lt;code&gt;$&lt;/code&gt;，表示的是Bash的命令提示符。&lt;/li&gt;
&lt;li&gt;下载安装包时我使用了速度相对较快的国内镜像，如果你对此有任何异议，可以自行去中心镜像站点下载。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;默认情况下文中提到的所有如StormUI等控制后台访问的路径都是localhost，如果你需要从Linux主机外部访问，需要iptables放行相应的端口。在本文中，用的Web端口有三个，具体如下表：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;服务描述&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;端口号&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Storm UI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8080&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hadoop UI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50070&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hadoop Applications&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8088&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;以Ubuntu为例，需要执行以下命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo ufw allow 8080/tcp
$ sudo ufw allow 50070/tcp
$ sudo ufw allow 8088/tcp
$ sudo ufw reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CentOS/RHEL 7.0以下可能需要直接操作iptables，7.0以上可以使用&lt;code&gt;firewall-cmd&lt;/code&gt;进行类似的操作。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-创建独立的用户并赋予合适的权限&#34;&gt;1. 创建独立的用户并赋予合适的权限&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ sudo useradd hadoop
$ sudo passwd hadoop
$ sudo chsh hadoop
$ sudo mkdir /home/hadoop
$ sudo chown -R hadoop:hadoop /opt/apache
$ sudo chown -R hadoop:hadoop /home/hadoop
$ su - hadoop
$ ssh-keygen
$ cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys
$ chmod 0600 ~/.ssh/authorized_keys
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;FAQ：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;为什么需要chsh并且手动为用户创建家目录？&lt;br /&gt;
不知道为什么在 Ubuntu 环境中执行&lt;code&gt;useradd&lt;/code&gt;命令之后并不会给新建的用户创建家目录和设置shell，可能是为了安全吧，要稍微麻烦一些。&lt;/li&gt;
&lt;li&gt;为什么不给新用户赋予root权限？&lt;br /&gt;
这里是测试环境倒还好，如果你需要搭建生产环境，记住千万不要给hadoop用户赋予root权限，它需要哪些目录的权限就单独赋予即可，它需要运行的端口都是1024以上的，都不需要root权限。如果需要，执行&lt;code&gt;sudo gpasswd -a hadoop sudo&lt;/code&gt;即可。&lt;/li&gt;
&lt;li&gt;为什么要做一个密钥认证？&lt;br /&gt;
这是因为在后续的步骤中会有&lt;strong&gt;从本地用户登录本地用户&lt;/strong&gt;的需求，也就是执行了&lt;code&gt;ssh hadoop@localhost&lt;/code&gt;这个命令，如果不做密钥信任，会需要多次输入密码。&lt;/li&gt;
&lt;li&gt;为什么会有一个&lt;code&gt;/opt/apache&lt;/code&gt;目录？&lt;br /&gt;
往下看。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-下载所需安装包&#34;&gt;1. 下载所需安装包&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;下载Java&lt;br /&gt;
到&lt;a href=&#34;http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html&#34;&gt;Java官网&lt;/a&gt;下载适用于Linux的Java安装包（这里下载了jdk-8u101-linux-x64.tar.gz）。&lt;/li&gt;
&lt;li&gt;下载maven&lt;br /&gt;
点击&lt;a href=&#34;http://mirrors.aliyun.com/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.zip&#34;&gt;阿里云镜像站&lt;/a&gt;下载最新版Maven。&lt;/li&gt;
&lt;li&gt;下载Apache的Storm Hadoop Kafka ZooKeeper&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/storm/apache-storm-0.10.2/apache-storm-0.10.2.tar.gz&#34;&gt;点击下载Storm-0.10.2&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/hadoop/core/hadoop-2.6.4/hadoop-2.6.4.tar.gz&#34;&gt;点击下载Hadoop-2.6.4&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/kafka/0.8.2.2/kafka_2.10-0.8.2.2.tgz&#34;&gt;点击下载Kafka_2.10-0.8.2.2&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz&#34;&gt;点击下载ZooKeeper-3.4.6&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-创建所需目录&#34;&gt;2. 创建所需目录&lt;/h3&gt;

&lt;p&gt;把所有和此项目相关的文件都放在统一的位置。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ sudo mkdir -p /opt/apache/{jdk, storm,hadoop,kafka,zookeeper}&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-解压所有安装包-将相应的安装包放在对应的位置&#34;&gt;3. 解压所有安装包，将相应的安装包放在对应的位置&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mv jdk1.8.0_101/* /opt/jdk/.
$ sudo mv apache-storm-0.10.0/* /opt/apache/storm/.
$ sudo mv hadoop-2.6.4/* /opt/apache/hadoop/.
$ sudo mv kafka_2.10-0.8.2.2/* /opt/apache/kafka/.
$ sudo mv zookeeper-3.4.6/* /opt/apache/zookeeper
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-配置环境变量&#34;&gt;4. 配置环境变量&lt;/h3&gt;

&lt;p&gt;在~/.bashrc中添加下面的片段&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export JAVA_HOME=/opt/jdk
export APACHE_HOME=/opt/apache
export STORM_HOME=$APACHE_HOME/storm
export ZK_HOME=$APACHE_HOME/zookeeper
export KAFKA_HOME=$APACHE_HOME/kafka

export HADOOP_HOME=$APACHE_HOME/hadoop
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_INSTALL=$HADOOP_HOME

export PATH=$PATH:$JAVA_HOME/bin
export PATH=$PATH:$STORM_HOME/bin
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export PATH=$PATH:$ZK_HOME/bin
export PATH=$PATH:$KAFKA_HOME/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后执行&lt;code&gt;$ source ~/.bashrc&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;5-安装java&#34;&gt;5. 安装Java&lt;/h4&gt;

&lt;p&gt;Apache的这些东西都是直接放在对的地方就可以运行的，但Java需要稍微的配置一下，因为可能你的机器上已经装了OpenJDK。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ sudo update-alternatives --install /usr/local/bin/java java /opt/jdk/bin/java 10000&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这时再执行&lt;code&gt;$ java -version&lt;/code&gt;验证一下是否使用的时最新安装的JDK。&lt;/p&gt;

&lt;h2 id=&#34;2-启动服务&#34;&gt;2. 启动服务&lt;/h2&gt;

&lt;h3 id=&#34;1-启动zookeeper&#34;&gt;1. 启动ZooKeeper&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ cp $ZK_HOME/conf/zoo_sample.cfg $ZK_HOME/conf/zoo.cfg
$ zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-启动storm&#34;&gt;2. 启动Storm&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ storm nimbus
$ storm supervisor
$ storm ui
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在可以访问&lt;a href=&#34;http://localhost:8080&#34;&gt;Storm UI&lt;/a&gt;了。&lt;/p&gt;

&lt;h3 id=&#34;3-启动kafka-broker&#34;&gt;3. 启动Kafka Broker&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ cd $KAFKA_HOME
$ bin/kafka-server-start.sh -daemon config/server.properties
$ bin/kafka-topics.sh --list --zookeeper localhost:2181
$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 10 --topic storm-demo-topic
Created topic &amp;quot;storm-demo-topic&amp;quot;.
$ bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic storm-demo-topic
Topic:storm-demo-topic  PartitionCount:10       ReplicationFactor:1     Configs:
        Topic: storm-demo-topic Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 2    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 3    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 4    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 5    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 6    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 7    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 8    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 9    Leader: 0       Replicas: 0     Isr: 0
$ kafka-console-producer.sh --broker-list localhost:9092 --topic storm-demo-topic
$ kafka-console-consumer.sh --zookeeper localhost:2181 --topic storm-demo-topic --from-beginning
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注意前面有些命令仅仅是为了测试kafka broker运行的情况。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;4-启动hadoop-hdfs&#34;&gt;4. 启动Hadoop(HDFS)&lt;/h3&gt;

&lt;h4 id=&#34;1-修改hadoop的配置文件&#34;&gt;1. 修改Hadoop的配置文件&lt;/h4&gt;

&lt;p&gt;在&lt;code&gt;$HADOOP_HOME/etc/hadoop&lt;/code&gt;目录下有5个文件需要修改:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;core-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.default.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;hdfs-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.name.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/hadoop/hadoopinfra/hdfs/namenode&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.data.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/hadoop/hadoopinfra/hdfs/datanode&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;yarn-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;mapred-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;hadoop-env.sh&lt;/code&gt;
把hadoop-env.sh中的${JAVA_HOME}替换成路径,这里是&lt;code&gt;/opt/jdk&lt;/code&gt;，因为貌似会找不到正确的&lt;code&gt;JAVA_HOME&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;2-验证是否安装成功&#34;&gt;2. 验证是否安装成功&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ hadoop namenode -format
$ start-dfs.sh
$ start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行上面三行语句，观察有没有明显的报错信息。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:50070&#34;&gt;检查HadoopUI&lt;/a&gt;运行是否正常。&lt;br /&gt;
&lt;a href=&#34;http://localhost:8088&#34;&gt;检查Hadoop Applications&lt;/a&gt;(我自己取的名字)运行是否正常。&lt;/p&gt;

&lt;p&gt;至此已经搭建了一个可以运行的hadoop环境，可以移步这里查看关于Storm入门分享详情。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>slf4j配合log4j来给你的应用打log</title>
      <link>http://lovelock.coding.me/java/use-slf4j-and-log4j-to-log-your-applications/</link>
      <pubDate>Thu, 22 Sep 2016 14:16:06 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/use-slf4j-and-log4j-to-log-your-applications/</guid>
      <description>&lt;p&gt;最近刚开始接触Java，被折腾的很难受。因为PHP随便找个环境都能执行，只需要把代码传上去就OK，而Java还需要编译、打包，用mvn执行命令，本来不多的功能就高出一下上百兆的包，然后传到服务器上。后来在运维同学的配合下整了一套只需要我把代码提交到Git仓库，系统自动打包并上传到需要执行的机器上的工作流，虽然比之前好了很多，但还是没有PHP开发的过程流畅。&lt;/p&gt;

&lt;p&gt;说了这么多，是因为Java调试起来不容易，或者说成本高。所以就需要尽量在提交代码之前打尽可能多的日志，帮助后面查找问题。找了一圈，发现最通用的Java日志库是slf4j(Simple Logging Facade for Java)。
这名字都不喜欢，什么破玩意儿。而且这玩意儿其实自己并不记录日志，而只是一个日志的Facade，也就是说它是用来&lt;strong&gt;为其他真正执行记日志功能的类库提供一个标准接口&lt;/strong&gt;的。我也没有兴趣去研究它的代码，想想也是各种设计模式用的6到飞起了。
下面是记录一下怎么用最简单的方式把它添加到自己的项目中，以log4j为例。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;需要添加的dependencies&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;slf4j-log4j12&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;1.7.21&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;后面两个依赖并不是必需的，只需要第一个即可。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;在需要记日志的类中添加这样的一些代码片段&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package com.unixera.mvn;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class App 
{
    private static Logger LOG = LoggerFactory.getLogger(App.class);
    public static void main( String[] args )
    {
        LOG.info(&amp;quot;this is a log&amp;quot;);
        LOG.debug(&amp;quot;This is a log with some information {}&amp;quot;, args.toString());
        System.out.println( &amp;quot;Hello World!&amp;quot; );
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;执行一下，这时候会发现下面的警告信息。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;log4j:WARN No appenders could be found for logger (HelloWorld).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;虽然把我引导去了一篇FAQ，但看完我还是不知道是怎么回事。关于这个问题的答案一搜一大把，这也说明看了FAQ仍然不明白的人远远不止我一个。&lt;br /&gt;
首先要知道这里appender的意思。它其实就是上面说到的真正执行记录日志工作的类库，在这里就是log4j。那它指出的问题就是log4j需要一个初始化配置，而我们并没有给它指定初始化配置。所以这个appender就不知道该怎们工作。&lt;br /&gt;
其实这也很容易理解，毕竟要记日志，你不告诉它日志级别、记录日志的路径和格式，它怎么能帮你决定这些事情呢？&lt;/p&gt;

&lt;p&gt;『小声说两句，其实这也是我写Java的时候感受最深最痛苦的事情，Java太过于讲究设计模式了，把任务的职责分的太细，导致本来很小的一件事都要绕来绕去引入很多东西，虽然这保证了大量菜鸟写起来不容易出错，但也导致了开发效率的降低和开发者的心情问题。』&lt;/p&gt;

&lt;p&gt;言归正传，最简单的办法是需要在main里面新建一个目录&lt;code&gt;resources&lt;/code&gt;，新建文件log4j.properties，写入&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;log4j.rootLogger=TRACE, file, stdout

log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Target=System.out
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSS} %-5p [%c] - %m%n


log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.File=./log/javavillage.log
log4j.appender.file.MaxFileSize=10000KB
log4j.appender.file.MaxBackupIndex=10
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} [%t] %-5p:: %m%n
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这段配置文件做了以下几件事：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;第一行设置了日志级别TRACE，意思是记录TRACE和高于TRACE级别的所有日志，因为TRACE是最低的，所以这里设置的是所有日志都会记录。什么意思呢？log4j有这几个日志级别：TRACE,DEBUG,INFO,WARN,ERROR,FATAL，这几个级别从左到右依次升高。也越来越不详细。也就是说，如果设置了日志级别是INFO，那么&lt;code&gt;LOG.trace()&lt;/code&gt;和&lt;code&gt;LOG.debug()&lt;/code&gt;这种语句会被忽略，而后面四中是会正常执行的。&lt;/li&gt;
&lt;li&gt;日志输出的位置，这里设置的是文件和标准输出&lt;/li&gt;
&lt;li&gt;分别设置了两种输出位置的一些属性，比如输出到标准输出应该是什么样的格式，用什么标准来做文本替换，用什么样的时间格式等等；至于输出到文件的情况就比较复杂了，因为还牵涉到文件的路径，文件大小上限等。具体这个项需要怎么配置我也没有详细的研究，以后如果需要再用到Java并且有需求再说吧。毕竟我不太喜欢Java。需要的可以参考这里&lt;a href=&#34;https://www.tutorialspoint.com/log4j/log4j_logging_files.htm&#34;&gt;1&lt;/a&gt;。&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>使用maven创建和运行Java应用</title>
      <link>http://lovelock.coding.me/java/create-and-run-java-application-with-maven/</link>
      <pubDate>Thu, 22 Sep 2016 14:15:41 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/create-and-run-java-application-with-maven/</guid>
      <description>

&lt;p&gt;最近这段时间在研究Storm，虽然不是研究源码而是研究使用，也让我这个自认为会写Java HelloWorld的菜鸟感到了深深的无力感。尤其是打开一本书，上面第一行代码就执行报错时我的心情可想而知了。&lt;/p&gt;

&lt;h3 id=&#34;1-创建应用&#34;&gt;1. 创建应用&lt;/h3&gt;

&lt;p&gt;因为我最近的使用场景是创建一个普通项目（区别于Web项目），所以直接用&lt;code&gt;mvn archetype:generate&lt;/code&gt;根据提示如果默认一路点下来会生成一个简单应用的骨架。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;注意：如果你在哪里看到&lt;code&gt;mvn archetype:create&lt;/code&gt;这样的写法，而在你的机器上执行出错，不用怀疑，因为你看到的资料太老了，而你用的是新版的maven，按我的写法没有错。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://ww1.sinaimg.cn/large/006y8lVajw1f840c2rryxj31ey100n83.jpg&#34; alt=&#34;创建应用的过程&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如果需要生成webapp类型应用，比如一个基于SpringFramework的应用就不是831了，而是类似这样&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mvn archetype:generate -DarchetypeArtifactId=maven-archetype-webapp\
                        -DinteractiveMode=false \
                        -DgroupId=com.unixera.webapp \
                        -DartifactId=spring-example
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体再到里面怎么写应用这里就不展开了，如果有时间的话会有相关的文章单独来介绍。&lt;/p&gt;

&lt;h3 id=&#34;2-打包应用&#34;&gt;2. 打包应用&lt;/h3&gt;

&lt;p&gt;经过上面的&lt;code&gt;mvn archetype:generate&lt;/code&gt;命令之后，创建的目录类似这样
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f84hsklj4oj30g003ejrn.jpg&#34; alt=&#34;根目录结构&#34; /&gt;
如果再往深了看，是这样的
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f84huul3ihj30jq0j8ab7.jpg&#34; alt=&#34;树状结构&#34; /&gt;
其中最需要注意的就是&lt;code&gt;pom.xml&lt;/code&gt;这个文件，关于maven的简单使用可以参考我之前写的&lt;a href=&#34;http://unixera.com/java/mvn-tutorial-for-novice/&#34;&gt;给Java新手看的mvn指南&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;写完了应用当然是希望执行它，我们知道Java程序是需要编译成字节码之后才能执行的，当你学Java的HelloWorld时一般是告诉你&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;javac HelloWorld.java
java HelloWorld
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这没有问题，但问题是当我们用maven管理一个项目时当然就不能这么去操作了，就像写C代码时直接用gcc编译和写Makefile使用make来管理项目是一样的道理。&lt;/p&gt;

&lt;h4 id=&#34;普通的jar包&#34;&gt;普通的jar包&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;mvn compile&lt;/code&gt;&lt;br /&gt;
这时可以尝试在根目录里执行&lt;code&gt;mvn compile&lt;/code&gt;看看结果。
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f84hzh3knjj31bk0l6dmm.jpg&#34; alt=&#34;&#34; /&gt;
这相当于执行&lt;code&gt;javac&lt;/code&gt;，只不过根据mvn的默认配置，它把编译生成的class文件放在了指定的位置，那它究竟生成了哪些文件呢？
&lt;img src=&#34;http://ww1.sinaimg.cn/large/006y8lVajw1f84i209hshj30xu0x241u.jpg&#34; alt=&#34;&#34; /&gt;
可以看到，它并没有生成我们希望的&lt;strong&gt;可以发布的jar包&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn package&lt;/code&gt;&lt;br /&gt;
我们知道，其实jar包的本质就是zip，是把项目执行需要的资源全部打包（此处不准确，后面会谈）在一起发布的方式。而&lt;code&gt;mvn package&lt;/code&gt;执行的就是打包的过程。
&lt;img src=&#34;http://ww1.sinaimg.cn/large/006y8lVajw1f84i6llp9cj31di194k5p.jpg&#34; alt=&#34;&#34; /&gt;
这里的输出结果也验证了之前的文章中提到的说法。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;compile test package install&lt;/code&gt;是一套流程，执行后面的命令时会重复执行前面的命令&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;再来看&lt;code&gt;mvn package&lt;/code&gt;生成了哪些文件（只看target目录即可）
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f84ibl3z03j30qm0xw78g.jpg&#34; alt=&#34;&#34; /&gt;
重点关注红线标注的jar包，这是我们需要的。
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f84iezqgjrj313c0h0jvy.jpg&#34; alt=&#34;&#34; /&gt;
这就是jar包中的所有东西。你可能知道执行一个jar包需要的命令时&lt;code&gt;java -jar xxxx.jar&lt;/code&gt;，然并卵，这时执行这个是会出错的。解决方法后面会说。
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f84iggkm9nj30vi02at9g.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;使用mvn生成main-class&#34;&gt;使用mvn生成Main-Class&lt;/h4&gt;

&lt;p&gt;下面来解释一下为什么简单的打包并不能生成可以直接执行的jar包。
首先需要了解一点Manifest的知识&lt;a href=&#34;https://docs.oracle.com/javase/tutorial/deployment/jar/manifestindex.html&#34;&gt;2&lt;/a&gt;。简单来说，就是一个jar包需要Manifest文件中包含指定的内容才可以执行。那我们根据前面的经验，用&lt;code&gt;mvn package&lt;/code&gt;生成的jar包中是包含&lt;code&gt;META-INF/MANIFEST.MF&lt;/code&gt;的，实际上jar包运行需要的就是这个所谓的Manifest文件。
打开它看一下
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f88hw52bhvj30kg06caax.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;根据Java SE官方文档&lt;a href=&#34;https://docs.oracle.com/javase/tutorial/deployment/jar/appman.html&#34;&gt;3&lt;/a&gt;, 一个Manifest文件中至少需要包含&lt;code&gt;Main-Class&lt;/code&gt;字段才可以使之使用&lt;code&gt;java -jar&lt;/code&gt;命令执行。&lt;/p&gt;

&lt;p&gt;那我们来试着修改一下
1. 把jar包解压：
&lt;img src=&#34;http://ww2.sinaimg.cn/large/006y8lVagw1f88i2b79rzj30zq0d00wv.jpg&#34; alt=&#34;&#34; /&gt;
2. 修改&lt;code&gt;META-INF/MANIFEST.MF&lt;/code&gt;文件，改成
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f88i3lfb2fj30pc08c0u5.jpg&#34; alt=&#34;&#34; /&gt;
（其中红框中的部分根据自己的实际报名填写）
3. 重新打包
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f88id79j1pj311a0cejv9.jpg&#34; alt=&#34;&#34; /&gt;
4. 再来执行一下
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f88ig6mioaj30ew020q32.jpg&#34; alt=&#34;&#34; /&gt;
没错，成功了。&lt;/p&gt;

&lt;p&gt;所以我们知道了直接生成的jar包不能执行是因为Manifest中缺少了指定Main-Class的指令。那么既然我们使用了mvn，依赖了pom.xml，那mvn当然是能帮我们直接解决这个问题的，不然要自己每次解压、修改再压缩得累死了。&lt;/p&gt;

&lt;p&gt;根据这个答案&lt;a href=&#34;http://stackoverflow.com/questions/574594/how-can-i-create-an-executable-jar-with-dependencies-using-maven&#34;&gt;4&lt;/a&gt;, 在&lt;code&gt;pom.xml&lt;/code&gt;中添加plugin配置即可&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependencies&amp;gt;
...
&amp;lt;/dependencies&amp;gt;

 &amp;lt;build&amp;gt;
    &amp;lt;plugins&amp;gt;
      &amp;lt;plugin&amp;gt;
        &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;maven-assembly-plugin&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;2.6&amp;lt;/version&amp;gt;
        &amp;lt;configuration&amp;gt;
          &amp;lt;archive&amp;gt;
            &amp;lt;manifest&amp;gt;
              &amp;lt;mainClass&amp;gt;com.unixera.mvn.App&amp;lt;/mainClass&amp;gt;
            &amp;lt;/manifest&amp;gt;
          &amp;lt;/archive&amp;gt;
        &amp;lt;/configuration&amp;gt;
      &amp;lt;/plugin&amp;gt;
    &amp;lt;/plugins&amp;gt;
  &amp;lt;/build&amp;gt;
&amp;lt;/project&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再执行&lt;code&gt;mvn package&lt;/code&gt;生成的jar包的Manifest中就会带有Main-Class的信息了。&lt;/p&gt;

&lt;h4 id=&#34;jar-with-dependencies&#34;&gt;jar-with-dependencies&lt;/h4&gt;

&lt;p&gt;现在我们终于有了一个可以正常工作的类了，不妨给它添加一个依赖吧。比如我在另外一篇文章中提到的slf4j&lt;a href=&#34;http://unixera.com/java/use-slf4j-and-log4j-to-log-your-applications/&#34;&gt;5&lt;/a&gt;。
具体做法可以参考该文章。这里只谈打包的问题。现在我们的pom.xml文件中在dependencies段中应该包含这样一段：
&lt;img src=&#34;http://ww2.sinaimg.cn/large/006y8lVajw1f96nuir9vnj30m405ygmi.jpg&#34; alt=&#34;&#34; /&gt;
我在App.java中添加了slf4j的用例。按照之前的做法，仍然
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f88lgk9cxxj31cs1787fv.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f88lgxno8yj311u090jv3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;怎么回事？明明已经引入了需要的包了，为什么会找不到类呢？
问题还是出在jar包的打包方式上。
有PHP使用经验并且用过Composer的同学可能知道，Composer管理依赖的方式非常简单，就是把你的项目需要的代码下载到你项目的目录中，然后通过Composer的Autoload功能把它们加载到使用它们的地方。
但Java不是这样，或者说mvn不是这样。
首先，mvn把所有的依赖的包都放在了用户的根目录下，默认是&lt;code&gt;$HOME/.m2/repository&lt;/code&gt;，在这个目录下可以看到各个vendor的各种版本的包。但是在目前我们配置的这种模式下，打成的jar包并不会包含这些东西，而且在执行jar包时，也不会去相应的目录去查找需要的包。
&lt;strong&gt;其实就是动态加载&lt;/strong&gt;。和写C时用到的.so文件是一个道理。如果希望我们的程序能到处能运行的话，最好把它的依赖都打成.a文件，然后和项目代码打成一个完整的包，所有依赖的类库都在同一个包里就不存在这种问题了。
所以需要引入一个新的打包方式&lt;code&gt;jar-with-dependencies&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;根据同样根据上面那个答案,还需要添加如下的配置
&lt;img src=&#34;http://ww2.sinaimg.cn/large/006y8lVajw1f96nstiz0qj30uy0ssn0y.jpg&#34; alt=&#34;&#34; /&gt;
再重新执行上面的过程，可以运行了。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;本来在上面的文章中引用的是maven的官方文档，后来在实际使用中发现那种方式经常失效，对照自己试验成功后的文章也不奏效，于是找到了前面提到的答案，看来即使是官方文档，也还是需要民间的工程师们来发现最佳实践啊。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;3-执行应用&#34;&gt;3. 执行应用&lt;/h3&gt;

&lt;p&gt;执行应用就很简单了，直接从java -help就可以获取很多信息，就不展开说了。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;java -cp $CLASSPATH -jar /path/to/jar-with-dependencies.jar&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;本文旨在引导读者一步一步创建可执行的jar包，包括工程骨架的创建，依赖管理，打包方式，重点谈了下打包方式对生成的jar包功能的影响。引用了不少官方文档，本文只是简略的描述了一下整个过程，更详细的配置可以追随我引用的文档继续研究。&lt;/p&gt;

&lt;p&gt;可能有读者会问为什么我用截图而不是代码块的方式来演示，其实我是怕你们偷懒哈哈哈。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DeepinLinux 体验报告</title>
      <link>http://lovelock.coding.me/linux/deepin-linux-experience/</link>
      <pubDate>Sat, 03 Sep 2016 17:20:45 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/linux/deepin-linux-experience/</guid>
      <description>

&lt;h2 id=&#34;为什么要写这篇文章&#34;&gt;为什么要写这篇文章&lt;/h2&gt;

&lt;p&gt;今天忽然看到知乎上的通知，发现两年前写的一篇答案现在还有人在关注和评论&lt;a href=&#34;https://www.zhihu.com/question/19694358/answer/26227403?group_id=748099576984006656#comment-158674705&#34;&gt;有人用国产的deepin吗？和其它Linux版本相比，有什么优点和不足呢？&amp;ndash;郁蓝的答案&lt;/a&gt;。也是无意间看到了有人让我再更新一下体验的要求（其实这个评论是很早之前的了，只不过今天刚注意到）。
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814221945.png&#34; alt=&#34;知乎答案评论截图&#34; /&gt;
虽然我也不是什么大神，但从我个人的感情来说，我还是很希望深度能做的更好的，所以就花了几个小时真的感受了一下。下面是我认为还比较中肯的看法。&lt;/p&gt;

&lt;h2 id=&#34;体验&#34;&gt;体验&lt;/h2&gt;

&lt;h3 id=&#34;1-官方网站-https-www-deepin-org&#34;&gt;1. &lt;a href=&#34;https://www.deepin.org/&#34;&gt;官方网站&lt;/a&gt;&lt;/h3&gt;

&lt;h4 id=&#34;华而不实&#34;&gt;华而不实&lt;/h4&gt;

&lt;p&gt;不得不说，这个网站初看上去还是挺好看的，但实际一看就是一个展示页，而且有相当的&lt;strong&gt;应付了事&lt;/strong&gt;的成分。那个国际排名也多少有点忽悠的感觉。。。
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814225102.png&#34; alt=&#34;深度官网展示&#34; /&gt;
因为对细节的展示很少，文档也是七零八碎，像我这样阅发行版无数的人当然很快就找到了安装方法（其实也没有找，只是按照经验），但对于完全不懂Linux的新手来说，很可能看一下就撤了。&lt;/p&gt;

&lt;h4 id=&#34;功能缺失&#34;&gt;功能缺失&lt;/h4&gt;

&lt;p&gt;即便这样，我觉得很多我关心的信息在网站上都没有展示出来。我是一名软件开发人员，说的更笼统一些是一名上班族，那从一个上班族的角度来看，如果要我从Windows迁移到Deepin OS，我会关注哪些东西？当然是办公软件的使用。这个&lt;strong&gt;办公软件&lt;/strong&gt;是广义上的，包括&lt;strong&gt;QQ,RTX,Office,搜狗输入法，邮件&lt;/strong&gt;等等，这个问题，产品经理肯定想过，因为我用了之后发现确实他们已经解决了，但在页面上并没有展示出来。甚至，我的希望是&lt;strong&gt;在页面上能有一个搜索框，我在安装之前就能知道哪些软件我能用，让我不会产生后顾之忧&lt;/strong&gt;。&lt;/p&gt;

&lt;h4 id=&#34;细节不到位&#34;&gt;细节不到位&lt;/h4&gt;

&lt;p&gt;我甚至点到了社区板块，看了一下更新日志，比如这篇&lt;a href=&#34;http://blog.deepin.org/2016/08/update-record-of-applications-in-deepin-store-2016-08/&#34;&gt;深度商店应用更新记录汇总2016-08&lt;/a&gt;。这样的汇总我实在是不想看，感觉就像是用awk+xargs处理了一下只把应用名打印出来的样子。我看到了两个问题：
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814225410.png&#34; alt=&#34;社区网页展示&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- 没有版本号，**差评**
- 应用名太拥挤，看起来不直观
- 层级不能回退，都实现成这样的控件竟然不能点击，简直不能忍
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我看到右侧其实是又很多这种更新汇总的，我觉得这作为一个正常人是都能看得到的问题，但就是不知道为什么那么久了都还一直这样。这期的我看到下面又评论说到没有版本号的事情，管理员（不知道是不是）说下次会带上。&lt;/p&gt;

&lt;h4 id=&#34;小结&#34;&gt;小结&lt;/h4&gt;

&lt;p&gt;总的感觉就是&lt;strong&gt;华而不实&lt;/strong&gt;，对细节的考虑不到位，简直浪费了程序员们的辛苦劳动。东西再好，展示的窗口都不做好，怎么吸引人呢？我觉得要么就传统一些，做一个像&lt;a href=&#34;https://www.archlinux.org/&#34;&gt;ArchLinux官网&lt;/a&gt;那样的纯展示性网站，引导用户去一个完备的Wiki站点，要么就学一学现在的手机厂商，把现代化的网页做的详细一些，别让用户费了半天劲把页面从最上面拉到最下面了却发现什么也没看明白。&lt;/p&gt;

&lt;h3 id=&#34;1-安装直观感受&#34;&gt;1. 安装直观感受&lt;/h3&gt;

&lt;p&gt;没有LiveCD，差评。
很不理解的一点，我刻好了优盘启动盘准备先在LiveCD里体验一下，看到启动项只有一个&lt;strong&gt;Start installation&lt;/strong&gt;我就懵逼了。。。这是跟国产的流氓软件学的，不让尝，先买了再说么？&lt;/p&gt;

&lt;h3 id=&#34;2-缺点&#34;&gt;2. 缺点&lt;/h3&gt;

&lt;p&gt;整个安装界面就有些搞不清楚。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;没有保留像Ubuntu那样可以&lt;strong&gt;对用户透明的和其他系统共存&lt;/strong&gt;的功能。（貌似最近的这版从基于Ubuntu迁移到了Debian Sid，这样就可以解释了，关于迁移的事情后面会说）&lt;/li&gt;
&lt;li&gt;对高清屏的支持不好，这在上面的截图里都已经可以看到了，我的电脑是15寸1080P屏幕，显示的字体太小，伤眼睛&lt;/li&gt;
&lt;li&gt;选择完语言之后就没得回去了，只能往后，不能往前，这有点蛋疼&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;好在安装过程很顺利，也很快。这点很赞。&lt;/p&gt;

&lt;h3 id=&#34;3-亮点&#34;&gt;3. 亮点&lt;/h3&gt;

&lt;p&gt;吐槽完了也得有点亮点吧，也不枉我把Ubuntu分区都干掉装这个啊。界面风格没啥好说的，还提供了三种模式
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814180441.png&#34; alt=&#34;默认Dock模式&#34; /&gt;
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814230948.png&#34; alt=&#34;Windows Dock模式1&#34; /&gt;
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814231109.png&#34; alt=&#34;Windows Dock模式2&#34; /&gt;
看完上面三张图，你有什么感受？对，没有自己的灵魂，学谁都没学像。学苹果却没有Magic动画，学Windows又没有开始菜单。而且控制面板放在最右边是什么鬼？是为了适应触摸屏？模仿Windows8的交互？看吧，Windows10已经回归了，我估计这个控制面板也要改成传统模式了。
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814231725.png&#34; alt=&#34;控制面板&#34; /&gt;&lt;/p&gt;

&lt;p&gt;说了这些发现还是吐槽，真正的亮点在终端。貌似是修改版的Quake，但我可没有在Quake里面找到过这个功能，简直贴心。
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814232511.png&#34; alt=&#34;SSH管理功能&#34; /&gt;
试了一下，简直弱鸡啊，也仅仅是个管理，连私钥都不支持。好吧，完成度不高，忍了。&lt;/p&gt;

&lt;p&gt;应用商店的资源还是挺丰富的，常用的差不多都有——其实本来Gnome也都有了。重点在于深度为用户提供了几乎0成本使用QQ的机会，这点很重要，一直以来对中国用户来说，Linux最大的痛点不就是没有QQ么？
其他软件也是开箱即用，完整度还可以，但完成度有待提高。&lt;/p&gt;

&lt;h3 id=&#34;4-混乱&#34;&gt;4. 混乱&lt;/h3&gt;

&lt;p&gt;整个一下午用下来最大的感受就是&lt;strong&gt;混乱&lt;/strong&gt;，看起来深度桌面更像是基于Gnome的，也带了不少Gnome系的应用，但它其实又在Gnome的基础上加上了自己的想法，让体验变得更加不统一了。比如应用打开首选项的方式和图标都不统一，有些按钮的位置那是真隐晦，谁能看出来那是按钮我服谁。
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814235541.png&#34; alt=&#34;界面高度不统一&#34; /&gt;
至于其中的某些Qt的应用带了的体验不一致这里就不说了，目前也没什么好的解决办法。&lt;/p&gt;

&lt;h3 id=&#34;5-期望&#34;&gt;5. 期望&lt;/h3&gt;

&lt;p&gt;总的来说，功能做的还是不错的，因为加入了Windows上常用的软件，使得它基本上算是一个开箱即用的操作系统。尤其是搜狗输入法的加成，让它对普通用户的友好程度大增。我搜了一下，软件源里面是包含Jetbrains家的应用的。只不过版本比较老了而已。看起来也没有对其进行什么修改，不知道是什么耽搁了它和上游的同步。现在这个Quake的SSH管理功能太弱鸡，如果可以，我希望能把Windows上的XShell引进来，毕竟Mac和Linux上都没有一款这么好用的终端。&lt;/p&gt;

&lt;p&gt;总之，深度的这款操作系统还是很能解决中国人用Linux的痛点的，这些痛点真的不是加个天气软件和农历日历就能解决的。很多使用习惯的问题需要去引导和克服。有人说，有这闲工夫通过各种技术手段让Windows上的软件跑在Linux上还不如大力发展Linux的原生应用，简直是Naive，如果原生的这么好做，也就不会有CrossOver这样的收费软件了。这毕竟是软件提供商的问题，他们不重视，作为用户也只能想别的办法了，起码在目前看来，这种方式是最行之有效又一针见血的。&lt;/p&gt;

&lt;p&gt;我想提的建议是，产品经理要是没什么大问题的话就换了吧，现在的真心不称职。包括网站的和桌面端的，抄别人的东西都抄不到精髓，那只能说自己都不知道想抄什么。那壁纸怎么那么像一加天气的背景呢？看我还是个耿直的boy，一加的ROM不行，确实是开发不给力，而Deepin做不好，产品要负大部分责任。&lt;/p&gt;

&lt;p&gt;感谢深度在Linux国产化的进程中的突出贡献。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>给Java新手看的mvn指南</title>
      <link>http://lovelock.coding.me/java/mvn-tutorial-for-novice/</link>
      <pubDate>Sun, 28 Aug 2016 14:29:16 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/mvn-tutorial-for-novice/</guid>
      <description>

&lt;h2 id=&#34;官方定义&#34;&gt;官方定义&lt;/h2&gt;

&lt;p&gt;Maven是基于项目对象模型，可以通过一小段描述信息来管理项目的构建、报告和文档的软件管理工具。&lt;/p&gt;

&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;

&lt;p&gt;Maven的使用过程中最经常用到的就是依赖管理了，一个依赖也就是一个包，是包含了几个属性的
- &lt;code&gt;groupId&lt;/code&gt; 通常是公司域名的反写加上项目名，比如&lt;code&gt;com.unixera.mvndemo&lt;/code&gt;
- &lt;code&gt;artifactId&lt;/code&gt; 模块名，比如&lt;code&gt;project1&lt;/code&gt;
- &lt;code&gt;version&lt;/code&gt; 版本号，经常见到的是形如&lt;code&gt;1.0.0-SNAPSHOT&lt;/code&gt;这种，即快照版本，还有&lt;code&gt;RELEASE&lt;/code&gt;等。&lt;/p&gt;

&lt;h2 id=&#34;规定&#34;&gt;规定&lt;/h2&gt;

&lt;p&gt;它规定的目录结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-src 
 -main
  -java
   -packagename
 -test
  -java
   -packagename
 -resource
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;基础命令&#34;&gt;基础命令&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mvn compile&lt;/code&gt; 编译项目&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn test&lt;/code&gt; 测试&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn package&lt;/code&gt; 打包&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn clean&lt;/code&gt; 删除已经生成的测试报告和字节码文件，其实就是删除target文件夹&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn install&lt;/code&gt; 安装jar包到本地目录中&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面这5个过程如果执行后面的，前面的也会自动执行。也就是说后面的命令是依赖前面的命令的。&lt;/p&gt;

&lt;h2 id=&#34;经常遇到的问题&#34;&gt;经常遇到的问题&lt;/h2&gt;

&lt;h3 id=&#34;1-间接依赖&#34;&gt;1. 间接依赖&lt;/h3&gt;

&lt;p&gt;A依赖B，B依赖C，那么A就间接的依赖了C，如果要显式的声明A不依赖C，可以在A的pom.xml中加入&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;
&amp;lt;dependecy&amp;gt;
	&amp;lt;groupId&amp;gt;BgroupId&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;BartifactId&amp;lt;/artifactId&amp;gt;
	&amp;lt;version&amp;gt;1.2.3&amp;lt;/version&amp;gt;
	&amp;lt;exclusions&amp;gt;
		&amp;lt;exclusion&amp;gt;
			&amp;lt;groupId&amp;gt;CgroupId&amp;lt;/groupId&amp;gt;
			&amp;lt;artifactId&amp;gt;CartifactId&amp;lt;/artifactId&amp;gt;
			&amp;lt;version&amp;gt;1.2.3&amp;lt;/version&amp;gt;
		&amp;lt;/exclusion&amp;gt;
	&amp;lt;/exclusions&amp;gt;
&amp;lt;/dependecy&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-如何添加依赖&#34;&gt;2. 如何添加依赖&lt;/h3&gt;

&lt;p&gt;比如项目要使用servlet，那就去&lt;a href=&#34;http://search.maven.org/&#34;&gt;全球中央仓库&lt;/a&gt;查找包名和相应的版本号,如图所示&lt;img src=&#34;http://ww4.sinaimg.cn/large/7853084cjw1f79btj2nb8j20fl0f9q4b.jpg&#34; alt=&#34;&#34; /&gt;。从中复制Apache Maven下面的一段XML粘贴到相应的&lt;code&gt;&amp;lt;dependencies&amp;gt;&amp;lt;/dependencies&amp;gt;&lt;/code&gt;中即可。&lt;/p&gt;

&lt;h3 id=&#34;3-变量的使用&#34;&gt;3. 变量的使用&lt;/h3&gt;

&lt;p&gt;有时在一个pom.xml文件中会看到有&lt;code&gt;${project.version}&lt;/code&gt;这种写法，那一看就是一个引用，这个东西是在&lt;code&gt;&amp;lt;properties&amp;gt;&amp;lt;/properties&amp;gt;&lt;/code&gt;中定义的，比如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;properties&amp;gt;
    &amp;lt;maven.compile.source&amp;gt;1.5&amp;lt;/maven.compile.source&amp;gt;
    &amp;lt;maven.compile.target&amp;gt;1.5&amp;lt;/maven.compile.target&amp;gt;
&amp;lt;/properties&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样定义了之后在后面就可以用&lt;code&gt;${maven.compile.source}&lt;/code&gt;来引用了。&lt;/p&gt;

&lt;h3 id=&#34;4-一个项目下多个模块重复依赖一个包&#34;&gt;4. 一个项目下多个模块重复依赖一个包&lt;/h3&gt;

&lt;p&gt;下面着重说一下如何利用Maven的继承关系简化项目的POM配置。&lt;/p&gt;

&lt;h4 id=&#34;在项目的根目录下创建pom-xml&#34;&gt;在项目的根目录下创建pom.xml&lt;/h4&gt;

&lt;p&gt;还以上面的项目名为例，比如root目录是project,则在project目录里创建pom.xml&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;project xmlns=&amp;quot;http://maven.apache.org/POM/4.0.0&amp;quot; xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot;
	xsi:schemaLocation=&amp;quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;quot;&amp;gt;
	&amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;
	&amp;lt;groupId&amp;gt;com.unixera&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;root&amp;lt;/artifactId&amp;gt;
	&amp;lt;version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/version&amp;gt;
	&amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt;
	
	&amp;lt;properties&amp;gt;
	    &amp;lt;project.version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/project.version&amp;gt;
	    &amp;lt;junit.version&amp;gt;4.10&amp;lt;/junit.version&amp;gt;
	    &amp;lt;jmock.version&amp;gt;2.8.2&amp;lt;/jmock.version&amp;gt;
	&amp;lt;/properties&amp;gt;
	
	&amp;lt;dependencies&amp;gt;
	    &amp;lt;dependency&amp;gt;
			&amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;
			&amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;
			&amp;lt;version&amp;gt;${junit.version}&amp;lt;/version&amp;gt;
			&amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
		&amp;lt;/dependency&amp;gt;
		&amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.jmock&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;jmock&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;${jmock.version}&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
	&amp;lt;/dependencies&amp;gt;
&amp;lt;/project&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就声明了该项目需要依赖junit，那么里面的子项目就用&lt;code&gt;mvn archetype:generate&lt;/code&gt;来交互式的生成，比如&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Choose org.apache.maven.archetypes:maven-archetype-quickstart version:
1: 1.0-alpha-1
2: 1.0-alpha-2
3: 1.0-alpha-3
4: 1.0-alpha-4
5: 1.0
6: 1.1
Choose a number: 6: 6
Define value for property &#39;groupId&#39;: : com.unixera.mvndemo
Define value for property &#39;artifactId&#39;: : project1
Define value for property &#39;version&#39;:  1.0-SNAPSHOT: :
Define value for property &#39;package&#39;:  com.unixera.mvndemo: :
Confirm properties configuration:
groupId: com.unixera.mvndemo
artifactId: project1
version: 1.0-SNAPSHOT
package: com.unixera.mvndemo
 Y: :
[INFO] ----------------------------------------------------------------------------
[INFO] Using following parameters for creating project from Old (1.x) Archetype: maven-archetype-quickstart:1.1
[INFO] ----------------------------------------------------------------------------
[INFO] Parameter: basedir, Value: /Users/frost/IdeaProjects
[INFO] Parameter: package, Value: com.unixera.mvndemo
[INFO] Parameter: groupId, Value: com.unixera.mvndemo
[INFO] Parameter: artifactId, Value: project1
[INFO] Parameter: packageName, Value: com.unixera.mvndemo
[INFO] Parameter: version, Value: 1.0-SNAPSHOT
[INFO] project created from Old (1.x) Archetype in dir: /Users/frost/IdeaProjects/project1
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 35.492 s
[INFO] Finished at: 2016-08-28T14:16:28+08:00
[INFO] Final Memory: 13M/201M
[INFO] ------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入&lt;code&gt;project&lt;/code&gt;目录，打开&lt;code&gt;pom.xml&lt;/code&gt;，可以看到mvn生成的项目已经默认依赖了junit，那我们来修改一下让它依赖parent所定义的junit。
首先加上&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;parent&amp;gt;
	&amp;lt;groupId&amp;gt;com.unixera.mvdemo&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;root&amp;lt;/artifactId&amp;gt;
	&amp;lt;version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/version&amp;gt;
&amp;lt;/parent&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就可以把junit的依赖放心的删掉了，因为它已经认了root做parent，parent的依赖就是它的依赖了。&lt;br /&gt;
那如果parent的某些依赖它并不需要呢？可以在子项目中添加&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependencyManagement&amp;gt;
    &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;com.unixera.mvndemo&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;root&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/version&amp;gt;
            &amp;lt;exclusions&amp;gt;
                &amp;lt;exclusion&amp;gt;
                    &amp;lt;groupId&amp;gt;org.jmock&amp;lt;/groupId&amp;gt;
                    &amp;lt;artifactId&amp;gt;jmock&amp;lt;/artifactId&amp;gt;
                    &amp;lt;version&amp;gt;2.8.2&amp;lt;/version&amp;gt;
                &amp;lt;/exclusion&amp;gt;
            &amp;lt;/exclusions&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;
&amp;lt;/dependencyManagement&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样子项目就不依赖jmock模块了。&lt;/p&gt;

&lt;p&gt;当然mvn的使用远远不止这些，这里记录一些目前使用到的，后面如果还继续回写Java的话会再更新一下。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
