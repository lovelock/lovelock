<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Me &amp; Web</title>
    <link>http://lovelock.coding.me/index.xml</link>
    <description>Recent content on Me &amp; Web</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>frostwong@gmail.com (Frost Wong)</managingEditor>
    <webMaster>frostwong@gmail.com (Frost Wong)</webMaster>
    <copyright>(c) 2013-2016 Frost Wong. All rights reserved.</copyright>
    <lastBuildDate>Fri, 14 Oct 2016 15:40:58 +0800</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>用Bash编写漂亮的命令行程序</title>
      <link>http://lovelock.coding.me/linux/handle-with-bash-options/</link>
      <pubDate>Fri, 14 Oct 2016 15:40:58 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/linux/handle-with-bash-options/</guid>
      <description>

&lt;p&gt;我学着写这篇是因为前面写了一个&lt;a href=&#34;http://unixera.com/virtualization/create-a-virtual-machine-with-vboxmanage/&#34;&gt;使用VBoxManage创建虚拟机&lt;/a&gt;，后来我发现这个过程太繁琐，就写了一个脚本，但脚本里面写死太多东西就没有了灵活性，所以就需要支持各种选项和参数。而因为这些命令都是很直观的命令，用Shell脚本就已经很完美的实现了这些功能。&lt;/p&gt;

&lt;p&gt;代码可以在&lt;a href=&#34;https://github.com/lovelock/bash_opts&#34;&gt;这里&lt;/a&gt;下载。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;本文基于&lt;a href=&#34;http://stackoverflow.com/questions/192249/how-do-i-parse-command-line-arguments-in-bash&#34;&gt;StackOverFlow&lt;/a&gt;上的这篇答案。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;首先要知道几个内建变量&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;内建变量&lt;/th&gt;
&lt;th&gt;意义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;执行的脚本文件名&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$1/$2&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;这些带数字（&amp;gt;0）的表示执行脚本后面对应的第N个参数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$#&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;脚本执行时的参数个数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$@&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;所有参数作为一个类似数组的结构&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$*&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;和&lt;code&gt;$@&lt;/code&gt;对比，前面的是一个数组结构，这个是用空格分开的多个变量&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$-&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;当前脚本执行时的附加参数，比如&lt;code&gt;-x&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$_&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;最近的参数（或者当前脚本执行时所在的目录）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$IFS&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;输入字段分隔符，一般是空格&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$!&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;最近的后台执行的命令，这个很常用，在vim中按Ctrl-z会把vim放在后台，在同样的终端中按&lt;code&gt;%!&lt;/code&gt;就会把他切回到前台&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$$&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;当前脚本的pid（进程号）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$?&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;脚本执行后的返回值，一般0代表成功，这个0就是我们用C写程序时&lt;code&gt;main&lt;/code&gt;方法中最后的&lt;code&gt;return 0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;使用空格分隔选项和相应的参数&#34;&gt;使用空格分隔选项和相应的参数&lt;/h2&gt;

&lt;p&gt;用法: &lt;code&gt;bash script.sh -e .php --path .&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/usr/bin/env bash

while [[ $# -gt 1 ]]
do
    KEY=$1

    case $KEY in
        -e|--extension)
            EXTENSION=$2
            shift
            ;;
        -s|--search-path)
            SEARCHPATH=$2
            shift
            ;;
        *)
            ;;
    esac
    shift


done

echo FILE_EXTENSION=${EXTENSION}
echo SEARCH_PATH=${SEARCHPATH}
echo &amp;quot;Number files in ${SEARCH_PATH} with ${EXTENSION}:&amp;quot; $(ls -1 &amp;quot;${SEARCHPATH}&amp;quot;/*.&amp;quot;${EXTENSION}&amp;quot; | wc -l)

if [[ -n $1 ]]; then
    echo &amp;quot;Last line of file specified as non-opt/last argument:&amp;quot;
    tail -1 $1
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该脚本接收两个参数，可以用&lt;strong&gt;长参数(&amp;ndash;extension)&lt;/strong&gt;也可以用&lt;strong&gt;短参数(-e)&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;示例： &lt;code&gt;$ bash space.sh -e py --search-path .&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;使用等号分隔选项和参数&#34;&gt;使用等号分隔选项和参数&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/usr/bin/env bash

for i in $@
do
    case $i in
        -e=*|--extension=*)
            EXTENSION=&amp;quot;${i#*=}&amp;quot;
            shift # past argument=value
            ;;
        -s=*|--searchpath=*)
            SEARCHPATH=&amp;quot;${i#*=}&amp;quot;
            shift # past argument=value
            ;;
        *)
            # unknown option
            ;;
    esac
done

echo &amp;quot;FILE EXTENSION  = ${EXTENSION}&amp;quot;
echo &amp;quot;SEARCH PATH     = ${SEARCHPATH}&amp;quot;
echo &amp;quot;Number files in SEARCH PATH with EXTENSION:&amp;quot; $(ls -1 &amp;quot;${SEARCHPATH}&amp;quot;/*.&amp;quot;${EXTENSION}&amp;quot; | wc -l)

if [[ -n $1 ]]; then
    echo &amp;quot;Last line of file specified as non-opt/last argument:&amp;quot;
    tail -1 $1
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该脚本接收两个参数，可以用&lt;strong&gt;长参数(&amp;ndash;extension)&lt;/strong&gt;也可以用&lt;strong&gt;短参数(-e)&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;示例： &lt;code&gt;$ bash space.sh -e=php --search-path=.&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;使用-getops&#34;&gt;使用&lt;code&gt;getops&lt;/code&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/usr/bin/env bash

# A POSIX variable
OPTIND=1         # Reset in case getopts has been used previously in the shell.

# Initialize our own variables:
EXTENSION=&amp;quot;&amp;quot;
VERBOSE=&amp;quot;-1&amp;quot;

while getopts &amp;quot;h?ve:&amp;quot; opt; do
    case &amp;quot;${opt}&amp;quot; in
        h|\?)
            show_help
            exit 0
            ;;
        v)  VERBOSE=&amp;quot;-l&amp;quot;
            ;;
        e)  EXTENSION=$OPTARG
            ;;
    esac
done

shift $((OPTIND-1))

[ &amp;quot;$1&amp;quot; = &amp;quot;--&amp;quot; ] &amp;amp;&amp;amp; shift

ls ${VERBOSE} *.${EXTENSION}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这种方式只能使用短参数不支持长参数，其中&lt;code&gt;${OPTARG}&lt;/code&gt;表示对应的这条选项的值。&lt;strong&gt;如果该选项后面会带参数，就要在其后面带&lt;code&gt;:&lt;/code&gt;&lt;/strong&gt;，比如在本例中，&lt;code&gt;-e&lt;/code&gt;选项后面需要带参数，那么&lt;code&gt;while getopts &amp;quot;h?ve:&amp;quot; opt; do&lt;/code&gt;这行&lt;code&gt;e&lt;/code&gt;的后面就有一个冒号了，不然你的在代码中是无法取到参数的。&lt;/p&gt;

&lt;p&gt;示例： &lt;code&gt;bash getopts.sh -v -e php&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;关于getopts的更多内容可以使用&lt;code&gt;help getopts&lt;/code&gt;查看。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用VBoxManage创建虚拟机</title>
      <link>http://lovelock.coding.me/virtualization/create-a-virtual-machine-with-vboxmanage/</link>
      <pubDate>Thu, 13 Oct 2016 16:35:22 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/virtualization/create-a-virtual-machine-with-vboxmanage/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;最近没有产品需求，就深入的研究一下大数据吧，第一步先要搭建一个集群，前面已经写了一篇关于搭建“伪集群”的文章，还是希望更完整的理解这套东西，还是弄一套真正的集群吧。但是没有机器，就只能拿本地的台式机搞起来了。&lt;/p&gt;

&lt;p&gt;本文主要介绍了如何使用VirtualBox命令行工具VBoxManage创建和维护虚拟机。官方文档中说到VBoxManage的功能是比GUI的VirtualBox要更完整的，但其实我也用不到那么完整的功能，我能想到的主要有以下几点，参照官方文档来逐个完成。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;创建一个虚拟机&lt;/li&gt;
&lt;li&gt;给虚拟机配置网络、CPU核心、内存、磁盘驱动器&lt;/li&gt;
&lt;li&gt;复制（clone）虚拟机&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我使用的环境如下：
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/machine.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;##
&amp;gt; 看到这张图片，我想说一句关于字体的，Windows下绝对是Consolas最耐看；Linux下SourceCodePro最好看；Mac下命令行用Monaco，但IDE里面用Monaco最觉得不能认真写代码了，太花了，还是SourceCodePro比较正常一点，呼呼&lt;/p&gt;

&lt;p&gt;下面开搞吧。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一定要确认你的VirtualBox安装了Extension Pack， 如果没有马上根据你的发行版或者去官网下载之后安装，否则无法远程连接虚拟机。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;创建虚拟机&#34;&gt;创建虚拟机&lt;/h2&gt;

&lt;h3 id=&#34;知识&#34;&gt;知识&lt;/h3&gt;

&lt;h4 id=&#34;1-vboxmanage-createmedium&#34;&gt;1. &lt;code&gt;VBoxManage createmedium&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;首先要创建一块磁盘。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;--filename &amp;lt;name&amp;gt;&lt;/code&gt; 创建的设备的名字&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--format VDI|VMDK|VHD&lt;/code&gt; 创建的设备的格式，默认是vdi，当年我做云主机运维的时候还测试过各种虚拟化磁盘格式的性能，vdi的性能是所有可选项里面最快的，值得信赖&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--size &amp;lt;megabytes&amp;gt;&lt;/code&gt; 创建的磁盘的大小，以M为单位&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;注意这个命令创建的磁盘是位于你当前所在的目录的，所以为了避免后面的问题，你最好在你想放在的位置执行这个命令。&lt;/p&gt;

&lt;h4 id=&#34;2-vboxmanage-createvm&#34;&gt;2. &lt;code&gt;VBoxManage createvm&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;然后创建一个虚拟机。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;--name &amp;lt;name&amp;gt;&lt;/code&gt; 指定虚拟机的名字，还会在&lt;code&gt;~/.config/VirtualBox/Machines&lt;/code&gt;目录下创建同名的xml文件，如果该虚拟机被重命名，该xml文件也会被自动重命名。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--basefolder &amp;lt;path&amp;gt;&lt;/code&gt; 指定上述的Machines目录，如果指定了这个目录，新创建时还是会在这个目录下产生xml文件，但当虚拟机被重命名时，该xml不会被重命名。所以这里我觉得还是不要改为好，虽然通常也不会去重命名虚拟机。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--groups &amp;lt;group&amp;gt;&lt;/code&gt; 指定虚拟机组，总是从&lt;code&gt;/&lt;/code&gt;开始，可以嵌套，默认是&lt;code&gt;/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--ostype &amp;lt;ostype&amp;gt;&lt;/code&gt; 指定虚拟机的操作系统类型，具体支持的操作系统类型可以使用&lt;code&gt;VBoxManage list ostypes&lt;/code&gt;来查看。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--uuid &amp;lt;uuid&amp;gt;&lt;/code&gt; 指定虚拟机的UUID，这个id在宿主机的命名空间内必须是唯一的，如果指定了虚拟机组，则在组内必须是唯一的，如果不指定，会自动生成，所以这个其实也每必要指定。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;默认情况下，这个命令只会创建一个xml文件，而并不会把虚拟机注册到系统中，可以使用&lt;code&gt;--register&lt;/code&gt;选项或者单独执行&lt;code&gt;VBoxManage register &amp;lt;uuid&amp;gt;&lt;/code&gt;来执行注册。&lt;/p&gt;

&lt;h4 id=&#34;3-vboxmanage-storagectl&#34;&gt;3. &lt;code&gt;VBoxManage storagectl&lt;/code&gt;&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;uuid|vmname&amp;gt;&lt;/code&gt; 指定要操作的虚拟机，可以使用前面创建时指定的名字，或者自动生成的uuid&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--name &amp;lt;name&amp;gt;&lt;/code&gt; 要创建的控制器的名字&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--controller&lt;/code&gt; 控制器，这个我也不太懂，一般电脑上是ACHI，这里就选IntelAHCI吧&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--add&lt;/code&gt; 添加的控制器类型，因为我们要创建的是磁盘驱动器，所以选择sata&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;这里其实是瞎说的，我也不太懂电脑硬件，这些概念不了解，就照着熟悉的来吧。需要创建两种类型的设备控制器，一个是磁盘控制器，用来管理硬盘，一个是光驱，用来管理ISO文件。这个很容易理解，这一步是创建控制器，而而这控制的东西，磁盘是前面创建的，iso是先前下载好的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;4-vboxmanage-storageattach&#34;&gt;4. &lt;code&gt;VBoxManage storageattach&lt;/code&gt;&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;uuid|vmname&amp;gt;&lt;/code&gt; 指定要操作的虚拟机，可以使用前面创建时指定的名字，或者自动生成的uuid&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--storagectl &amp;lt;name&amp;gt;&lt;/code&gt; 这就是上面那个&lt;code&gt;storagectl&lt;/code&gt;命令时的&lt;code&gt;--name&lt;/code&gt;选项指定的参数了&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--port&lt;/code&gt; 端口号&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--device&lt;/code&gt; 设备号&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--type&lt;/code&gt; 设备类型&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--medium&lt;/code&gt; 指定创建磁盘文件，即vdi文件&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;把创建的磁盘驱动器和虚拟机、磁盘连接起来。&lt;/p&gt;

&lt;h4 id=&#34;5-vboxmanage-list-hdds&#34;&gt;5. &lt;code&gt;VBoxManage list hdds&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;这时就可以查看注册过的磁盘了。&lt;/p&gt;

&lt;h3 id=&#34;操作&#34;&gt;操作&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;// 创建磁盘
$ VBoxManage createmedium disk --filename CentOS7.vdi --size 50000
0%...10%...20%...30%...40%...50%...60%...70%...80%...90%...100%
Medium created. UUID: 1cc3b870-7180-4eea-8263-f82a783d1478

// 创建虚拟机配置
$ cd ~/cluster
$ VBoxManage createvm --name CentOS7 --ostype RedHat_64 --register
Virtual machine &#39;CentOS7&#39; is created and registered.
UUID: 4afd6d6d-9cee-4efe-89a6-b752644711f0
Settings file: &#39;/home/hadoop/VirtualBox VMs/CentOS7/CentOS7.vbox&#39;

// 创建磁盘控制器
$ VBoxManage storagectl CentOS7 --add sata --controller IntelAHCI --name &amp;quot;SATA Controller&amp;quot;

// 绑定磁盘控制器
$ VBoxManage storageattach CentOS7 --storagectl &amp;quot;SATA Controller&amp;quot; --port 0 --device 0 --type hdd --medium CentOS7.vdi

// 创建光盘驱动器
$ VBoxManage storagectl CentOS7 --name &amp;quot;IDE Controller&amp;quot; --add ide

// 绑定光盘控制器
$ VBoxManage storageattach CentOS7 --storagectl &amp;quot;IDE Controller&amp;quot; --port 0 --device 0 --type dvddrive --medium ~/Downloads/CentOS-7-x86_64-Minimal-1511.iso

// 设置网络连接方式为桥接
$ VBoxManage modifyvm CentOS7 --nic1 bridged --bridgeadapter1 eno1 --vrde on --vrdeaddress 0.0.0.0 --vrdeport 5010 --memory 1024 --cpus 1

$ VBoxManage startvm CentOS7 --type=headless

&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注意：在我的操作系统下，执行createvm会在~/VirtualBox VMs/目录下生成&lt;code&gt;CentOS7.vbox&lt;/code&gt;文件，其实就是一个xml文件。而所谓的注册操作，就是在&lt;code&gt;~/.config/VirtualBox&lt;/code&gt;目录下生成一个VirtualBox.xml文件，里面有注册过的虚拟机的信息，类似下图所示：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/virtualbox.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;连接虚拟机&#34;&gt;连接虚拟机&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;这里我又要牢骚两句，网上有些人啊，觉得用命令行就是为了装13，根本不从问题的出发点去考虑。我为什么要用VirtualBox的命令行来安装虚拟机？图形界面不是更简单么？那是因为我的工作站没有图形界面啊！有些人上来就说连接你新创建的虚拟机要用&lt;code&gt;rdesktop -N localhost:3389&lt;/code&gt;，简直是bullshit，我要是用带图形环境的工作站，就根本就不用费那么大力气搞这个了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;言归正传，现在有了两种选择，Windows可以用自带的“远程桌面连接”应用进行连接，需要注意的是，以上面的命令为例，在填写主机时就需要写&amp;rdquo;192.168.159.3:5010&amp;rdquo;（其中IP是我用的工作站的IP，具体根据你的实际情况写），如果是Linux桌面就用&lt;code&gt;rdesktop -N 192.168.159.3:5010&lt;/code&gt;。至于Mac我好像也没有找到可以用的。&lt;/p&gt;

&lt;h2 id=&#34;复制虚拟机&#34;&gt;复制虚拟机&lt;/h2&gt;

&lt;p&gt;毕竟资源不是无限的，咱们创建虚拟机建集群也不能太浪费资源。我的理解是，如果要赋值虚拟机，最好用&amp;rdquo;link&amp;rdquo;形式，也就是说，复制虚拟机的快照，系统通过两个虚拟机的diff来区分二者。具体到VirtualBox的操作是这样的&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;为模板虚拟机创建一个snapshot&lt;/li&gt;
&lt;li&gt;复制snapshot并命名&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这两步就可以创建一个以前面的虚拟机为基础的虚拟机，而系统又不会占用两套存储空间，也步要求它有多高的性能，只要能说名问题即可。&lt;/p&gt;

&lt;p&gt;先查看一下当前有哪些虚拟机（注意：snapshot是另外一种实体，查看vm的命令是查看不到snapshot的）
&lt;img src=&#34;http://ww1.sinaimg.cn/large/65e4f1e6gw1f8v1dqo36oj20yw05etat.jpg&#34; alt=&#34;&#34; /&gt;
看一下指定的虚拟机是否已经有snapshot(这里只是不想给已经有snapshot的虚拟机再创建新的，其实是没有问题的)
&lt;img src=&#34;http://ww1.sinaimg.cn/large/65e4f1e6gw1f8v1ffm5tcj216002omy7.jpg&#34; alt=&#34;&#34; /&gt;
创建新的snapshot并查看是否创建成功
&lt;img src=&#34;http://ww1.sinaimg.cn/large/65e4f1e6gw1f8v1ig2xsuj21kw07en04.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;VBoxManage clonevm Debian-original --options link --name Debian-cluster-01 --register&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这样就克隆了一个新的虚拟机，并且注册到VirtualBox中，下面启动新的虚拟机的步骤就和前面直接创建新虚拟机一样了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ZooKeeper原理简介和简单使用</title>
      <link>http://lovelock.coding.me/bigdata/zookeeper-simple-practice/</link>
      <pubDate>Wed, 12 Oct 2016 23:36:09 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/bigdata/zookeeper-simple-practice/</guid>
      <description>

&lt;h2 id=&#34;什么是分布式应用&#34;&gt;什么是分布式应用&lt;/h2&gt;

&lt;p&gt;分布式应用运行在其上的一组系统被称为『集群』(cluster)，运行在集群中的每个机器被称为『节点』(node)。&lt;/p&gt;

&lt;h3 id=&#34;分布式应用的优点&#34;&gt;分布式应用的优点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;可靠性 单机或少量机器的故障不会导致整个系统不可用。&lt;/li&gt;
&lt;li&gt;可扩展性 不用停机只需要做很少的配置就可以根据需求通过增加机器来提升系统的性能。&lt;/li&gt;
&lt;li&gt;透明性 隐藏了系统的复杂性，对外值暴露单一的入口/应用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;分布式应用需要解决的难点&#34;&gt;分布式应用需要解决的难点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;竞争条件 两个或多个机器都尝试去执行同一个任务，而该任务在任意时刻都应该只被一台机器执行。比如，共享的资源在某一时刻应该只能被一台机器修改。&lt;/li&gt;
&lt;li&gt;死锁 两个或多个操作无限期的相互等待对方完成。&lt;/li&gt;
&lt;li&gt;不一致性 数据的部分错误。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;zookeeper简介&#34;&gt;ZooKeeper简介&lt;/h2&gt;

&lt;p&gt;ZooKeeper是一个&lt;strong&gt;分布式的&lt;/strong&gt;、用来管理大量主机的&lt;strong&gt;协调服务&lt;/strong&gt;。
在分布式环境中协调和管理一个服务是很复杂的工作，而ZooKeeper用简单的架构和API解决了这个问题，它用&lt;code&gt;fail-safe synchronization&lt;/code&gt;机制解决了竞争和死锁的问题, 用&lt;code&gt;atomicity(原子性)&lt;/code&gt;解决了数据的一致性问题。它屏蔽了分布式环境中的复杂性，让开发人员可以专注于核心应用功能的开发，而不用去关心分布式环境的太多细节。&lt;/p&gt;

&lt;h3 id=&#34;zookeeper提供的服务&#34;&gt;ZooKeeper提供的服务&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;名字服务 在一个集群内根据name找到主机，类似DNS服务&lt;/li&gt;
&lt;li&gt;配置管理 集中管理某个节点的最新配置&lt;/li&gt;
&lt;li&gt;集群管理 管理一个集群中某一节点的加入和离开&lt;/li&gt;
&lt;li&gt;主节点选举 协调一个集群选举中一个新的主节点&lt;/li&gt;
&lt;li&gt;加锁和同步服务 在数据被修改时给其加锁，这种机制可以帮助你在连接到其他如HBase的分布式服务时实现自动错误恢复&lt;/li&gt;
&lt;li&gt;存放高可用数据 可以保证在一个或多个节点出故障时保证数据的可用性&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;zookeeper的优点&#34;&gt;ZooKeeper的优点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;简单的分布式协调过程&lt;/li&gt;
&lt;li&gt;同步 服务器进程间的互斥和协作&lt;/li&gt;
&lt;li&gt;有序的消息&lt;/li&gt;
&lt;li&gt;序列化 用指定的规则编码数据。保证你的应用一致的运行。这种方式可以用在MapReduce中来协调对来执行线程&lt;/li&gt;
&lt;li&gt;可靠性&lt;/li&gt;
&lt;li&gt;原子性 数据传输要么成功要么失败，不存在中间状态&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;zookeeper的架构&#34;&gt;ZooKeeper的架构&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8mN6jw1f7alv0grqej30fw04zdgg.jpg&#34; alt=&#34;ZooKeeper架构图&#34; /&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;概念&lt;/th&gt;
&lt;th&gt;职责和作用&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Client&lt;/td&gt;
&lt;td&gt;Client定时向Server发送消息通知Server该Client是alive众泰，同时Server会返回Response给Client，如果Client发送Message后没有收到Response，则会自动重定向到其他Server&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Server&lt;/td&gt;
&lt;td&gt;ZooKeeper集群中的一个节点，提供给Clients所有的服务&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Ensemble&lt;/td&gt;
&lt;td&gt;一个可以提供ZooKeeper服务的集群，如果要达到高可用性，至少需要三个节点&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Leader&lt;/td&gt;
&lt;td&gt;节点故障时执行自动恢复的节点，启动时选举出的&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Follower&lt;/td&gt;
&lt;td&gt;根据Leader的指示执行任务&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;层级的命名空间&#34;&gt;层级的命名空间&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8mN6jw1f7ayltmo57j30go0ce0t8.jpg&#34; alt=&#34;ZooKeeper的层级的命名空间&#34; /&gt;&lt;/p&gt;

&lt;p&gt;层级结构中的每个节点叫做znode, 每个znode维护一个&lt;code&gt;stat&lt;/code&gt;结构。这个&lt;code&gt;stat&lt;/code&gt;仅仅提供一个znode的元信息，其中包括版本号(Version number)、行为控制列表(Action Control List, ACL)、时间戳(Timestamp)、数据长度(Data Lenght)。&lt;/p&gt;

&lt;p&gt;下面来就实例看一下一个znode有哪些信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8mN6jw1f8r0ho7jkhj31320h6ad1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这样一看就很明显了吧。&lt;/p&gt;

&lt;h3 id=&#34;znode的类型&#34;&gt;znode的类型&lt;/h3&gt;

&lt;p&gt;znode分为三种类型：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;永久型 永久型节点当客户端断开连接之后仍然存在，默认情况下创建的节点都是永久型节点&lt;/li&gt;
&lt;li&gt;临时型 只有client保持alive时才存在的节点叫临时节点，当client从ZooKeeper集群断开时，节点被自动删除。所以临时节点不允许有子节点。如果一个临时节点被删除了，下一个合适的节点会填充它的位置。临时节点在Leader的选取中起到重要作用。&lt;/li&gt;
&lt;li&gt;顺序型 序列型节点可以是永久的也可以是临时的。当一个znode被创建为顺序型时，ZooKeeper在它原来的name后面加上十位的十进制数字。如果两个顺序型节点是并发创建的，ZooKeeper会保证两个节点的name不同。顺序型节点在锁和同步中起到重要作用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;会话-sessions&#34;&gt;会话（Sessions）&lt;/h3&gt;

&lt;p&gt;一个会话中的请求是按照FIFO的顺序执行的。当一个client连接上一个server，一个会话就创建成功了并且会生成一个session id给client。&lt;br /&gt;
client会按一个时间间隔给server发送heartbeat来保证session的有效性。如果在一个session的生命周期内没有收到client的heartbeat，它就会认为这个client已经死掉了。&lt;br /&gt;
Session超时通常用ms表示。当一个session不管由于什么原因结束时，在session中创建的临时节点都会被删除掉。&lt;/p&gt;

&lt;h3 id=&#34;watches&#34;&gt;Watches&lt;/h3&gt;

&lt;p&gt;Watches是用来保证client能在znode上的数据发生变化时收到通知的一种简单机制。client在读取znode的数据时可以设置一个watches给一个特定的znode，当这个znode上的数据或者它的子节点发生变化时都会触发watches给client发送通知。&lt;br /&gt;
watches只会被触发一次，如果client还需要通知，那就需要另外一次的读取操作了。当一个client和server之间的会话过期时，它们之间的连接就断开了，同时watches也会被移除。&lt;/p&gt;

&lt;h3 id=&#34;工作流程&#34;&gt;工作流程&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;client读取数据 client发送一个&lt;strong&gt;读取请求&lt;/strong&gt;给ZooKeeper的一个节点，该节点根据请求中的path信息读取&lt;strong&gt;自己数据库中的数据&lt;/strong&gt;返回znode的信息给client。所以读取操作在ZooKeeper集群中是很快的。&lt;/li&gt;
&lt;li&gt;client写数据 如果收到请求的是Follower，它会先把请求转发给Leader，由Leader再发送写请求给Followers。只有&lt;strong&gt;大多数节点&lt;/strong&gt;正确响应时，写请求才会成功并且返回正确的返回码给client。否则写请求就会失败。这个严格的&lt;strong&gt;大多数节点&lt;/strong&gt;被称为&lt;strong&gt;Quorum（法定人数)&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;zookeeper中的节点数量&#34;&gt;ZooKeeper中的节点数量&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;当只有一个节点时，没有大多数&lt;/li&gt;
&lt;li&gt;只有两个节点，一个出故障时，也没有大多数&lt;/li&gt;
&lt;li&gt;当有三个节点，有一个出了故障，那2个就是大多数&lt;/li&gt;
&lt;li&gt;当有四个节点，2个出故障了，那也是没有大多数的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以，ZooKeeper集群的中节点的数量不要太多，不然写的性能会有下降。同时节点的数量是3/5/7这种奇数，而不要是偶数。&lt;/p&gt;

&lt;h3 id=&#34;小结&#34;&gt;小结&lt;/h3&gt;

&lt;p&gt;看了上面的这么一大套理论，可能还是对ZooKeeper做的事情云里雾里，因为它做的事情太抽象了，好像实际它什么都没做，但又发现好像每个组件比如Kafka/Storm都要和ZooKeeper配合才能用。到底为什么呢？&lt;/p&gt;

&lt;p&gt;上面讲过，ZooKeeper其实是一个配置分发服务，也就是具体的应用如Kafka和Storm都是&lt;strong&gt;无状态&lt;/strong&gt;的，它本身为了保持&lt;strong&gt;容错&lt;/strong&gt;的特性，而容错很重要的一项特性就是应用Down掉之后重启还要能从之前结束时的地方继续。既然是无状态，其实是&lt;strong&gt;自己不存储状态&lt;/strong&gt;，那要实现的这个特性肯定是&lt;strong&gt;需要知道&lt;/strong&gt;应用Down掉之前的状态的，那么好，我就把状态存在ZooKeeper里。&lt;/p&gt;

&lt;p&gt;举个生动的例子，假设有一个很长的（水）槽，Kafka会每秒把一个玻璃球放在槽里，这样的结果就是最先放进去的玻璃球在最前面。而Storm就是&lt;strong&gt;计数工&lt;/strong&gt;，（注意&lt;strong&gt;不是搬运工&lt;/strong&gt;，因为它数了之后并不会真实的改变玻璃球的位置）极端一点这个游戏是在一个战场上，Storm随时会死掉，它怎么保证它的后来者来到之后马上知道它之前数到哪个位置了？自己当然是不可靠的，因为它死掉之后这个信息就丢失了，所以它&lt;strong&gt;每数一个&lt;/strong&gt;就朝ZooKeeper大喊一声（发送写请求）告诉它数到哪个位置了，而Storm又是个健忘症（无状态），刚数完的自己就忘了，更不用说后面来的人了，那么当它把位置信息告诉ZooKeeper之后其实它和自己的后来者就没有区别了，因为不管是谁，在计数之前都需要先去ZooKeeper读取一下前面数到的位置。这样的好处就是每个Storm随时都可以死掉，只要能有新的应用随时可以起来即可。那么存到了ZooKeeper就万无一失了么？考虑前面ZooKeeper处理写请求的特点，它是把相同的信息在集群中所有的机器上都写了一份，即使其中的一台或几台宕掉了，除非在这几台重启之前仅剩的一台也宕掉了，服务是不受影响的。如果全宕掉了，那真的没办法了，你把整个机房的电源拔掉，肯定会丢数据的。&lt;/p&gt;

&lt;p&gt;也可以理解为把状态和应用做的解耦。&lt;/p&gt;

&lt;p&gt;那么问题来了，为什么是在战场上？为什么好好的一个应用会无缘无故的Down掉呢？这就要从分布式应用的特点说起了。我们知道以前的所谓大型机、小型机都是很大很昂贵的特殊机器，是区别于普通的硬件的，包括CPU、内存、硬盘都是特制的，所以一台机器上百万甚至千万的都很常见，这种机器宕机的几率很小，但如果宕机的话影响也会相当严重。所以可以说这些机器的费用里其实也包含了保险费，因为机器宕机导致的损失，供应商是要负责任的。&lt;/p&gt;

&lt;p&gt;但现在不同了，现在是用大量普通（廉价）的机器组成集群来替代之前特殊的机器，既然是普通，那出错的几率当然就更高了，这也就是为什么诸如Storm这些系统在设计之初就特别注重&lt;strong&gt;容错&lt;/strong&gt;和&lt;strong&gt;无状态&lt;/strong&gt;了。&lt;/p&gt;

&lt;h2 id=&#34;zookeeper的使用&#34;&gt;ZooKeeper的使用&lt;/h2&gt;

&lt;h3 id=&#34;安装和配置&#34;&gt;安装和配置&lt;/h3&gt;

&lt;h4 id=&#34;安装&#34;&gt;安装&lt;/h4&gt;

&lt;p&gt;大数据的这套东西安装起来都是很简单，因为都是编译好的包，直接解压之后就可以以默认配置执行了。不过ZooKeeper有点特殊，因为它需要读取的配置文件是&lt;code&gt;conf/zoo.cfg&lt;/code&gt;，而默认的发行包里面是有个&lt;code&gt;conf/zoo_sample.cfg&lt;/code&gt;，不过好在只需要重命名一下即可。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost zookeeper-3.4.8]# cp conf/zoo_sample.cfg conf/zoo.cfg
[root@localhost zookeeper-3.4.8]# bin/zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /root/packages/zookeeper-3.4.8/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
[root@localhost zookeeper-3.4.8]# bin/zkServer.sh status
Mode: standalone
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注意这里的Mode，表示单点模式，区别于集群模式&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;配置&#34;&gt;配置&lt;/h4&gt;

&lt;p&gt;前面只讲了基础配置，这样的配置是没法跑集群环境的，下面先从默认配置出发，一步一步搭建一个集群环境。
先贴默认配置：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tickTime=2000
initLimit=10
syncLimit=5
dataDir=/tmp/zookeeper
clientPort=2181
#maxClientCnxns=60
#autopurge.snapRetainCount=3
#autopurge.purgeInterval=1
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;tickTime&lt;/code&gt;： ZooKeeper服务器或客户端与服务器之间维持心跳的时间间隔，也就是每个tickTime就会发送一条心跳&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dataDir&lt;/code&gt; 顾名思义就是ZooKeeper保存数据的目录&lt;/li&gt;
&lt;li&gt;&lt;code&gt;clientPort&lt;/code&gt; ZooKeeper对外提供服务的端口，即客户端通过该端口与ZooKeeper通信&lt;/li&gt;
&lt;li&gt;&lt;code&gt;initLimit&lt;/code&gt; ZooKeeper集群中的Leader忍受Follower多少个心跳间隔不发送心跳。从这里的默认配置推算，10个心跳间隔，每个心跳间隔2秒钟，也就是当Leader经过2*10秒还收不到Follower的信条时就认为这个Follower已经挂了&lt;/li&gt;
&lt;li&gt;&lt;code&gt;syncLimit&lt;/code&gt; Leader和Follower之间发送消息时，请求和应答的时间长度，默认5，及10秒&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;从上面的描述就可以看到，从第4条开始就是集群需要的配置了，然而仅仅在每个机器上这样配置并不能变成一个集群，还需要一个重要的配置，形如&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server.1=c1:2888:3888
server.2=c2:2888:3888
server.3=c3:2888:3888
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中的&lt;code&gt;server.n&lt;/code&gt;中的n表示节点的编号，那么问题来了，编号从哪里定义呢？我觉得这个设计其实不太好，当然我也想不到更好的方式来解决这个问题了。我们还需要在&lt;code&gt;dataDir&lt;/code&gt;中写入一个名为&lt;code&gt;myid&lt;/code&gt;的文件，其中填写当前机器的编号，操作如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd /path/to/dataDir
echo 1 &amp;gt; myid
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;c1的位置是节点机器的hostname或者IP地址，这样写当然还是不行的，因为它们并不知道c1是什么鬼，所以还需要修改&lt;code&gt;/etc/hosts&lt;/code&gt;，以我当前的本地集群为例，在该文件中添加&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;192.168.1.111 c1
192.168.1.110 c2
192.168.1.112 c3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2888是默认的Follower与Leader交换信息的端口，3888是用于选举Leader的端口，当Leader挂了，当然需要选举一个新的Leader来继续它未竟的事业了。&lt;/p&gt;

&lt;h3 id=&#34;启动集群&#34;&gt;启动集群&lt;/h3&gt;

&lt;p&gt;这时可以在三台机器上同时执行&lt;code&gt;bin/zkServer.sh start&lt;/code&gt;了。如果看到和前面一样的结果（注意把刚才已经启动的服务先关掉，执行&lt;code&gt;bin/zkServer.sh stop&lt;/code&gt;），恭喜你成功了一半了。
这时再执行&lt;code&gt;bin/zkServer.sh status&lt;/code&gt;你会惊奇的发现其中一台会显示&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost zookeeper-3.4.8]# bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /root/packages/zookeeper-3.4.8/bin/../conf/zoo.cfg
Mode: leader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外两台显示&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost zookeeper-3.4.8]# bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /root/packages/zookeeper-3.4.8/bin/../conf/zoo.cfg
Mode: follower
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了证明Leader节点是自动选举的，可以把Leader手动关掉，再分别看看另外两台的&lt;code&gt;status&lt;/code&gt;。是不是有一个变成了Leader了？&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;几天前写这篇文章时没有问题，但今天继续编写Kafka部分时，因为之前重启过这几台虚拟机，IP变了，重启所有虚拟机之后发现虽然已经在本地启动了ZooKeeper服务，但执行&lt;code&gt;zkServer.sh status&lt;/code&gt;时总是提示没有运行，而如果你再执行&lt;code&gt;start&lt;/code&gt;指令，它又会提示说进程已经在运行了。根据&lt;a href=&#34;http://stackoverflow.com/questions/29909191/zookeeper-it-is-probably-not-running&#34;&gt;StackOverFlow的答案&lt;/a&gt;，把&lt;code&gt;/root/packages/zookeeper-3.4.8/bin&lt;/code&gt;添加至&lt;code&gt;$PATH&lt;/code&gt;中即可。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vim /etc/profile.d/zookeeper.sh
export ZK_HOME=/root/packages/zookeeper-3.4.8
export PATH=$PATH:$ZK_HOME/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后执行&lt;code&gt;source /etc/profile.d/zookeeper.sh&lt;/code&gt;即可直接在系统的任何地方执行&lt;code&gt;zkServer.sh start&lt;/code&gt;了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;通过动态的选举Leader节点，就解决了&lt;strong&gt;主从系统的单点故障问题&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&#34;简单使用&#34;&gt;简单使用&lt;/h3&gt;

&lt;p&gt;前面说了启动服务，细心的你可能还发现在bin目录里面还有一个zkCli.sh（请自动无视zkCli.cmd，因为那明显是给Windows用的，而我觉得也没有人会在Windows上跑这些服务），这就是ZooKeeper的命令行客户端。&lt;/p&gt;

&lt;p&gt;而我要说的只有两个最简单的命令。&lt;/p&gt;

&lt;h4 id=&#34;1-ls&#34;&gt;1. &lt;code&gt;ls&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;ls&lt;/code&gt;顾名思义就是查看指定path下的数据，前面我已经演示过了，要注意的一点是&lt;strong&gt;如果&lt;code&gt;ls&lt;/code&gt;后跟的是一个叶子节点，返回的结果是&lt;code&gt;[]&lt;/code&gt;&lt;/strong&gt;，这时你应该很敏锐的意识到应该换用&lt;code&gt;get&lt;/code&gt;来操作这个节点从而查看它的详细信息了。&lt;/p&gt;

&lt;h4 id=&#34;2-get&#34;&gt;2. &lt;code&gt;get&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;get&lt;/code&gt;当然就是用来查看指定节点的详细信息用的了。&lt;/p&gt;

&lt;p&gt;ZooKeeper提供的借口当然远远不止这两个，但起码到目前为止我还没有用到需要自行调用ZooKeeper接口的地方。因为实际上ZooKeeper是一个很底层的服务，它是用来为Storm和Kafka这类系统提供服务的，而我们通常不直接使用它们。在前两天一次查问题的过程中，发现数据一直在重复写入HDFS，查到了一个症状是ZooKeeper中的offset从一次重启发布之后一直没有更新过，导致系统一直反复读取该时间点之后的数据。这期间也就只用了这两个命令，至于对各种语言的binding，这里就不多说了，如果你要使用ZooKeeper给你的应用提供服务，那也不是看我的这篇文章就能搞明白的：）&lt;/p&gt;

&lt;p&gt;Happy Coding!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;本文大量参考了&lt;a href=&#34;https://www.tutorialspoint.com//zookeeper/index.htm&#34;&gt;https://www.tutorialspoint.com/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>一个真实Storm应用源码解析</title>
      <link>http://lovelock.coding.me/java/storm-demo-presentation/</link>
      <pubDate>Tue, 11 Oct 2016 16:41:18 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/java/storm-demo-presentation/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;这里是Storm分享的内容。我自己也是初学者，这里抛砖引玉，希望大家多多指教。为简单起见，本应用用的是Java实现，没有用到Storm的多语言支持和更高层面的Trident Topology。源码详见&lt;a href=&#34;https://github.com/lovelock/storm-demo&#34;&gt;storm-demo&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;理论&#34;&gt;理论&lt;/h2&gt;

&lt;h3 id=&#34;概述&#34;&gt;概述&lt;/h3&gt;

&lt;p&gt;Apache Storm是一个自由并且开源的&lt;strong&gt;分布式实时&lt;/strong&gt;计算系统.它使得像Hadoop做批处理一样做&lt;strong&gt;实时的&lt;/strong&gt;、&lt;strong&gt;无限量&lt;/strong&gt;的&lt;strong&gt;流数据&lt;/strong&gt;处理变得简单可靠.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://storm.apache.org/images/storm-flow.png&#34; alt=&#34;Apache Storm工作流程&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;概念解释&#34;&gt;概念解释&lt;/h3&gt;

&lt;h4 id=&#34;工作原理&#34;&gt;工作原理&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://www.tutorialspoint.com/apache_storm/images/zookeeper_framework.jpg&#34; alt=&#34;Apache Storm组件间关系&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Nimbus&lt;br /&gt;
 Nimbus是Storm集群的&lt;strong&gt;主节点master node&lt;/strong&gt;。Storm集群中除Nimbus节点之外的所有节点叫做&lt;strong&gt;工作节点worker nodes&lt;/strong&gt;。&lt;br /&gt;
 Nimbus负责三项工作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;向worker nodes分发数据&lt;/li&gt;
&lt;li&gt;向worker nodes分配tasks&lt;/li&gt;
&lt;li&gt;监控失败&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Supervisor&lt;br /&gt;
 接受Nimbus的指令的节点叫做Supervisors（监工），它有&lt;strong&gt;多个worker process&lt;/strong&gt;，并控制worker process完成Nimbus分配的tasks&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Worker Process&lt;br /&gt;
 Worker process执行指定Topology的tasks。&lt;strong&gt;worker process自己并不实际执行tasks，而是创建executors并由executors执行指定的task。&lt;/strong&gt;一个worker process可以由多个executor。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Executor&lt;br /&gt;
 Executor是由worker process创建的线程。一个executor执行一个或多个tasks，但只为&lt;strong&gt;一个指定的Spout或者Bolt工作&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Task&lt;br /&gt;
 Task是实际的数据处理工作，所以它可能是一个Spout或者Bolt。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;配套服务&#34;&gt;配套服务&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;ZooKeeper&lt;br /&gt;
&lt;a href=&#34;http://zookeeper.apache.org/&#34;&gt;ZooKeeper&lt;/a&gt;是一个分布式的配置分发服务。Storm和Kafka都是无状态的，它们的工作需要外部服务为其维持状态，如Storm从Kafka中取数据时需要的partition编号和offset偏移量等诸如此类的信息。ZooKeeper会综合分析Spout和Bolt发送来的ack或者fail请求来决定是否更新offset。如下图所示&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww3.sinaimg.cn/large/65e4f1e6jw1f8wd8tm94ij21kw097q5h.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kafka&lt;br /&gt;
&lt;a href=&#34;http://kafka.apache.org/&#34;&gt;Kafka&lt;/a&gt;是一个分布式的消息系统。支持&lt;strong&gt;点对点&lt;/strong&gt;和&lt;strong&gt;发布-订阅&lt;/strong&gt;两种消息模式。在和Storm配合中，充当&lt;strong&gt;数据来源&lt;/strong&gt;的角色。用&lt;a href=&#34;https://github.com/apache/storm/tree/master/external/storm-kafka&#34;&gt;KafkaSpout&lt;/a&gt;和Storm进行组合。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;本文只关注Storm，有关ZooKeeper和Kafka的介绍，可以访问&lt;a href=&#34;http://apache.org/&#34;&gt;官网&lt;/a&gt;、&lt;a href=&#34;http://www.tutorialspoint.com/&#34;&gt;TutorialsPoint&lt;/a&gt;或本博客的其他相关文章。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;拓扑作业&#34;&gt;拓扑作业&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Tuple&lt;br /&gt;
 Tuple是Topology中数据流的传输格式。它是&lt;strong&gt;不可变的键值对组&lt;/strong&gt;。既然是键值对，就需要设置键和值，典型的设置方式如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; // 设置键
 outputFieldsDeclarer.declare(new Fields(&amp;quot;timestamp&amp;quot;, &amp;quot;fieldvalues&amp;quot;));
 // 设置值
 collector.emit(tuple, new Values(timestamp, stringBuilder.toString()));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就会得到一个形如&lt;code&gt;(&amp;quot;timestamp&amp;quot;: timestamp, &amp;quot;fieldvalues&amp;quot;: xxxx&amp;quot;)&lt;/code&gt;这样的Tuple。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Spout&lt;br /&gt;
 Spout是Topology的数据来源，输出的数据以Tuple的形式传入下一个Bolt。具体到本例中，KafkaSpout会把它接收到的数据以类似&lt;code&gt;(0: message)&lt;/code&gt;这样的形式发射(emit)出来。所以，在KafkaSpout下游的Bolt需要这样获取整条数据(其实这里是可配置的)：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; String message = tuple.getString(0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对KafkaSpout而言，它也实现了多个方法，但我们这里只需要了解两个&lt;code&gt;ack&lt;/code&gt;和&lt;code&gt;fail&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww3.sinaimg.cn/large/65e4f1e6jw1f8wdqv4tuqj218y0ji41l.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这两个是回调方法，分别在acker向其发送ack或fail请求时被触发，一般而言，ack方法由于通知Kafka发送下一条数据，fail方法用于通知Kafka重发上一条数据。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Storm中有个特殊的task名叫acker，它们负责跟踪Spout发出的每一个Tuple的Tuple树（因为一个Tuple通过Spout发出了，经过每一个Bolt处理后，会生成一个新的Tuple发送出去）。当acker（框架自启动的task）发现一个Tuple树已经处理完成了，它会发送一个消息给产生这个Tuple的那个task。&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bolt&lt;br /&gt;
 Bolt是真正写处理逻辑的地方，比如在本例中，我们要做以下几件事：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;把message中的每个字段提取出来，&lt;/li&gt;
&lt;li&gt;从message的domain字段中过滤出以&lt;code&gt;.api.ksyun.com&lt;/code&gt;结尾的，其他的舍弃&lt;/li&gt;
&lt;li&gt;把domain字段的值以&lt;code&gt;.&lt;/code&gt;分割，取出index为0的部分，也就是第一段作为service字段&lt;/li&gt;
&lt;li&gt;把service最终输出Tuple的一个field写入输出结果&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一般情况下，要实现一个Bolt有几种方式&lt;/p&gt;

&lt;p&gt;​&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;实现&lt;code&gt;IRichBolt&lt;/code&gt;接口&lt;br /&gt;
  因为这个比较低级，要实现的方法有很多，而其中多数的方法不需要做特殊处理，所以一般会用第二种方式&lt;/li&gt;

&lt;li&gt;&lt;p&gt;集成&lt;code&gt;BaseRichBolt&lt;/code&gt;类&lt;br /&gt;
  这个基类实现了&lt;code&gt;IRichBolt&lt;/code&gt;中定义的几个不常用的方法，让我们只需要关注重点的几个方法即可。在这种方式中，我们需要自己实现三个方法：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;public void prepare(Map map, TopologyContext topologyContext, OutputCollector outputCollector)&lt;/code&gt;&lt;br /&gt;
  这个方法&lt;strong&gt;类似构造函数&lt;/strong&gt;，用来做一些准备工作，通常用于&lt;strong&gt;把上游传来的collector赋值给成员变量&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;public void execute(Tuple tuple)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这是最核心的方法。它负责：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;从上游传来的Tuple中读取感兴趣的字段&lt;/li&gt;
&lt;li&gt;把这些字段做一些处理后产生一组新的字段&lt;/li&gt;
&lt;li&gt;把这些值通过&lt;code&gt;OutputCollector::emit(new Values())&lt;/code&gt;方法发射出去&lt;/li&gt;
&lt;li&gt;向上游发送&lt;code&gt;OutputCollector::ack(Tuple tuple)&lt;/code&gt;或&lt;code&gt;OutputCollector::fail(Tuple tuple)&lt;/code&gt;，以告知上游本次Tuple处理是否成功。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;前面已经说过，Tuple是数据交流的格式，这个方法就是用来定义发送到下游的Tuple的字段名的。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Topology&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://storm.apache.org/releases/0.10.0/images/topology.png&#34; alt=&#34;一个典型的Topology&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上面这张图中有4个Topology，说明了几个问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一个Spout就是一个Topology的入口，从Spout分出几条线就有几个Topology&lt;/li&gt;
&lt;li&gt;一个Topology由一个Spout和若干个Bolt组成&lt;/li&gt;
&lt;li&gt;Topology之间可以共享Spout或者Bolt&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;创建一个Topology的典型过程：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    TopologyBuilder topologyBuilder = new TopologyBuilder();
    topologyBuilder.setSpout(KAFKA_SPOUT_ID, kafkaSpout, 10);
    topologyBuilder.setBolt(CROP_BOLT_ID, new CropBolt(), 10).shuffleGrouping(KAFKA_SPOUT_ID);
    topologyBuilder.setBolt(SPLIT_FIELDS_BOLT_ID, new SplitFieldsBolt(), 10).shuffleGrouping(CROP_BOLT_ID);
    topologyBuilder.setBolt(STORM_HDFS_BOLT_ID, hdfsBolt, 10).fieldsGrouping(SPLIT_FIELDS_BOLT_ID, new Fields(&amp;quot;timestamp&amp;quot;, &amp;quot;fieldvalues&amp;quot;));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的代码可以看到，&lt;code&gt;TopologyBuilder&lt;/code&gt;类通过&lt;code&gt;setSpout()&lt;/code&gt;和&lt;code&gt;setBolt()&lt;/code&gt;两个方法生动的反映了上图的工作流程。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;源码分析&#34;&gt;源码分析&lt;/h2&gt;

&lt;h3 id=&#34;cropbolt-java&#34;&gt;&lt;code&gt;CropBolt.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;主要关注&lt;code&gt;execute&lt;/code&gt;方法，它首先从上游发射来的Tuple中取出第一个字段，也就是整条消息作为一个字符串。根据对字符串的分析，我们知道该字符串是以&lt;code&gt;\t\t&lt;/code&gt;作为字段间分隔符，以&lt;code&gt;:&lt;/code&gt;作为键值分隔符的字符串，所以可以写一个方法来用这种规则解析出消息中的所有字段，并把它放在一个HashMap里。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    private HashMap makeMapOfMessage(String message) {
    String[] fields = message.split(ServerConfig.getFieldSeparator());
    HashMap&amp;lt;String, String&amp;gt; map = new HashMap&amp;lt;&amp;gt;();

    try {
        for (String field : fields) {
            String[] pair = field.split(ServerConfig.getPairSeparator(), 2);
            map.put(pair[0], pair[1]);
        }
    } catch (ArrayIndexOutOfBoundsException e) {
        LOG.warn(&amp;quot;makeMapOfMessage failed {}&amp;quot;, message);
        e.printStackTrace();
    }

    return map;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中&lt;code&gt;ServerConfig&lt;/code&gt;是一个工具类，它提供了简单的API，把处理逻辑和配置信息分离。在本例中我用的分隔符和实际项目并不一样，这个差别只需要在相应的properties配置文件中做修改即可。还需要注意异常处理，这个方法的返回值有可能是null，在调用该方法的地方需要做相应的判断。&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;execute&lt;/code&gt;方法中，从上述方法的返回值取出关心的字段，并按需求解析出需要的&lt;code&gt;service&lt;/code&gt;字段，并通过&lt;code&gt;collector.emit&lt;/code&gt;发送给下游的Bolt。&lt;/p&gt;

&lt;p&gt;这个方法中有三点需要注意：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;没有在&lt;code&gt;try&lt;/code&gt;子句中调用&lt;code&gt;ack&lt;/code&gt;方法&lt;/li&gt;
&lt;li&gt;没有在&lt;code&gt;catch&lt;/code&gt;子句中调用&lt;code&gt;fail&lt;/code&gt;方法&lt;/li&gt;
&lt;li&gt;在&lt;code&gt;finally&lt;/code&gt;子句中调用了&lt;code&gt;ack&lt;/code&gt;方法&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因为我们catch住的这种情况，是只有在输入的数据不满足我们约定要求的情况下才会发生的，比如某些必要的字段不存在等，而这种情况在当前的Topology中是不需要处理的，并且也不需要重试，因此，不需要调用&lt;code&gt;fail&lt;/code&gt;。同时，不管数据是否符合要求，我们都是需要通知Spout&lt;strong&gt;这里的处理已经完成&lt;/strong&gt;这个信息的，所以在&lt;code&gt;finally&lt;/code&gt;中调用&lt;code&gt;ack&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;splitfieldsbolt-java&#34;&gt;&lt;code&gt;SplitFieldsBolt.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;这步的功能很简单，就是把前面传过来的所有字段用一个特定的分隔符连接起来，变成一行数据。只有一个特殊，也就是&lt;code&gt;service&lt;/code&gt;字段，它不是直接取出来的，而是前面的Bolt通过一些处理得到的，所以这是&lt;code&gt;stringBuilder&lt;/code&gt;需要处理的一种特殊情况。&lt;/p&gt;

&lt;p&gt;最后把『时间戳』和『各个字段的值』发射给下游的&lt;code&gt;HdfsBolt&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;hdfsbolt&#34;&gt;&lt;code&gt;HdfsBolt&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;HdfsBolt&lt;/code&gt;是Storm到HDFS的一个中转层，配置一些规则，把Storm输出的数据写入HDFS。其中比较重要的配置有：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;DelimitedRecordFormat&lt;/code&gt; 要写入的字段 在本例中，『时间戳』只是用来划分目录的，所以不需要写入HDFS中&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CountSyncPolicy&lt;/code&gt; 指定当内存中超过多少条数据时cache到磁盘中&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FileSizeRotationPolicy&lt;/code&gt; 指定cache的文件超过多大时将文件写入文件系统，如果该值设置的较大，而数据流量又不太大的情况下，文件通常不会达到设置的值，因为当等待写入的文件未达到限制大小而先达到超时时间时，也会创建一个新的文件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DefaultFileNameFormat&lt;/code&gt; 指定文件写入HDFS中的根目录和文件后缀&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Partitioner&lt;/code&gt; 指定分块规则，在本例中，我们根据日志中&lt;code&gt;time_local&lt;/code&gt;字段划分相应的消息应该写入的HDFS目录，比如&lt;code&gt;31/Aug/2016:13:08:12 +0800&lt;/code&gt;，相应的记录就会写入&lt;code&gt;root/20160831/13&lt;/code&gt;目录中。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FsURL&lt;/code&gt; 当然需要指定正确的&lt;code&gt;HDFS&lt;/code&gt;服务。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;其实我们的KMR对应的Storm 0.10.0是不支持HDFS 的partition的，这里我是把Storm最新版的2.0.0-SNAPSHOT中相应的代码移植过来用的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;logstatisticstopology-java&#34;&gt;&lt;code&gt;LogStatisticsTopology.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;前面讲过，这是拓扑作业的入口，这里指定了一条消息要通过的路径。需要注意的有以下几点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;setSpout&lt;/code&gt;和&lt;code&gt;setBolt&lt;/code&gt;方法中的parallelism_hint(并行度建议)，前面说了，Spout和Bolt在Storm中是以executor的形式存在的，而这个值就是指定executor的数量。但又没有那么绝对，比如在KafkaSpout中，如果指定的Topic在Kafka中有10个partition，但这里的KafkaSpout指定了15个并行度，实际还是只有10个executor有意义，因为剩余的5个在前面10个都正常工作的情况下是分配不到任何数据的，由于ZooKeeper做了中间人，它是知道每个Topic有多少个partition的，所以这里设置多于partition数量的并行度也是不起作用的。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;grouping类型 Storm目前支持4种分组形式。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;随机分组 等量tuples随机分发给执行bolt的所有workers&lt;/li&gt;
&lt;li&gt;字段分组 把指定字段值相同的分配给同一个task,在wordCount应用中比较重要&lt;/li&gt;
&lt;li&gt;广播分组 给每个executor发送一个这个tuple的副本&lt;/li&gt;
&lt;li&gt;全局分组 把所有数据分发给bolt的executor中id最小的&lt;strong&gt;一个&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;无分组   目前基本等同于随机分组，会把tuple交给和它上游同一个线程内的下游bolt，以减少数据传递的开销&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;根据我们的需求，其实是不需要太关心分组的事情。&lt;/p&gt;

&lt;p&gt;关于优化，有几个方面可以考虑：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;考虑到后面需要用Hive分析数据，如果产生很多小的文件，就会产生过多的Map过程，影响性能，可以考虑同一小时的文件交给同一个executor来写，因为每个executor会打开一个hdfs文件，但这样可能会导致并发数过少&lt;/li&gt;
&lt;li&gt;既然这样，可以减少executor的数量，比如现在是10个，可以改成5个，在不触发FileSizeRotationPolicy的情况下，把生成的文件数量减少了一半，也就把Hive查询时Map过程的数量减少了一半&lt;/li&gt;
&lt;li&gt;分析需求，如果没有按照小时分组的需求，可以直接删除这个级别，直接用天作为区分，这样，在不触发FileSizeRotationPolicy的情况下产生的文件数量会变成1/24,相应的Hive查询中Map的过程也会变成1/24.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;本文主要介绍了Storm的工作流程，以及其与Kafka和HDFS的配合来进行日志分析的工作流程，并简单介绍了一些需要注意的点。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>在本地单机部署Hadoop/Storm运行环境</title>
      <link>http://lovelock.coding.me/java/deploy-pseudo-distributed-mode-hadoop/</link>
      <pubDate>Mon, 10 Oct 2016 17:53:14 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/java/deploy-pseudo-distributed-mode-hadoop/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;由于要在小组内做一个关于Storm的分享，涉及到我负责开发的大数据项目，本着开放的原则，把我做的准备工作记录下来，提前发给可能参会的同事。&lt;br /&gt;
要演示的项目目前为止用到了Apache的多个项目，包括Kafka, Storm, Hadoop(HDFS, Hive), ZooKeeper等，项目刚刚起步，很多基础设施还不完善，比如现在是在本地开发完成之后直接部署到线上环境的，这次演示可不能直接在线上环境做了，故而在本地的台式机上部署了一下&lt;strong&gt;伪集群&lt;/strong&gt;，用来作为演示和以后开发测试用的环境。&lt;/p&gt;

&lt;h2 id=&#34;准备工作&#34;&gt;准备工作&lt;/h2&gt;

&lt;p&gt;说明：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;以下工作全部基于Ubuntu 16.04。用其他的发行版或版本理论上应该都是可行的，可能有些命令需要微调。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;所有需要执行的命令前面都有一个&lt;code&gt;$&lt;/code&gt;，表示的是Bash的命令提示符。&lt;/li&gt;
&lt;li&gt;下载安装包时我使用了速度相对较快的国内镜像，如果你对此有任何异议，可以自行去中心镜像站点下载。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;默认情况下文中提到的所有如StormUI等控制后台访问的路径都是localhost，如果你需要从Linux主机外部访问，需要iptables放行相应的端口。在本文中，用的Web端口有三个，具体如下表：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;服务描述&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;端口号&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Storm UI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8080&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hadoop UI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50070&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hadoop Applications&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8088&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;以Ubuntu为例，需要执行以下命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo ufw allow 8080/tcp
$ sudo ufw allow 50070/tcp
$ sudo ufw allow 8088/tcp
$ sudo ufw reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CentOS/RHEL 7.0以下可能需要直接操作iptables，7.0以上可以使用&lt;code&gt;firewall-cmd&lt;/code&gt;进行类似的操作。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-创建独立的用户并赋予合适的权限&#34;&gt;1. 创建独立的用户并赋予合适的权限&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ sudo useradd hadoop
$ sudo passwd hadoop
$ sudo chsh hadoop
$ sudo mkdir /home/hadoop
$ sudo chown -R hadoop:hadoop /opt/apache
$ sudo chown -R hadoop:hadoop /home/hadoop
$ su - hadoop
$ ssh-keygen
$ cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys
$ chmod 0600 ~/.ssh/authorized_keys
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;FAQ：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;为什么需要chsh并且手动为用户创建家目录？&lt;br /&gt;
不知道为什么在 Ubuntu 环境中执行&lt;code&gt;useradd&lt;/code&gt;命令之后并不会给新建的用户创建家目录和设置shell，可能是为了安全吧，要稍微麻烦一些。&lt;/li&gt;
&lt;li&gt;为什么不给新用户赋予root权限？&lt;br /&gt;
这里是测试环境倒还好，如果你需要搭建生产环境，记住千万不要给hadoop用户赋予root权限，它需要哪些目录的权限就单独赋予即可，它需要运行的端口都是1024以上的，都不需要root权限。如果需要，执行&lt;code&gt;sudo gpasswd -a hadoop sudo&lt;/code&gt;即可。&lt;/li&gt;
&lt;li&gt;为什么要做一个密钥认证？&lt;br /&gt;
这是因为在后续的步骤中会有&lt;strong&gt;从本地用户登录本地用户&lt;/strong&gt;的需求，也就是执行了&lt;code&gt;ssh hadoop@localhost&lt;/code&gt;这个命令，如果不做密钥信任，会需要多次输入密码。&lt;/li&gt;
&lt;li&gt;为什么会有一个&lt;code&gt;/opt/apache&lt;/code&gt;目录？&lt;br /&gt;
往下看。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-下载所需安装包&#34;&gt;1. 下载所需安装包&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;下载Java&lt;br /&gt;
到&lt;a href=&#34;http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html&#34;&gt;Java官网&lt;/a&gt;下载适用于Linux的Java安装包（这里下载了jdk-8u101-linux-x64.tar.gz）。&lt;/li&gt;
&lt;li&gt;下载maven&lt;br /&gt;
点击&lt;a href=&#34;http://mirrors.aliyun.com/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.zip&#34;&gt;阿里云镜像站&lt;/a&gt;下载最新版Maven。&lt;/li&gt;
&lt;li&gt;下载Apache的Storm Hadoop Kafka ZooKeeper&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/storm/apache-storm-0.10.2/apache-storm-0.10.2.tar.gz&#34;&gt;点击下载Storm-0.10.2&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/hadoop/core/hadoop-2.6.4/hadoop-2.6.4.tar.gz&#34;&gt;点击下载Hadoop-2.6.4&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/kafka/0.8.2.2/kafka_2.10-0.8.2.2.tgz&#34;&gt;点击下载Kafka_2.10-0.8.2.2&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz&#34;&gt;点击下载ZooKeeper-3.4.6&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-创建所需目录&#34;&gt;2. 创建所需目录&lt;/h3&gt;

&lt;p&gt;把所有和此项目相关的文件都放在统一的位置。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ sudo mkdir -p /opt/apache/{jdk, storm,hadoop,kafka,zookeeper}&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-解压所有安装包-将相应的安装包放在对应的位置&#34;&gt;3. 解压所有安装包，将相应的安装包放在对应的位置&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mv jdk1.8.0_101/* /opt/jdk/.
$ sudo mv apache-storm-0.10.0/* /opt/apache/storm/.
$ sudo mv hadoop-2.6.4/* /opt/apache/hadoop/.
$ sudo mv kafka_2.10-0.8.2.2/* /opt/apache/kafka/.
$ sudo mv zookeeper-3.4.6/* /opt/apache/zookeeper
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-配置环境变量&#34;&gt;4. 配置环境变量&lt;/h3&gt;

&lt;p&gt;在~/.bashrc中添加下面的片段&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export JAVA_HOME=/opt/jdk
export APACHE_HOME=/opt/apache
export STORM_HOME=$APACHE_HOME/storm
export ZK_HOME=$APACHE_HOME/zookeeper
export KAFKA_HOME=$APACHE_HOME/kafka

export HADOOP_HOME=$APACHE_HOME/hadoop
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_INSTALL=$HADOOP_HOME

export PATH=$PATH:$JAVA_HOME/bin
export PATH=$PATH:$STORM_HOME/bin
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export PATH=$PATH:$ZK_HOME/bin
export PATH=$PATH:$KAFKA_HOME/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后执行&lt;code&gt;$ source ~/.bashrc&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;5-安装java&#34;&gt;5. 安装Java&lt;/h4&gt;

&lt;p&gt;Apache的这些东西都是直接放在对的地方就可以运行的，但Java需要稍微的配置一下，因为可能你的机器上已经装了OpenJDK。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ sudo update-alternatives --install /usr/local/bin/java java /opt/jdk/bin/java 10000&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这时再执行&lt;code&gt;$ java -version&lt;/code&gt;验证一下是否使用的时最新安装的JDK。&lt;/p&gt;

&lt;h2 id=&#34;2-启动服务&#34;&gt;2. 启动服务&lt;/h2&gt;

&lt;h3 id=&#34;1-启动zookeeper&#34;&gt;1. 启动ZooKeeper&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ cp $ZK_HOME/conf/zoo_sample.cfg $ZK_HOME/conf/zoo.cfg
$ zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-启动storm&#34;&gt;2. 启动Storm&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ storm nimbus
$ storm supervisor
$ storm ui
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在可以访问&lt;a href=&#34;http://localhost:8080&#34;&gt;Storm UI&lt;/a&gt;了。&lt;/p&gt;

&lt;h3 id=&#34;3-启动kafka-broker&#34;&gt;3. 启动Kafka Broker&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ cd $KAFKA_HOME
$ bin/kafka-server-start.sh -daemon config/server.properties
$ bin/kafka-topics.sh --list --zookeeper localhost:2181
$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 10 --topic storm-demo-topic
Created topic &amp;quot;storm-demo-topic&amp;quot;.
$ bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic storm-demo-topic
Topic:storm-demo-topic  PartitionCount:10       ReplicationFactor:1     Configs:
        Topic: storm-demo-topic Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 2    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 3    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 4    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 5    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 6    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 7    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 8    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 9    Leader: 0       Replicas: 0     Isr: 0
$ kafka-console-producer.sh --broker-list localhost:9092 --topic storm-demo-topic
$ kafka-console-consumer.sh --zookeeper localhost:2181 --topic storm-demo-topic --from-beginning
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注意前面有些命令仅仅是为了测试kafka broker运行的情况。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;4-启动hadoop-hdfs&#34;&gt;4. 启动Hadoop(HDFS)&lt;/h3&gt;

&lt;h4 id=&#34;1-修改hadoop的配置文件&#34;&gt;1. 修改Hadoop的配置文件&lt;/h4&gt;

&lt;p&gt;在&lt;code&gt;$HADOOP_HOME/etc/hadoop&lt;/code&gt;目录下有5个文件需要修改:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;core-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.default.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;hdfs-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.name.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/hadoop/hadoopinfra/hdfs/namenode&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.data.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/hadoop/hadoopinfra/hdfs/datanode&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;yarn-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;mapred-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;hadoop-env.sh&lt;/code&gt;
把hadoop-env.sh中的${JAVA_HOME}替换成路径,这里是&lt;code&gt;/opt/jdk&lt;/code&gt;，因为貌似会找不到正确的&lt;code&gt;JAVA_HOME&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;2-验证是否安装成功&#34;&gt;2. 验证是否安装成功&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ hadoop namenode -format
$ start-dfs.sh
$ start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行上面三行语句，观察有没有明显的报错信息。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:50070&#34;&gt;检查HadoopUI&lt;/a&gt;运行是否正常。&lt;br /&gt;
&lt;a href=&#34;http://localhost:8088&#34;&gt;检查Hadoop Applications&lt;/a&gt;(我自己取的名字)运行是否正常。&lt;/p&gt;

&lt;p&gt;至此已经搭建了一个可以运行的hadoop环境，可以移步这里查看关于Storm入门分享详情。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>slf4j配合log4j来给你的应用打log</title>
      <link>http://lovelock.coding.me/java/use-slf4j-and-log4j-to-log-your-applications/</link>
      <pubDate>Thu, 22 Sep 2016 14:16:06 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/java/use-slf4j-and-log4j-to-log-your-applications/</guid>
      <description>&lt;p&gt;最近刚开始接触Java，被折腾的很难受。因为PHP随便找个环境都能执行，只需要把代码传上去就OK，而Java还需要编译、打包，用mvn执行命令，本来不多的功能就高出一下上百兆的包，然后传到服务器上。后来在运维同学的配合下整了一套只需要我把代码提交到Git仓库，系统自动打包并上传到需要执行的机器上的工作流，虽然比之前好了很多，但还是没有PHP开发的过程流畅。&lt;/p&gt;

&lt;p&gt;说了这么多，是因为Java调试起来不容易，或者说成本高。所以就需要尽量在提交代码之前打尽可能多的日志，帮助后面查找问题。找了一圈，发现最通用的Java日志库是slf4j(Simple Logging Facade for Java)。
这名字都不喜欢，什么破玩意儿。而且这玩意儿其实自己并不记录日志，而只是一个日志的Facade，也就是说它是用来&lt;strong&gt;为其他真正执行记日志功能的类库提供一个标准接口&lt;/strong&gt;的。我也没有兴趣去研究它的代码，想想也是各种设计模式用的6到飞起了。
下面是记录一下怎么用最简单的方式把它添加到自己的项目中，以log4j为例。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;需要添加的dependencies&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.slf4j&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;slf4j-log4j12&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;1.7.21&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;后面两个依赖并不是必需的，只需要第一个即可。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;在需要记日志的类中添加这样的一些代码片段&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;package com.unixera.mvn;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class App 
{
    private static Logger LOG = LoggerFactory.getLogger(App.class);
    public static void main( String[] args )
    {
        LOG.info(&amp;quot;this is a log&amp;quot;);
        LOG.debug(&amp;quot;This is a log with some information {}&amp;quot;, args.toString());
        System.out.println( &amp;quot;Hello World!&amp;quot; );
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;执行一下，这时候会发现下面的警告信息。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;log4j:WARN No appenders could be found for logger (HelloWorld).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;虽然把我引导去了一篇FAQ，但看完我还是不知道是怎么回事。关于这个问题的答案一搜一大把，这也说明看了FAQ仍然不明白的人远远不止我一个。&lt;br /&gt;
首先要知道这里appender的意思。它其实就是上面说到的真正执行记录日志工作的类库，在这里就是log4j。那它指出的问题就是log4j需要一个初始化配置，而我们并没有给它指定初始化配置。所以这个appender就不知道该怎们工作。&lt;br /&gt;
其实这也很容易理解，毕竟要记日志，你不告诉它日志级别、记录日志的路径和格式，它怎么能帮你决定这些事情呢？&lt;/p&gt;

&lt;p&gt;『小声说两句，其实这也是我写Java的时候感受最深最痛苦的事情，Java太过于讲究设计模式了，把任务的职责分的太细，导致本来很小的一件事都要绕来绕去引入很多东西，虽然这保证了大量菜鸟写起来不容易出错，但也导致了开发效率的降低和开发者的心情问题。』&lt;/p&gt;

&lt;p&gt;言归正传，最简单的办法是需要在main里面新建一个目录&lt;code&gt;resources&lt;/code&gt;，新建文件log4j.properties，写入&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;log4j.rootLogger=TRACE, file, stdout

log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.Target=System.out
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSS} %-5p [%c] - %m%n


log4j.appender.file=org.apache.log4j.RollingFileAppender
log4j.appender.file.File=./log/javavillage.log
log4j.appender.file.MaxFileSize=10000KB
log4j.appender.file.MaxBackupIndex=10
log4j.appender.file.layout=org.apache.log4j.PatternLayout
log4j.appender.file.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} [%t] %-5p:: %m%n
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这段配置文件做了以下几件事：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;第一行设置了日志级别TRACE，意思是记录TRACE和高于TRACE级别的所有日志，因为TRACE是最低的，所以这里设置的是所有日志都会记录。什么意思呢？log4j有这几个日志级别：TRACE,DEBUG,INFO,WARN,ERROR,FATAL，这几个级别从左到右依次升高。也越来越不详细。也就是说，如果设置了日志级别是INFO，那么&lt;code&gt;LOG.trace()&lt;/code&gt;和&lt;code&gt;LOG.debug()&lt;/code&gt;这种语句会被忽略，而后面四中是会正常执行的。&lt;/li&gt;
&lt;li&gt;日志输出的位置，这里设置的是文件和标准输出&lt;/li&gt;
&lt;li&gt;分别设置了两种输出位置的一些属性，比如输出到标准输出应该是什么样的格式，用什么标准来做文本替换，用什么样的时间格式等等；至于输出到文件的情况就比较复杂了，因为还牵涉到文件的路径，文件大小上限等。具体这个项需要怎么配置我也没有详细的研究，以后如果需要再用到Java并且有需求再说吧。毕竟我不太喜欢Java。需要的可以参考这里&lt;a href=&#34;https://www.tutorialspoint.com/log4j/log4j_logging_files.htm&#34;&gt;1&lt;/a&gt;。&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>使用maven创建和运行Java应用</title>
      <link>http://lovelock.coding.me/java/create-and-run-java-application-with-maven/</link>
      <pubDate>Thu, 22 Sep 2016 14:15:41 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/java/create-and-run-java-application-with-maven/</guid>
      <description>

&lt;p&gt;最近这段时间在研究Storm，虽然不是研究源码而是研究使用，也让我这个自认为会写Java HelloWorld的菜鸟感到了深深的无力感。尤其是打开一本书，上面第一行代码就执行报错时我的心情可想而知了。&lt;/p&gt;

&lt;h3 id=&#34;1-创建应用&#34;&gt;1. 创建应用&lt;/h3&gt;

&lt;p&gt;因为我最近的使用场景是创建一个普通项目（区别于Web项目），所以直接用&lt;code&gt;mvn archetype:generate&lt;/code&gt;根据提示如果默认一路点下来会生成一个简单应用的骨架。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;注意：如果你在哪里看到&lt;code&gt;mvn archetype:create&lt;/code&gt;这样的写法，而在你的机器上执行出错，不用怀疑，因为你看到的资料太老了，而你用的是新版的maven，按我的写法没有错。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://ww1.sinaimg.cn/large/006y8lVajw1f840c2rryxj31ey100n83.jpg&#34; alt=&#34;创建应用的过程&#34; /&gt;&lt;/p&gt;

&lt;p&gt;如果需要生成webapp类型应用，比如一个基于SpringFramework的应用就不是831了，而是类似这样&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mvn archetype:generate -DarchetypeArtifactId=maven-archetype-webapp\
                        -DinteractiveMode=false \
                        -DgroupId=com.unixera.webapp \
                        -DartifactId=spring-example
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体再到里面怎么写应用这里就不展开了，如果有时间的话会有相关的文章单独来介绍。&lt;/p&gt;

&lt;h3 id=&#34;2-打包应用&#34;&gt;2. 打包应用&lt;/h3&gt;

&lt;p&gt;经过上面的&lt;code&gt;mvn archetype:generate&lt;/code&gt;命令之后，创建的目录类似这样
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f84hsklj4oj30g003ejrn.jpg&#34; alt=&#34;根目录结构&#34; /&gt;
如果再往深了看，是这样的
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f84huul3ihj30jq0j8ab7.jpg&#34; alt=&#34;树状结构&#34; /&gt;
其中最需要注意的就是&lt;code&gt;pom.xml&lt;/code&gt;这个文件，关于maven的简单使用可以参考我之前写的&lt;a href=&#34;http://unixera.com/java/mvn-tutorial-for-novice/&#34;&gt;给Java新手看的mvn指南&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;写完了应用当然是希望执行它，我们知道Java程序是需要编译成字节码之后才能执行的，当你学Java的HelloWorld时一般是告诉你&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;javac HelloWorld.java
java HelloWorld
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这没有问题，但问题是当我们用maven管理一个项目时当然就不能这么去操作了，就像写C代码时直接用gcc编译和写Makefile使用make来管理项目是一样的道理。&lt;/p&gt;

&lt;h4 id=&#34;普通的jar包&#34;&gt;普通的jar包&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;mvn compile&lt;/code&gt;&lt;br /&gt;
这时可以尝试在根目录里执行&lt;code&gt;mvn compile&lt;/code&gt;看看结果。
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f84hzh3knjj31bk0l6dmm.jpg&#34; alt=&#34;&#34; /&gt;
这相当于执行&lt;code&gt;javac&lt;/code&gt;，只不过根据mvn的默认配置，它把编译生成的class文件放在了指定的位置，那它究竟生成了哪些文件呢？
&lt;img src=&#34;http://ww1.sinaimg.cn/large/006y8lVajw1f84i209hshj30xu0x241u.jpg&#34; alt=&#34;&#34; /&gt;
可以看到，它并没有生成我们希望的&lt;strong&gt;可以发布的jar包&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn package&lt;/code&gt;&lt;br /&gt;
我们知道，其实jar包的本质就是zip，是把项目执行需要的资源全部打包（此处不准确，后面会谈）在一起发布的方式。而&lt;code&gt;mvn package&lt;/code&gt;执行的就是打包的过程。
&lt;img src=&#34;http://ww1.sinaimg.cn/large/006y8lVajw1f84i6llp9cj31di194k5p.jpg&#34; alt=&#34;&#34; /&gt;
这里的输出结果也验证了之前的文章中提到的说法。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;compile test package install&lt;/code&gt;是一套流程，执行后面的命令时会重复执行前面的命令&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;再来看&lt;code&gt;mvn package&lt;/code&gt;生成了哪些文件（只看target目录即可）
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f84ibl3z03j30qm0xw78g.jpg&#34; alt=&#34;&#34; /&gt;
重点关注红线标注的jar包，这是我们需要的。
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f84iezqgjrj313c0h0jvy.jpg&#34; alt=&#34;&#34; /&gt;
这就是jar包中的所有东西。你可能知道执行一个jar包需要的命令时&lt;code&gt;java -jar xxxx.jar&lt;/code&gt;，然并卵，这时执行这个是会出错的。解决方法后面会说。
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f84iggkm9nj30vi02at9g.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;使用mvn生成main-class&#34;&gt;使用mvn生成Main-Class&lt;/h4&gt;

&lt;p&gt;下面来解释一下为什么简单的打包并不能生成可以直接执行的jar包。
首先需要了解一点Manifest的知识&lt;a href=&#34;https://docs.oracle.com/javase/tutorial/deployment/jar/manifestindex.html&#34;&gt;2&lt;/a&gt;。简单来说，就是一个jar包需要Manifest文件中包含指定的内容才可以执行。那我们根据前面的经验，用&lt;code&gt;mvn package&lt;/code&gt;生成的jar包中是包含&lt;code&gt;META-INF/MANIFEST.MF&lt;/code&gt;的，实际上jar包运行需要的就是这个所谓的Manifest文件。
打开它看一下
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f88hw52bhvj30kg06caax.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;根据Java SE官方文档&lt;a href=&#34;https://docs.oracle.com/javase/tutorial/deployment/jar/appman.html&#34;&gt;3&lt;/a&gt;, 一个Manifest文件中至少需要包含&lt;code&gt;Main-Class&lt;/code&gt;字段才可以使之使用&lt;code&gt;java -jar&lt;/code&gt;命令执行。&lt;/p&gt;

&lt;p&gt;那我们来试着修改一下
1. 把jar包解压：
&lt;img src=&#34;http://ww2.sinaimg.cn/large/006y8lVagw1f88i2b79rzj30zq0d00wv.jpg&#34; alt=&#34;&#34; /&gt;
2. 修改&lt;code&gt;META-INF/MANIFEST.MF&lt;/code&gt;文件，改成
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f88i3lfb2fj30pc08c0u5.jpg&#34; alt=&#34;&#34; /&gt;
（其中红框中的部分根据自己的实际报名填写）
3. 重新打包
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f88id79j1pj311a0cejv9.jpg&#34; alt=&#34;&#34; /&gt;
4. 再来执行一下
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f88ig6mioaj30ew020q32.jpg&#34; alt=&#34;&#34; /&gt;
没错，成功了。&lt;/p&gt;

&lt;p&gt;所以我们知道了直接生成的jar包不能执行是因为Manifest中缺少了指定Main-Class的指令。那么既然我们使用了mvn，依赖了pom.xml，那mvn当然是能帮我们直接解决这个问题的，不然要自己每次解压、修改再压缩得累死了。&lt;/p&gt;

&lt;p&gt;根据这个答案&lt;a href=&#34;http://stackoverflow.com/questions/574594/how-can-i-create-an-executable-jar-with-dependencies-using-maven&#34;&gt;4&lt;/a&gt;, 在&lt;code&gt;pom.xml&lt;/code&gt;中添加plugin配置即可&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependencies&amp;gt;
...
&amp;lt;/dependencies&amp;gt;

 &amp;lt;build&amp;gt;
    &amp;lt;plugins&amp;gt;
      &amp;lt;plugin&amp;gt;
        &amp;lt;groupId&amp;gt;org.apache.maven.plugins&amp;lt;/groupId&amp;gt;
        &amp;lt;artifactId&amp;gt;maven-assembly-plugin&amp;lt;/artifactId&amp;gt;
        &amp;lt;version&amp;gt;2.6&amp;lt;/version&amp;gt;
        &amp;lt;configuration&amp;gt;
          &amp;lt;archive&amp;gt;
            &amp;lt;manifest&amp;gt;
              &amp;lt;mainClass&amp;gt;com.unixera.mvn.App&amp;lt;/mainClass&amp;gt;
            &amp;lt;/manifest&amp;gt;
          &amp;lt;/archive&amp;gt;
        &amp;lt;/configuration&amp;gt;
      &amp;lt;/plugin&amp;gt;
    &amp;lt;/plugins&amp;gt;
  &amp;lt;/build&amp;gt;
&amp;lt;/project&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;再执行&lt;code&gt;mvn package&lt;/code&gt;生成的jar包的Manifest中就会带有Main-Class的信息了。&lt;/p&gt;

&lt;h4 id=&#34;jar-with-dependencies&#34;&gt;jar-with-dependencies&lt;/h4&gt;

&lt;p&gt;现在我们终于有了一个可以正常工作的类了，不妨给它添加一个依赖吧。比如我在另外一篇文章中提到的slf4j&lt;a href=&#34;http://unixera.com/java/use-slf4j-and-log4j-to-log-your-applications/&#34;&gt;5&lt;/a&gt;。
具体做法可以参考该文章。这里只谈打包的问题。现在我们的pom.xml文件中在dependencies段中应该包含这样一段：
&lt;img src=&#34;http://ww2.sinaimg.cn/large/006y8lVajw1f96nuir9vnj30m405ygmi.jpg&#34; alt=&#34;&#34; /&gt;
我在App.java中添加了slf4j的用例。按照之前的做法，仍然
&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8lVajw1f88lgk9cxxj31cs1787fv.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8lVajw1f88lgxno8yj311u090jv3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;怎么回事？明明已经引入了需要的包了，为什么会找不到类呢？
问题还是出在jar包的打包方式上。
有PHP使用经验并且用过Composer的同学可能知道，Composer管理依赖的方式非常简单，就是把你的项目需要的代码下载到你项目的目录中，然后通过Composer的Autoload功能把它们加载到使用它们的地方。
但Java不是这样，或者说mvn不是这样。
首先，mvn把所有的依赖的包都放在了用户的根目录下，默认是&lt;code&gt;$HOME/.m2/repository&lt;/code&gt;，在这个目录下可以看到各个vendor的各种版本的包。但是在目前我们配置的这种模式下，打成的jar包并不会包含这些东西，而且在执行jar包时，也不会去相应的目录去查找需要的包。
&lt;strong&gt;其实就是动态加载&lt;/strong&gt;。和写C时用到的.so文件是一个道理。如果希望我们的程序能到处能运行的话，最好把它的依赖都打成.a文件，然后和项目代码打成一个完整的包，所有依赖的类库都在同一个包里就不存在这种问题了。
所以需要引入一个新的打包方式&lt;code&gt;jar-with-dependencies&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;根据同样根据上面那个答案,还需要添加如下的配置
&lt;img src=&#34;http://ww2.sinaimg.cn/large/006y8lVajw1f96nstiz0qj30uy0ssn0y.jpg&#34; alt=&#34;&#34; /&gt;
再重新执行上面的过程，可以运行了。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;本来在上面的文章中引用的是maven的官方文档，后来在实际使用中发现那种方式经常失效，对照自己试验成功后的文章也不奏效，于是找到了前面提到的答案，看来即使是官方文档，也还是需要民间的工程师们来发现最佳实践啊。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;3-执行应用&#34;&gt;3. 执行应用&lt;/h3&gt;

&lt;p&gt;执行应用就很简单了，直接从java -help就可以获取很多信息，就不展开说了。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;java -cp $CLASSPATH -jar /path/to/jar-with-dependencies.jar&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;本文旨在引导读者一步一步创建可执行的jar包，包括工程骨架的创建，依赖管理，打包方式，重点谈了下打包方式对生成的jar包功能的影响。引用了不少官方文档，本文只是简略的描述了一下整个过程，更详细的配置可以追随我引用的文档继续研究。&lt;/p&gt;

&lt;p&gt;可能有读者会问为什么我用截图而不是代码块的方式来演示，其实我是怕你们偷懒哈哈哈。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DeepinLinux 体验报告</title>
      <link>http://lovelock.coding.me/linux/deepin-linux-experience/</link>
      <pubDate>Sat, 03 Sep 2016 17:20:45 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/linux/deepin-linux-experience/</guid>
      <description>

&lt;h2 id=&#34;为什么要写这篇文章&#34;&gt;为什么要写这篇文章&lt;/h2&gt;

&lt;p&gt;今天忽然看到知乎上的通知，发现两年前写的一篇答案现在还有人在关注和评论&lt;a href=&#34;https://www.zhihu.com/question/19694358/answer/26227403?group_id=748099576984006656#comment-158674705&#34;&gt;有人用国产的deepin吗？和其它Linux版本相比，有什么优点和不足呢？&amp;ndash;郁蓝的答案&lt;/a&gt;。也是无意间看到了有人让我再更新一下体验的要求（其实这个评论是很早之前的了，只不过今天刚注意到）。
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814221945.png&#34; alt=&#34;知乎答案评论截图&#34; /&gt;
虽然我也不是什么大神，但从我个人的感情来说，我还是很希望深度能做的更好的，所以就花了几个小时真的感受了一下。下面是我认为还比较中肯的看法。&lt;/p&gt;

&lt;h2 id=&#34;体验&#34;&gt;体验&lt;/h2&gt;

&lt;h3 id=&#34;1-官方网站-https-www-deepin-org&#34;&gt;1. &lt;a href=&#34;https://www.deepin.org/&#34;&gt;官方网站&lt;/a&gt;&lt;/h3&gt;

&lt;h4 id=&#34;华而不实&#34;&gt;华而不实&lt;/h4&gt;

&lt;p&gt;不得不说，这个网站初看上去还是挺好看的，但实际一看就是一个展示页，而且有相当的&lt;strong&gt;应付了事&lt;/strong&gt;的成分。那个国际排名也多少有点忽悠的感觉。。。
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814225102.png&#34; alt=&#34;深度官网展示&#34; /&gt;
因为对细节的展示很少，文档也是七零八碎，像我这样阅发行版无数的人当然很快就找到了安装方法（其实也没有找，只是按照经验），但对于完全不懂Linux的新手来说，很可能看一下就撤了。&lt;/p&gt;

&lt;h4 id=&#34;功能缺失&#34;&gt;功能缺失&lt;/h4&gt;

&lt;p&gt;即便这样，我觉得很多我关心的信息在网站上都没有展示出来。我是一名软件开发人员，说的更笼统一些是一名上班族，那从一个上班族的角度来看，如果要我从Windows迁移到Deepin OS，我会关注哪些东西？当然是办公软件的使用。这个&lt;strong&gt;办公软件&lt;/strong&gt;是广义上的，包括&lt;strong&gt;QQ,RTX,Office,搜狗输入法，邮件&lt;/strong&gt;等等，这个问题，产品经理肯定想过，因为我用了之后发现确实他们已经解决了，但在页面上并没有展示出来。甚至，我的希望是&lt;strong&gt;在页面上能有一个搜索框，我在安装之前就能知道哪些软件我能用，让我不会产生后顾之忧&lt;/strong&gt;。&lt;/p&gt;

&lt;h4 id=&#34;细节不到位&#34;&gt;细节不到位&lt;/h4&gt;

&lt;p&gt;我甚至点到了社区板块，看了一下更新日志，比如这篇&lt;a href=&#34;http://blog.deepin.org/2016/08/update-record-of-applications-in-deepin-store-2016-08/&#34;&gt;深度商店应用更新记录汇总2016-08&lt;/a&gt;。这样的汇总我实在是不想看，感觉就像是用awk+xargs处理了一下只把应用名打印出来的样子。我看到了两个问题：
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814225410.png&#34; alt=&#34;社区网页展示&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- 没有版本号，**差评**
- 应用名太拥挤，看起来不直观
- 层级不能回退，都实现成这样的控件竟然不能点击，简直不能忍
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;我看到右侧其实是又很多这种更新汇总的，我觉得这作为一个正常人是都能看得到的问题，但就是不知道为什么那么久了都还一直这样。这期的我看到下面又评论说到没有版本号的事情，管理员（不知道是不是）说下次会带上。&lt;/p&gt;

&lt;h4 id=&#34;小结&#34;&gt;小结&lt;/h4&gt;

&lt;p&gt;总的感觉就是&lt;strong&gt;华而不实&lt;/strong&gt;，对细节的考虑不到位，简直浪费了程序员们的辛苦劳动。东西再好，展示的窗口都不做好，怎么吸引人呢？我觉得要么就传统一些，做一个像&lt;a href=&#34;https://www.archlinux.org/&#34;&gt;ArchLinux官网&lt;/a&gt;那样的纯展示性网站，引导用户去一个完备的Wiki站点，要么就学一学现在的手机厂商，把现代化的网页做的详细一些，别让用户费了半天劲把页面从最上面拉到最下面了却发现什么也没看明白。&lt;/p&gt;

&lt;h3 id=&#34;1-安装直观感受&#34;&gt;1. 安装直观感受&lt;/h3&gt;

&lt;p&gt;没有LiveCD，差评。
很不理解的一点，我刻好了优盘启动盘准备先在LiveCD里体验一下，看到启动项只有一个&lt;strong&gt;Start installation&lt;/strong&gt;我就懵逼了。。。这是跟国产的流氓软件学的，不让尝，先买了再说么？&lt;/p&gt;

&lt;h3 id=&#34;2-缺点&#34;&gt;2. 缺点&lt;/h3&gt;

&lt;p&gt;整个安装界面就有些搞不清楚。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;没有保留像Ubuntu那样可以&lt;strong&gt;对用户透明的和其他系统共存&lt;/strong&gt;的功能。（貌似最近的这版从基于Ubuntu迁移到了Debian Sid，这样就可以解释了，关于迁移的事情后面会说）&lt;/li&gt;
&lt;li&gt;对高清屏的支持不好，这在上面的截图里都已经可以看到了，我的电脑是15寸1080P屏幕，显示的字体太小，伤眼睛&lt;/li&gt;
&lt;li&gt;选择完语言之后就没得回去了，只能往后，不能往前，这有点蛋疼&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;好在安装过程很顺利，也很快。这点很赞。&lt;/p&gt;

&lt;h3 id=&#34;3-亮点&#34;&gt;3. 亮点&lt;/h3&gt;

&lt;p&gt;吐槽完了也得有点亮点吧，也不枉我把Ubuntu分区都干掉装这个啊。界面风格没啥好说的，还提供了三种模式
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814180441.png&#34; alt=&#34;默认Dock模式&#34; /&gt;
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814230948.png&#34; alt=&#34;Windows Dock模式1&#34; /&gt;
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814231109.png&#34; alt=&#34;Windows Dock模式2&#34; /&gt;
看完上面三张图，你有什么感受？对，没有自己的灵魂，学谁都没学像。学苹果却没有Magic动画，学Windows又没有开始菜单。而且控制面板放在最右边是什么鬼？是为了适应触摸屏？模仿Windows8的交互？看吧，Windows10已经回归了，我估计这个控制面板也要改成传统模式了。
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814231725.png&#34; alt=&#34;控制面板&#34; /&gt;&lt;/p&gt;

&lt;p&gt;说了这些发现还是吐槽，真正的亮点在终端。貌似是修改版的Quake，但我可没有在Quake里面找到过这个功能，简直贴心。
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814232511.png&#34; alt=&#34;SSH管理功能&#34; /&gt;
试了一下，简直弱鸡啊，也仅仅是个管理，连私钥都不支持。好吧，完成度不高，忍了。&lt;/p&gt;

&lt;p&gt;应用商店的资源还是挺丰富的，常用的差不多都有——其实本来Gnome也都有了。重点在于深度为用户提供了几乎0成本使用QQ的机会，这点很重要，一直以来对中国用户来说，Linux最大的痛点不就是没有QQ么？
其他软件也是开箱即用，完整度还可以，但完成度有待提高。&lt;/p&gt;

&lt;h3 id=&#34;4-混乱&#34;&gt;4. 混乱&lt;/h3&gt;

&lt;p&gt;整个一下午用下来最大的感受就是&lt;strong&gt;混乱&lt;/strong&gt;，看起来深度桌面更像是基于Gnome的，也带了不少Gnome系的应用，但它其实又在Gnome的基础上加上了自己的想法，让体验变得更加不统一了。比如应用打开首选项的方式和图标都不统一，有些按钮的位置那是真隐晦，谁能看出来那是按钮我服谁。
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/DeepinScreenshot20160814235541.png&#34; alt=&#34;界面高度不统一&#34; /&gt;
至于其中的某些Qt的应用带了的体验不一致这里就不说了，目前也没什么好的解决办法。&lt;/p&gt;

&lt;h3 id=&#34;5-期望&#34;&gt;5. 期望&lt;/h3&gt;

&lt;p&gt;总的来说，功能做的还是不错的，因为加入了Windows上常用的软件，使得它基本上算是一个开箱即用的操作系统。尤其是搜狗输入法的加成，让它对普通用户的友好程度大增。我搜了一下，软件源里面是包含Jetbrains家的应用的。只不过版本比较老了而已。看起来也没有对其进行什么修改，不知道是什么耽搁了它和上游的同步。现在这个Quake的SSH管理功能太弱鸡，如果可以，我希望能把Windows上的XShell引进来，毕竟Mac和Linux上都没有一款这么好用的终端。&lt;/p&gt;

&lt;p&gt;总之，深度的这款操作系统还是很能解决中国人用Linux的痛点的，这些痛点真的不是加个天气软件和农历日历就能解决的。很多使用习惯的问题需要去引导和克服。有人说，有这闲工夫通过各种技术手段让Windows上的软件跑在Linux上还不如大力发展Linux的原生应用，简直是Naive，如果原生的这么好做，也就不会有CrossOver这样的收费软件了。这毕竟是软件提供商的问题，他们不重视，作为用户也只能想别的办法了，起码在目前看来，这种方式是最行之有效又一针见血的。&lt;/p&gt;

&lt;p&gt;我想提的建议是，产品经理要是没什么大问题的话就换了吧，现在的真心不称职。包括网站的和桌面端的，抄别人的东西都抄不到精髓，那只能说自己都不知道想抄什么。那壁纸怎么那么像一加天气的背景呢？看我还是个耿直的boy，一加的ROM不行，确实是开发不给力，而Deepin做不好，产品要负大部分责任。&lt;/p&gt;

&lt;p&gt;感谢深度在Linux国产化的进程中的突出贡献。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>给Java新手看的mvn指南</title>
      <link>http://lovelock.coding.me/java/mvn-tutorial-for-novice/</link>
      <pubDate>Sun, 28 Aug 2016 14:29:16 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/java/mvn-tutorial-for-novice/</guid>
      <description>

&lt;h2 id=&#34;官方定义&#34;&gt;官方定义&lt;/h2&gt;

&lt;p&gt;Maven是基于项目对象模型，可以通过一小段描述信息来管理项目的构建、报告和文档的软件管理工具。&lt;/p&gt;

&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;

&lt;p&gt;Maven的使用过程中最经常用到的就是依赖管理了，一个依赖也就是一个包，是包含了几个属性的
- &lt;code&gt;groupId&lt;/code&gt; 通常是公司域名的反写加上项目名，比如&lt;code&gt;com.unixera.mvndemo&lt;/code&gt;
- &lt;code&gt;artifactId&lt;/code&gt; 模块名，比如&lt;code&gt;project1&lt;/code&gt;
- &lt;code&gt;version&lt;/code&gt; 版本号，经常见到的是形如&lt;code&gt;1.0.0-SNAPSHOT&lt;/code&gt;这种，即快照版本，还有&lt;code&gt;RELEASE&lt;/code&gt;等。&lt;/p&gt;

&lt;h2 id=&#34;规定&#34;&gt;规定&lt;/h2&gt;

&lt;p&gt;它规定的目录结构如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;-src 
 -main
  -java
   -packagename
 -test
  -java
   -packagename
 -resource
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;基础命令&#34;&gt;基础命令&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mvn compile&lt;/code&gt; 编译项目&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn test&lt;/code&gt; 测试&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn package&lt;/code&gt; 打包&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn clean&lt;/code&gt; 删除已经生成的测试报告和字节码文件，其实就是删除target文件夹&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mvn install&lt;/code&gt; 安装jar包到本地目录中&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面这5个过程如果执行后面的，前面的也会自动执行。也就是说后面的命令是依赖前面的命令的。&lt;/p&gt;

&lt;h2 id=&#34;经常遇到的问题&#34;&gt;经常遇到的问题&lt;/h2&gt;

&lt;h3 id=&#34;1-间接依赖&#34;&gt;1. 间接依赖&lt;/h3&gt;

&lt;p&gt;A依赖B，B依赖C，那么A就间接的依赖了C，如果要显式的声明A不依赖C，可以在A的pom.xml中加入&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;
&amp;lt;dependecy&amp;gt;
	&amp;lt;groupId&amp;gt;BgroupId&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;BartifactId&amp;lt;/artifactId&amp;gt;
	&amp;lt;version&amp;gt;1.2.3&amp;lt;/version&amp;gt;
	&amp;lt;exclusions&amp;gt;
		&amp;lt;exclusion&amp;gt;
			&amp;lt;groupId&amp;gt;CgroupId&amp;lt;/groupId&amp;gt;
			&amp;lt;artifactId&amp;gt;CartifactId&amp;lt;/artifactId&amp;gt;
			&amp;lt;version&amp;gt;1.2.3&amp;lt;/version&amp;gt;
		&amp;lt;/exclusion&amp;gt;
	&amp;lt;/exclusions&amp;gt;
&amp;lt;/dependecy&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-如何添加依赖&#34;&gt;2. 如何添加依赖&lt;/h3&gt;

&lt;p&gt;比如项目要使用servlet，那就去&lt;a href=&#34;http://search.maven.org/&#34;&gt;全球中央仓库&lt;/a&gt;查找包名和相应的版本号,如图所示&lt;img src=&#34;http://ww4.sinaimg.cn/large/7853084cjw1f79btj2nb8j20fl0f9q4b.jpg&#34; alt=&#34;&#34; /&gt;。从中复制Apache Maven下面的一段XML粘贴到相应的&lt;code&gt;&amp;lt;dependencies&amp;gt;&amp;lt;/dependencies&amp;gt;&lt;/code&gt;中即可。&lt;/p&gt;

&lt;h3 id=&#34;3-变量的使用&#34;&gt;3. 变量的使用&lt;/h3&gt;

&lt;p&gt;有时在一个pom.xml文件中会看到有&lt;code&gt;${project.version}&lt;/code&gt;这种写法，那一看就是一个引用，这个东西是在&lt;code&gt;&amp;lt;properties&amp;gt;&amp;lt;/properties&amp;gt;&lt;/code&gt;中定义的，比如&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;properties&amp;gt;
    &amp;lt;maven.compile.source&amp;gt;1.5&amp;lt;/maven.compile.source&amp;gt;
    &amp;lt;maven.compile.target&amp;gt;1.5&amp;lt;/maven.compile.target&amp;gt;
&amp;lt;/properties&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样定义了之后在后面就可以用&lt;code&gt;${maven.compile.source}&lt;/code&gt;来引用了。&lt;/p&gt;

&lt;h3 id=&#34;4-一个项目下多个模块重复依赖一个包&#34;&gt;4. 一个项目下多个模块重复依赖一个包&lt;/h3&gt;

&lt;p&gt;下面着重说一下如何利用Maven的继承关系简化项目的POM配置。&lt;/p&gt;

&lt;h4 id=&#34;在项目的根目录下创建pom-xml&#34;&gt;在项目的根目录下创建pom.xml&lt;/h4&gt;

&lt;p&gt;还以上面的项目名为例，比如root目录是project,则在project目录里创建pom.xml&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;project xmlns=&amp;quot;http://maven.apache.org/POM/4.0.0&amp;quot; xmlns:xsi=&amp;quot;http://www.w3.org/2001/XMLSchema-instance&amp;quot;
	xsi:schemaLocation=&amp;quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;quot;&amp;gt;
	&amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt;
	&amp;lt;groupId&amp;gt;com.unixera&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;root&amp;lt;/artifactId&amp;gt;
	&amp;lt;version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/version&amp;gt;
	&amp;lt;packaging&amp;gt;pom&amp;lt;/packaging&amp;gt;
	
	&amp;lt;properties&amp;gt;
	    &amp;lt;project.version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/project.version&amp;gt;
	    &amp;lt;junit.version&amp;gt;4.10&amp;lt;/junit.version&amp;gt;
	    &amp;lt;jmock.version&amp;gt;2.8.2&amp;lt;/jmock.version&amp;gt;
	&amp;lt;/properties&amp;gt;
	
	&amp;lt;dependencies&amp;gt;
	    &amp;lt;dependency&amp;gt;
			&amp;lt;groupId&amp;gt;junit&amp;lt;/groupId&amp;gt;
			&amp;lt;artifactId&amp;gt;junit&amp;lt;/artifactId&amp;gt;
			&amp;lt;version&amp;gt;${junit.version}&amp;lt;/version&amp;gt;
			&amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt;
		&amp;lt;/dependency&amp;gt;
		&amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.jmock&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;jmock&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;${jmock.version}&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
	&amp;lt;/dependencies&amp;gt;
&amp;lt;/project&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就声明了该项目需要依赖junit，那么里面的子项目就用&lt;code&gt;mvn archetype:generate&lt;/code&gt;来交互式的生成，比如&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Choose org.apache.maven.archetypes:maven-archetype-quickstart version:
1: 1.0-alpha-1
2: 1.0-alpha-2
3: 1.0-alpha-3
4: 1.0-alpha-4
5: 1.0
6: 1.1
Choose a number: 6: 6
Define value for property &#39;groupId&#39;: : com.unixera.mvndemo
Define value for property &#39;artifactId&#39;: : project1
Define value for property &#39;version&#39;:  1.0-SNAPSHOT: :
Define value for property &#39;package&#39;:  com.unixera.mvndemo: :
Confirm properties configuration:
groupId: com.unixera.mvndemo
artifactId: project1
version: 1.0-SNAPSHOT
package: com.unixera.mvndemo
 Y: :
[INFO] ----------------------------------------------------------------------------
[INFO] Using following parameters for creating project from Old (1.x) Archetype: maven-archetype-quickstart:1.1
[INFO] ----------------------------------------------------------------------------
[INFO] Parameter: basedir, Value: /Users/frost/IdeaProjects
[INFO] Parameter: package, Value: com.unixera.mvndemo
[INFO] Parameter: groupId, Value: com.unixera.mvndemo
[INFO] Parameter: artifactId, Value: project1
[INFO] Parameter: packageName, Value: com.unixera.mvndemo
[INFO] Parameter: version, Value: 1.0-SNAPSHOT
[INFO] project created from Old (1.x) Archetype in dir: /Users/frost/IdeaProjects/project1
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 35.492 s
[INFO] Finished at: 2016-08-28T14:16:28+08:00
[INFO] Final Memory: 13M/201M
[INFO] ------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;进入&lt;code&gt;project&lt;/code&gt;目录，打开&lt;code&gt;pom.xml&lt;/code&gt;，可以看到mvn生成的项目已经默认依赖了junit，那我们来修改一下让它依赖parent所定义的junit。
首先加上&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;parent&amp;gt;
	&amp;lt;groupId&amp;gt;com.unixera.mvdemo&amp;lt;/groupId&amp;gt;
	&amp;lt;artifactId&amp;gt;root&amp;lt;/artifactId&amp;gt;
	&amp;lt;version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/version&amp;gt;
&amp;lt;/parent&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就可以把junit的依赖放心的删掉了，因为它已经认了root做parent，parent的依赖就是它的依赖了。&lt;br /&gt;
那如果parent的某些依赖它并不需要呢？可以在子项目中添加&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;dependencyManagement&amp;gt;
    &amp;lt;dependencies&amp;gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;com.unixera.mvndemo&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;root&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;1.0.0-SNAPSHOT&amp;lt;/version&amp;gt;
            &amp;lt;exclusions&amp;gt;
                &amp;lt;exclusion&amp;gt;
                    &amp;lt;groupId&amp;gt;org.jmock&amp;lt;/groupId&amp;gt;
                    &amp;lt;artifactId&amp;gt;jmock&amp;lt;/artifactId&amp;gt;
                    &amp;lt;version&amp;gt;2.8.2&amp;lt;/version&amp;gt;
                &amp;lt;/exclusion&amp;gt;
            &amp;lt;/exclusions&amp;gt;
        &amp;lt;/dependency&amp;gt;
    &amp;lt;/dependencies&amp;gt;
&amp;lt;/dependencyManagement&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样子项目就不依赖jmock模块了。&lt;/p&gt;

&lt;p&gt;当然mvn的使用远远不止这些，这里记录一些目前使用到的，后面如果还继续回写Java的话会再更新一下。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用ssh-config提升你的生产力</title>
      <link>http://lovelock.coding.me/mac/use-ssh-config-to-tune-your-productivity-up/</link>
      <pubDate>Tue, 09 Aug 2016 14:57:11 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/mac/use-ssh-config-to-tune-your-productivity-up/</guid>
      <description>

&lt;p&gt;我们做服务端开发的，每天最烦心的事情可能就是登陆各种服务器了。在Windows上还好，有SecureCRT还有XShell这种很强大的工具可以用，但在Mac下面选择就很少了。SecureCRT我个人感觉远远不如Windows下的稳定，而渲染效果我当然还是最喜欢iTerm了。其实并没有用到它的很强大的那些功能，比如窗口分割、全局查找等等，最能打动我的其实是智能复制粘贴。不多说了，下面说一下怎样用ssh的config文件来记住登录账户。&lt;/p&gt;

&lt;h2 id=&#34;常规的解决方案&#34;&gt;常规的解决方案&lt;/h2&gt;

&lt;p&gt;我们最习惯用已知的知识来解决新问题。所以当然你会在.bashrc中添加一条&lt;code&gt;alias dev=&#39;ssh root@10.69.41.41&#39;&lt;/code&gt;这种命令了——注意，这个指令在多数环境中其实是不适用的，因为还面临通道机——最让开发头痛的东西。&lt;/p&gt;

&lt;p&gt;所以让我们来发掘一下ssh的强大威力。&lt;/p&gt;

&lt;h2 id=&#34;用ssh-config提高效率&#34;&gt;用ssh config提高效率&lt;/h2&gt;

&lt;h3 id=&#34;可以直连的机器&#34;&gt;可以直连的机器&lt;/h3&gt;

&lt;p&gt;如果可以直连一台机器，比如我的192.168.1.104虚拟机，那就可以在&lt;code&gt;.ssh/config&lt;/code&gt;中添加一段记录&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Host debian
	Hostname 192.168.1.104
	Port 22
	User frost
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;不需重启，现在执行&lt;code&gt;ssh debian&lt;/code&gt;就可以连接debian机器了。&lt;br /&gt;
那么问题来了，通常来说，Linux环境中是找不到明文存储的密码的，这里也不例外，肯定不会让你把密码直接写在这个配置文件中。要实现重新打开一个标签连接同一台机器不需要重新输密码，有两种方式。&lt;/p&gt;

&lt;h4 id=&#34;1-用key登录&#34;&gt;1. 用key登录&lt;/h4&gt;

&lt;p&gt;具体操作这里不展开，这里只需要把key的路径加在配置文件里即可。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Host debian
	Hostname 192.168.1.104
	IdentityFile ~/.ssh/coolio.example.key
	Port 22
	User frost
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;即可。这是最简单直接的方式。&lt;/p&gt;

&lt;h4 id=&#34;2-模拟securecrt的-复制会话-功能&#34;&gt;2. 模拟SecureCRT的『复制会话』功能&lt;/h4&gt;

&lt;p&gt;也就是说，在一个标签登录了一台机器之后，会在本地保存一份该会话的标识文件。当重新连接这个机器时，会使用这个临时文件当做认证，直接登录而无需验证。局限是如果重启了终端，就需要重新输入一次密码。&lt;br /&gt;
要实现这个功能，只需要在&lt;code&gt;.ssh/config&lt;/code&gt;里加入这样一段&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Host *
ControlMaster auto
ControlPath ~/.ssh/master-%r@%h:%p
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;你可能要问了，key那么方便，为什么需要这样呢？这是因为我们认为key已经很安全了，但安全组的同事可能觉得也没那么安全，他们希望我们用安全性更高的静态密码+动态口令的方式登录跳板机，而且跳板机是无法存储任何文件的，无法实现保存key。&lt;/p&gt;

&lt;h3 id=&#34;无法直连的机器&#34;&gt;无法直连的机器&lt;/h3&gt;

&lt;p&gt;前面提到了跳板机，登录到跳板机当然不是目的，还要登录各种各样的机器，如果我要经常登录一台跳板机后的机器，难道要每次都先登录跳板机（虽然不用每次都输入密码）然后再手工跳转到另一台机器？当然不是。这里要引入『本地端口转发』的概念。
说白了就是我们指定一个本地端口，往这个端口发送的所有数据都会通过&lt;strong&gt;跳板机&lt;/strong&gt;被转发到另外一台机器的指定端口。注意两个指定端口不需要是一样的。比如我希望通过本地的2222端口来登录一台开发机的22端口。就需要这样配置一个隧道&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Host tunnel
	HostName 10.0.0.2
	LocalForward 2222 10.30.43.23:22
	User frost
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样执行&lt;code&gt;ssh -f -N tunnel&lt;/code&gt;就会建立这条本地端口转发的隧道。其实还需要一段配置&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Host dev
	HostName 127.0.0.1
	Port 2222
	User root
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然，看到&lt;code&gt;ssh -f -N tunnel&lt;/code&gt;这条这么长的指令还是不爽，这时就可以用alias来简化输入了。&lt;/p&gt;

&lt;h3 id=&#34;服务器和本地传输文件&#34;&gt;服务器和本地传输文件&lt;/h3&gt;

&lt;p&gt;其实用SecureCRT或者XShell还有一个很重要的原因是二者对lrzsz这个小工具的支持很好，而几乎所有的终端工具都存在各种问题，iTerm2也不例外。虽然也可以有workaround来解决，但毕竟不是原生，不好用。我也纠结了很久，原来Mac上没有相应的工具是因为真的不需要啊。&lt;br /&gt;
现在跟我一起做，比如我们前面已经配了一个可以本地直连的远程机器debian，当需要传输文件的时候只需要在本地命令窗口打开&lt;code&gt;sftp debian&lt;/code&gt;就会打开一个交互的shell。那么不要怕，虽然它有很多命令，但我觉得简单的使用只需要记住4组命令就好了，而且其中3组是原来就会的。&lt;br /&gt;
首先要知道本地和远程的概念，因为你执行了这个命令之后其实已经登陆了了远程机器了，只不过不在bash里面，所以现在你要操作本地的东西时，所有命令都要加上&lt;code&gt;l&lt;/code&gt;也就是local，而远程的就什么都不加了。&lt;br /&gt;
所以记住下面几个命令：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;lpwd&lt;/code&gt; 查看本地机器当前所在目录&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pwd&lt;/code&gt; 查看远程机器当前所在目录&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lls&lt;/code&gt; 查看本地机器当前目录下的文件列表&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ls&lt;/code&gt; 查看远程机器当前目录下的文件列表&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lcd dir&lt;/code&gt; 在本地切换到目标目录&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd dir&lt;/code&gt; 在远程主机上切换到目标目录&lt;/li&gt;
&lt;li&gt;&lt;code&gt;put filename&lt;/code&gt; 把本地的文件放在远程主机的当前位置&lt;/li&gt;
&lt;li&gt;&lt;code&gt;get filename&lt;/code&gt; 把远程机器上的目录下载到本地当前位置&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这和SecureCRT的实现方式是完全一样的，XShell好封装了一个两栏的文件管理器呢，这样看来XShell真的是业界良心。&lt;/p&gt;

&lt;p&gt;有人可能会说用expect来实现密码自动填充也是极好的。这个问题，见仁见智吧，至少用了一段时间之后我是不喜欢用expect了，最主要的问题在于窗口的自动缩放，就不展开说了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>谈谈转基因食物</title>
      <link>http://lovelock.coding.me/miscs/talk-about-transgene-foods/</link>
      <pubDate>Sun, 17 Jul 2016 22:53:33 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/miscs/talk-about-transgene-foods/</guid>
      <description>&lt;p&gt;这件事情其实我没有怎么关注过，到超市去买油什么的也是全凭一时冲动，没有固定的品牌和品种。&lt;/p&gt;

&lt;p&gt;因为我是生物专业毕业的，知道的人难免会让我谈谈关于转基因食物的看法，因为我并不了解社会上对这件事的主流看法是怎样的，所以在谈这个问题时往往不太敢太明显的表达自己的观点，而会模棱两可的说我认为转基因是无害的，而具体是否是这样，还需要科学家们去证实。&lt;/p&gt;

&lt;p&gt;我觉得任何一个学过高中生物课的人都应该能明白这个道理。我们吃的食物在体内是经过消化和分解过程的。最终吸收到体内的不过是一个个的生物大分子片段，这些片段包括氨基酸，也就是蛋白质的组成结构，当然也有（脱氧）核糖核酸，注意，我说的是片段，因为它们也仅仅是片段，它们的作用是为我们提供营养物质，而不是改变我们身体的性状。&lt;/p&gt;

&lt;p&gt;之所以很多人一提到转基因就害怕，可能是社会上某些公知人士的大肆渲染，毕竟因为自己不懂，对那些认为自己很懂又很愿意宣传，同时很有影响力的人当然大多数人会选择深信不疑。这种盲从很可怕。&lt;/p&gt;

&lt;p&gt;看过我文章的读者可能知道我喜欢用最贴近生活的例子来阐述一件事情。那对于转基因这件事，我还是有个例子可以说。&lt;/p&gt;

&lt;p&gt;转基因可以分为自然转基因和人工转基因。大多数人害怕的其实是『人工转基因』。想理解人工转基因，那就得先知道什么是自然转基因。其实自然转基因在生活中处处可见，比如你家的小狗狗生了一群小小狗狗，小小狗狗的爸爸妈妈都是黑色的，但有可能这群小小狗狗里有一只身上出现了白色的斑点，这就有可能是基因突变引起的。我说有可能是因为关于狗的遗传特性我并没有具体研究，不知道毛色是显性还是隐形性状。咱们单说这个毛色的突变，从基因的层面上说就是有可能小小狗狗的某一条染色体上的F变成了F1,然后它翻译、转码生成的蛋白质就变成了白色。当这只小小狗狗再生小宝宝时，这种白色的性状就有可能保留了下来。假设，在这只小狗之前世界上没有带白色斑点的狗，那么严格的说，我们甚至可以说基因突变『产生』了一种新的性状。&lt;/p&gt;

&lt;p&gt;其实，基因突变就是一种自然转基因的类型。我说它是一种类型，那肯定就还有别的类型，那就是杂交了。别以为只有在人类的干预下才会有杂交的出现，其实自然界中这种现象相当普遍。一般来说生物之间是有自然隔离的，但大自然就是这么神奇，万一两种生物的染色体条数一样多，再加上其他因素也匹配，那么两种生物就有可能杂交而产生一种新的物种。当然我印象中的杂交产物就是骡子了，但骡子是没有繁殖能力的，并不能算是新的物种。&lt;/p&gt;

&lt;p&gt;那对应基因突变和杂交，人工转基因究竟干了什么呢？&lt;/p&gt;

&lt;p&gt;对狭义的转基因（排除杂交）而言，转基因就是把一个物种的DNA上某些片段重新编码成新的序列，从而产生新的性状。（这不是教科书上的定义，可能并不准确，只是我的理解）而产生这种重新编码的方法也有多种，有可能是从其他物种的DNA上截取一截粘贴上去，也可能是直接人工重新排序一段编码，还有最初的用宇宙射线什么的引发基因突变等等，当年学的什么密码子啥玩意儿的都忘得差不多了，只需要知道这些技术现在已经工业化了就对了，根本不是问题。&lt;/p&gt;

&lt;p&gt;想想有点可笑，外面都说我们中国人什么都吃，但到了转基因这里却变得异常谨慎了。&lt;/p&gt;

&lt;p&gt;那么，我就想问了，黑色狗是狗，带斑点的狗还是狗吗？『正常』的大豆是大豆，转基因的大豆就不是大豆了？你吃的转基因豆油大部分只是脂肪而已，到了肚子里是还要经过消化的，它只不过变成了我们需要的各种氨基酸等，并没有让我们的基因重排，并不会改变我们的性状。&lt;/p&gt;

&lt;p&gt;今天还看到微博上自称『央视新闻』的媒体说某些主要成分是『氯化钠』的假冒食盐已经流向市场，长期食用氯化钠可引起头晕等等症状，说的头头是道，我看了好多遍到底说的是不是氯化钠，最后确定还真是，而且这个微博账号确实是官方的。这么说那还不如说『某某生成的劣质水，主要成分是一氧化二氢，大量食用会引起膀胱胀痛』。&lt;/p&gt;

&lt;p&gt;如果你觉得民智没有开启，那么就请尽自己的一份力量多解释一下；如果他们不愿意听，你可以解释给下一个人听，没有必要变得像他们一样，网络上全是乌烟瘴气的对骂，没有意义，而且会让自己显得和他们一样，只是喷子，更没有人愿意听你的真相了。&lt;/p&gt;

&lt;p&gt;以上。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PHP扩展实战——扩展的骨架</title>
      <link>http://lovelock.coding.me/php/internals/create-skeleton-of-extension/</link>
      <pubDate>Sat, 09 Apr 2016 22:04:18 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/php/internals/create-skeleton-of-extension/</guid>
      <description>

&lt;p&gt;前面啰嗦了这么多读者都要没有兴趣了。从现在起要真正开始PHP扩展开发阶段了。&lt;/p&gt;

&lt;p&gt;首先来生成扩展的骨架。所谓骨架就是一个扩展需要的基本文件了。&lt;/p&gt;

&lt;h2 id=&#34;获取php源码&#34;&gt;获取PHP源码&lt;/h2&gt;

&lt;p&gt;截至目前，PHP最新源码是7.0.5。&lt;a href=&#34;http://cn2.php.net/get/php-7.0.5.tar.bz2/from/this/mirror&#34;&gt;下载链接&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;➜  projects wget http://cn2.php.net/get/php-7.0.5.tar.bz2/from/this/mirror -O php705.tar.bz2
--2016-04-09 10:18:39--  http://cn2.php.net/get/php-7.0.5.tar.bz2/from/this/mirror
Resolving cn2.php.net (cn2.php.net)... 202.108.35.194, 202.108.35.235, 202.108.35.237, ...
Connecting to cn2.php.net (cn2.php.net)|202.108.35.194|:80... connected.
HTTP request sent, awaiting response... 302 Found
Location: http://cn2.php.net/distributions/php-7.0.5.tar.bz2 [following]
--2016-04-09 10:18:39--  http://cn2.php.net/distributions/php-7.0.5.tar.bz2
Reusing existing connection to cn2.php.net:80.
HTTP request sent, awaiting response... 200 OK
Length: 14086522 (13M) [application/octet-stream]
Saving to: ‘php705.tar.bz2’

php705.tar.bz2                             100%[=======================================================================================&amp;gt;]  13.43M  4.49MB/s    in 3.0s

2016-04-09 10:18:42 (4.49 MB/s) - ‘php705.tar.bz2’ saved [14086522/14086522]

➜  projects md5sum php705.tar.bz2
b15e6836babcbf0aa446678ee38f896b  php705.tar.bz2
➜  projects echo b15e6836babcbf0aa446678ee38f896b
b15e6836babcbf0aa446678ee38f896b
➜  projects tar xjf php705.tar.bz2
➜  projects cd php-7.0.5/ext
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;终于来到了正题了。我现在也终于明白鸟哥为啥费劲写个生成Yaf最小化应用的脚本了，就是从写扩展的经历中得来的，既然可以帮用户做的更多，那就帮一下好了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;➜  ext ./ext_skel --extname=hylog
Creating directory hylog
Creating basic files: config.m4 config.w32 .gitignore hylog.c php_hylog.h CREDITS EXPERIMENTAL tests/001.phpt hylog.php [done].

To use your new extension, you will have to execute the following steps:

1.  $ cd ..
2.  $ vi ext/hylog/config.m4
3.  $ ./buildconf
4.  $ ./configure --[with|enable]-hylog
5.  $ make
6.  $ ./sapi/cli/php -f ext/hylog/hylog.php
7.  $ vi ext/hylog/hylog.c
8.  $ make

Repeat steps 3-6 until you are satisfied with ext/hylog/config.m4 and
step 6 confirms that your module is compiled into PHP. Then, start writing
code and repeat the last two steps as often as necessary.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样，&lt;code&gt;ext_skel&lt;/code&gt;就帮我们生成了一个名为&lt;code&gt;hylog&lt;/code&gt;的扩展框架。&lt;/p&gt;

&lt;p&gt;下面要介绍一下安装扩展的两种方式了，一种是直接编译进PHP，一种是接下来我们要讨论的这种，即动态加载的扩展。&lt;/p&gt;

&lt;p&gt;什么是直接编译进PHP呢？&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;➜  ext cd hylog
➜  hylog ls
config.m4  config.w32  CREDITS  EXPERIMENTAL  hylog.c  hylog.php  php_hylog.h  tests
➜  hylog vim config.m4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;会看到这样的几行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-m4&#34;&gt;dnl If your extension references something external, use with:

dnl PHP_ARG_WITH(hylog, for hylog support,
dnl Make sure that the comment is aligned:
dnl [  --with-hylog             Include hylog support])

dnl Otherwise use enable:

dnl PHP_ARG_ENABLE(hylog, whether to enable hylog support,
dnl Make sure that the comment is aligned:
dnl [  --enable-hylog           Enable hylog support])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中的&lt;code&gt;dnl&lt;/code&gt;是注释，主要看&lt;code&gt;--with-hylog&lt;/code&gt;和&lt;code&gt;--enable-hylog&lt;/code&gt;。假定你来看本文，你一定自己编译过PHP了，如果没有，那先去整一遍再回来看吧：）
是这样的，我们在编译PHP的时候经常会碰到类似这种&lt;code&gt;--with[out]-blah=/path/to/foo&lt;/code&gt;或者&lt;code&gt;--enable-blah&lt;/code&gt;或者&lt;code&gt;--disable-blah&lt;/code&gt;的选项吧。其实对编写扩展的我们来说，这两种都是可行的，并没有本质上的区别，只是一般用&lt;code&gt;--with&lt;/code&gt;会带个路径，告诉PHP这个扩展依赖的外部库的路径，而&lt;code&gt;--enable&lt;/code&gt;则表示该扩展是独立的，或者依赖的库在默认的搜索路径内。&lt;/p&gt;

&lt;p&gt;那和我们说的两种安装方式有什么关系呢？不如我们就来真的安装一下看看效果吧。&lt;/p&gt;

&lt;p&gt;看上面的注释，我们知道了需要把&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-m4&#34;&gt;dnl PHP_ARG_ENABLE(hylog, whether to enable hylog support,
dnl Make sure that the comment is aligned:
dnl [  --enable-hylog           Enable hylog support])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这段改成&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-m4&#34;&gt;PHP_ARG_ENABLE(hylog, whether to enable hylog support,
dnl Make sure that the comment is aligned:
[  --enable-hylog           Enable hylog support])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至于是喜欢用&lt;code&gt;--enable&lt;/code&gt;还是喜欢用&lt;code&gt;--with&lt;/code&gt;看个人喜好了，因为本例中并没有用到外部依赖，所以用&lt;code&gt;--enable&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;提醒一下，改完之后最好把当前的这个状态保存下来——创建一个git工作目录就好了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;➜  hylog git init
Initialized empty Git repository in /home/frost/projects/php-7.0.5/ext/hylog/.git/
➜  hylog git:(master) ✗ gst
On branch master

Initial commit

Untracked files:
  (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to include in what will be committed)

	.gitignore
	CREDITS
	EXPERIMENTAL
	config.m4
	config.w32
	hylog.c
	hylog.php
	php_hylog.h
	tests/

nothing added to commit but untracked files present (use &amp;quot;git add&amp;quot; to track)
➜  hylog git:(master) ✗ ga .
➜  hylog git:(master) ✗ gc -m &#39;init hylog&#39;
[master (root-commit) 58e5e4a] init hylog
 Committer: frost &amp;lt;frost@debian.unixera.com&amp;gt;
Your name and email address were configured automatically based
on your username and hostname. Please check that they are accurate.
You can suppress this message by setting them explicitly. Run the
following command and follow the instructions in your editor to edit
your configuration file:

    git config --global --edit

After doing this, you may fix the identity used for this commit with:

    git commit --amend --reset-author

 9 files changed, 409 insertions(+)
 create mode 100644 .gitignore
 create mode 100644 CREDITS
 create mode 100644 EXPERIMENTAL
 create mode 100644 config.m4
 create mode 100644 config.w32
 create mode 100644 hylog.c
 create mode 100644 hylog.php
 create mode 100644 php_hylog.h
 create mode 100644 tests/001.phpt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为什么要这么做呢？其实主要是想让这个目录干净，因为待会儿执行了一些命令之后会生成很多文件，如果你想清除这些文件就变得很麻烦。但现在我只把这些文件&lt;code&gt;commit&lt;/code&gt;了，待会儿生成文件后，如果我想删除，就可以用&lt;code&gt;git clean -df&lt;/code&gt;，立即回到现在的状态。但关于&lt;code&gt;git&lt;/code&gt;的操作，那就是另外一回事了（强烈推荐&lt;a href=&#34;http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000&#34;&gt;廖雪峰的git教程&lt;/a&gt;)。&lt;/p&gt;

&lt;h3 id=&#34;编译进php&#34;&gt;编译进PHP&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;重新生成配置文件&lt;/p&gt;

&lt;p&gt;注意其中的&lt;code&gt;./buildconf --force&lt;/code&gt;，之所以带&lt;code&gt;--force&lt;/code&gt;是因为我们是在正式版的PHP源码中进行操作的，正常情况下使用这种方式编译的都是内建扩展，例如&lt;code&gt;PDO&lt;/code&gt;这种，是PHP官方团队开发的，所以你非要用这种方式编译的话，就强制一下好了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;➜  hylog git:(master) cd ..
➜  ext cd ..
➜  php-7.0.5 ./buildconf --force
Forcing buildconf
Removing configure caches
buildconf: checking installation...
buildconf: autoconf version 2.69 (ok)
rebuilding aclocal.m4
rebuilding configure
rebuilding main/php_config.h.in
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;查找变化&lt;/p&gt;

&lt;p&gt;刚刚的操作背后发生了什么呢？注意&lt;code&gt;rebuilding&lt;/code&gt;的三行，那我们就挨个看看。分别在三个文件中搜索&lt;code&gt;hylog&lt;/code&gt;关键字吧。
在&lt;code&gt;aclocal.m4&lt;/code&gt;中未找到变化。
在&lt;code&gt;configure&lt;/code&gt;中有大量变化，稍后介绍能看到的变化。
在&lt;code&gt;main/php_config.h.in&lt;/code&gt;中，增加了两行，用来取消&lt;code&gt;COMPILE_DL_HYLOG&lt;/code&gt;的定义，表示该扩展不是动态加载。&lt;/p&gt;

&lt;p&gt;这时检查一下&lt;code&gt;configure --help&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;➜  php-7.0.5 ./configure --help | grep hylog
  --enable-hylog           Enable hylog support
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;诶，有点眼熟对不对？就是刚才在&lt;code&gt;ext/hylog/config.m4&lt;/code&gt;中取消注释的内容。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;编译PHP&lt;/p&gt;

&lt;p&gt;既然要把它编译进来，那就加上&lt;code&gt;--enable-hylog&lt;/code&gt;吧。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;➜  php-7.0.5 ./configure --enable-hylog
➜  php-7.0.5 make
➜  php-7.0.5 sudo make install
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;查看已安装的扩展&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;➜  php-7.0.5 php -v
PHP 7.0.5 (cli) (built: Apr  9 2016 11:08:08) ( NTS )
Copyright (c) 1997-2016 The PHP Group
Zend Engine v3.0.0, Copyright (c) 1998-2016 Zend Technologies
➜  php-7.0.5 php -m
[PHP Modules]
Core
ctype
date
dom
fileinfo
filter
hash
hylog
iconv
json
libxml
pcre
PDO
pdo_sqlite
Phar
posix
Reflection
session
SimpleXML
SPL
sqlite3
standard
tokenizer
xml
xmlreader
xmlwriter
    
[Zend Modules]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在可以看到我们新创建的扩展已经编译进PHP了——虽然它没有任何功能。可以再到&lt;code&gt;/usr/local/lib/php/extensions/no-debug-non-zts-20151012&lt;/code&gt;中验证一下是不是真的没有&lt;code&gt;hylog.so&lt;/code&gt;存在。&lt;/p&gt;

&lt;p&gt;所以如果不想用它了怎么办呢？你当然可以选择无视它，但最好还是卸载了吧，卸载的方法也很简单，&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;➜  php-7.0.5 ./configure --disable-hylog
➜  php-7.0.5 make
➜  php-7.0.5 sudo make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;看起来就是三行，其实要用很长时间，所以，像我们这样的第三方扩展开发者还是不要用这种方式比较好。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;动态加载&#34;&gt;动态加载&lt;/h3&gt;

&lt;p&gt;动态加载方式是把每个扩展编译成一个单独的&lt;code&gt;.so&lt;/code&gt;文件，然后在&lt;code&gt;php.ini&lt;/code&gt;中加上&lt;code&gt;extension=hylog.so&lt;/code&gt;，如果有配置就再加上一些配置。CLI的话就直接生效了，FPM环境下就要重启一下FPM了。我们这里只讨论CLI模式。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;第三方扩展安装的一般流程&lt;/p&gt;

&lt;p&gt;还记得我刚刚提到的执行某些命令后会生成很多文件吗？就是这里了。如果你还没有用&lt;code&gt;git&lt;/code&gt;，我劝你现在用了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;➜  hylog git:(master) phpize
Configuring for:
PHP Api Version:         20151012
Zend Module Api No:      20151012
Zend Extension Api No:   320151012
➜  hylog git:(master) ✗ ./configure
➜  hylog git:(master) ✗ make
➜  hylog git:(master) ✗ sudo make install
Installing shared extensions:     /usr/local/lib/php/extensions/no-debug-non-zts-20151012/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;好，到这里已经看到在独立编译动态扩展时，生成的&lt;code&gt;.so&lt;/code&gt;文件是放在了这个目录下的。这时动态的好处就体现出来了。文件有了，至于你想不想用，只需要修改&lt;code&gt;php.ini&lt;/code&gt;即可，不用任何重新编译。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;安装和卸载扩展&lt;/p&gt;

&lt;p&gt;前面说了，如果需要该扩展，编辑&lt;code&gt;/usr/local/lib/php.ini&lt;/code&gt;，在最下面添加（安装）或删除（卸载）一行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-ini&#34;&gt;extension=hylog.so
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;调试&lt;/p&gt;

&lt;p&gt;我可不敢保证代码一次就能成功，调试的时候要多次执行以上三个命令，所以可以创建一个&lt;code&gt;rebuild.sh&lt;/code&gt;脚本，运行脚本重新编译并安装最新的版本。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./configure
make
sudo make install
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最好把它加入到&lt;code&gt;git&lt;/code&gt;工作目录中。&lt;/p&gt;

&lt;p&gt;扩展的安装就这些，下一节介绍PHP变量的基本类型。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PHP扩展实战——用PHP实现类的原型</title>
      <link>http://lovelock.coding.me/php/internals/class-prototype-in-php/</link>
      <pubDate>Sat, 09 Apr 2016 21:55:00 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/php/internals/class-prototype-in-php/</guid>
      <description>&lt;p&gt;在编写之前先用PHP实现这个类的原型吧。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;&amp;lt;?php

namespace Hylog;

use \DateTime;

class Hylog
{
    const HYLOG_VERSION = &amp;quot;0.1.0&amp;quot;;

    const EMERGENCY = &#39;EMERGENCY&#39;;
    const ALERT     = &#39;ALERT&#39;;
    const CRITICAL  = &#39;CRITICAL&#39;;
    const ERROR     = &#39;ERROR&#39;;
    const WARNING   = &#39;WARNING&#39;;
    const NOTICE    = &#39;NOTICE&#39;;
    const INFO      = &#39;INFO&#39;;
    const DEBUG     = &#39;DEBUG&#39;;

    private static $_instance;

    private $_basePath;
    private $_sliceLogByHour;

    public function log($level, $message, $context = array())
    {
        $line = $this-&amp;gt;interpolate($message, $context);

        $datetime         = new DateTime();
        $timestamp        = $datetime-&amp;gt;getTimestamp();
        $formatedDatetime = $datetime-&amp;gt;format(DateTime::ATOM);

        $line = $timestamp . &amp;quot;\t|\t&amp;quot; . $formatedDatetime . &amp;quot;\t|\t&amp;quot; . $line;

        $this-&amp;gt;output($level, $line);
    }

    public function emergency($message, $context = array())
    {
        $this-&amp;gt;log(self::EMERGENCY, $message, $context);
    }

    public function alert($message, $context = array())
    {
        $this-&amp;gt;log(self::ALERT, $message, $context);
    }

    public function critical($message, $context = array())
    {
        $this-&amp;gt;log(self::CRITICAL, $message, $context);
    }

    public function error($message, $context = array())
    {
        $this-&amp;gt;log(self::ERROR, $message, $context);
    }

    public function warning($message, $context = array())
    {
        $this-&amp;gt;log(self::WARING, $message, $context);
    }

    public function notice($message, $context = array())
    {
        $this-&amp;gt;log(self::NOTICE, $message, $context);
    }

    public function info($message, $context = array())
    {
        $this-&amp;gt;log(self::INFO, $message, $context);
    }

    public function debug($message, $context = array())
    {
        $this-&amp;gt;log(self::DEBUG, $message, $context);
    }

    public static function getInstance() : object
    {
        if (!isset(self::$_instance)) {
            self::$_instance = new static();
        }

        return self::$_instance;
    }

    public function getVersion()
    {
        return self::HYLOG_VERSION;
    }

    public function setBasePath($path)
    {
        $this-&amp;gt;_basePath = $path;
    }

    public function getBasePath() : string
    {
        return $this-&amp;gt;_basePath;
    }

    public function setSliceByHour($bool)
    {
        $this-&amp;gt;_sliceLogByHour = $bool;
    }

    public function getSliceByHour() : bool
    {
        return $this-&amp;gt;_sliceLogByHour;
    }

    private function output($level, $message)
    {
        $logFile = $this-&amp;gt;getLogFile($level);

        error_log($message . PHP_EOL, 3, $logFile);
    }

    private function getLogFile($level) : string
    {
        $cHour = date(&#39;ymdH&#39;);
        $cDay  = date(&#39;ymd&#39;);

        if ($this-&amp;gt;_sliceLogByHour) {
            return $this-&amp;gt;_basePath . &#39;/&#39; . $level . &#39;.&#39; . $cHour . &#39;.log&#39;;
        } else {
            return $this-&amp;gt;_basePath . &#39;/&#39; . $level . &#39;.&#39; . $cDay . &#39;.log&#39;;
        }
    }

    private function interpolate($message, $context = array())
    {
        foreach ($context as $key =&amp;gt; $val) {
            $replace[&#39;{&#39; . $key . &#39;}&#39;] = $val;
        }

        return strtr($message, $replace);
    }

    private function __construct()
    {
        $this-&amp;gt;_basePath = &#39;/tmp/log&#39;;

        if (!is_dir($this-&amp;gt;_basePath)) {
            mkdir($this-&amp;gt;_basePath, 0700, true);
        } else {
            chmod($this-&amp;gt;_basePath, 0700);
        }

        $this-&amp;gt;_sliceLogByHour = true;
    }

    private function __clone()
    {
    }

    private function __wakeup()
    {
    }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>PHP扩展实战——目标和计划</title>
      <link>http://lovelock.coding.me/php/internals/schedules/</link>
      <pubDate>Sat, 09 Apr 2016 21:13:28 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/php/internals/schedules/</guid>
      <description>

&lt;p&gt;好了，现在来整理一下我们要做的工作。&lt;/p&gt;

&lt;h2 id=&#34;功能目标&#34;&gt;功能目标&lt;/h2&gt;

&lt;p&gt;既然是要做一个记日志的扩展，那当然就避免不了两个功能：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;格式化日志流&lt;/li&gt;
&lt;li&gt;将日志流推送到特定目标（通常是写入文件）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这两个是最核心的功能，其他的都是辅助。但辅助也可以很贴心，所以我设计了以下功能：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;尽可能多的从扩展层面获取共用的信息，比如时间、客户端IP、当前机器的IP等（这里涉及&lt;strong&gt;超全局变量&lt;/strong&gt;的获取）&lt;/li&gt;
&lt;li&gt;设计尽量简单的默认规则，既可以开箱即用，又可以随心配置&lt;/li&gt;
&lt;li&gt;遵守&lt;a href=&#34;http://www.php-fig.org/psr/psr-3/&#34;&gt;PSR-3&lt;/a&gt;规范&lt;/li&gt;
&lt;li&gt;命名空间和传统写法的兼容(鸟哥的Yaf是教科书）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;还有一个需要考虑的问题是高并发场景下的文件写入丢失问题，我觉得以我目前的水平是无法解决这个问题的，那没关系，PHP内置的已经有强大的&lt;code&gt;error_log&lt;/code&gt;方法了，它可以保证这点，用它就可以。喂等等，那既然已经有了&lt;code&gt;error_log&lt;/code&gt;，我干嘛还要做这个呢？&lt;/p&gt;

&lt;p&gt;因为它不够灵活。&lt;/p&gt;

&lt;p&gt;我们通常的做法是封装&lt;code&gt;error_log&lt;/code&gt;方法，填充默认参数、格式化、写入文件等，&lt;code&gt;error_log&lt;/code&gt;方法本身是很快的，但挡不住我们添加的这些代码的消耗也很大，因为写日志是个非常频繁的操作，所以一个极小的性能损失积累下来都可能影响很大。&lt;/p&gt;

&lt;h2 id=&#34;取名&#34;&gt;取名&lt;/h2&gt;

&lt;p&gt;既然用C写，那就是奔着高性能去的，High Performance PHP Log，叫Hilog貌似就可以，但为了致敬鸟哥，把i换成y好了：）所以叫Hylog。&lt;/p&gt;

&lt;h2 id=&#34;类的设计&#34;&gt;类的设计&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;拥有PRS-3规定的8个level作为常量&lt;/li&gt;
&lt;li&gt;对应8个方法，分别写到不同的文件&lt;/li&gt;
&lt;li&gt;一个log方法比上述8个方法多个level参数，上述8个函数实际是调用这个方法记日志的&lt;/li&gt;
&lt;li&gt;格式化日志的方法&lt;/li&gt;
&lt;li&gt;数组插值的方法&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;依赖关系&#34;&gt;依赖关系&lt;/h2&gt;

&lt;p&gt;依赖PHP内置函数&lt;code&gt;error_log&lt;/code&gt;。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用PHP生成器和迭代器</title>
      <link>http://lovelock.coding.me/php/php-generator-and-iterator/</link>
      <pubDate>Tue, 05 Apr 2016 12:05:46 +0800</pubDate>
      <author>frostwong@gmail.com (Frost Wong)</author>
      <guid>http://lovelock.coding.me/php/php-generator-and-iterator/</guid>
      <description>

&lt;p&gt;从开始写PHP就知道迭代器这个东西，当时师傅告诉我用的挺少的，需要的时候再看也不晚，于是就没有放在意上。但他还说这其实也是区分高手和菜鸟的一个标志，那我还是研究一下好了：）&lt;/p&gt;

&lt;p&gt;PHP程序员都知道我们最经常用的可能就是&lt;code&gt;foreach&lt;/code&gt;这个大杀器了。得益于我们&lt;strong&gt;万能的数组&lt;/strong&gt;，所以这个大杀器在多数场合都是可以直接用的，只要输入元素是数组类型即可——事实上并不是如此，&lt;code&gt;foreach&lt;/code&gt;能遍历数组并不是因为它是数组，而是因为数组&lt;code&gt;implements&lt;/code&gt;了&lt;code&gt;Iterator&lt;/code&gt;接口。说白了就是只要告诉&lt;code&gt;foreach&lt;/code&gt;遍历的规则，它就可以执行遍历，而和是否数组无关。&lt;/p&gt;

&lt;h3 id=&#34;iterator&#34;&gt;Iterator&lt;/h3&gt;

&lt;h4 id=&#34;解析&#34;&gt;解析&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;Iterator&lt;/code&gt;接口定义了5个方法，如果一个类要实现&lt;code&gt;Iterator&lt;/code&gt;接口，当然就要实现这一套方法了。&lt;code&gt;Iterator&lt;/code&gt;的原型如下&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;Interface Iterator
{
	abstract public function current() : mixed;
	abstract public function key() : scalar;
	abstract public function next() : void;
	abstract public function rewind() : void;
	abstract public function valid() : boolean;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;我在方法后面按照PHP7的新语法加了个返回值类型，其实这样写是不对的，但可以表明意思啦：）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;详细说一下这几个方法要做的事情。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;current()&lt;/p&gt;

&lt;p&gt;返回当前位置的&lt;strong&gt;值&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;key()&lt;/p&gt;

&lt;p&gt;返回当前位置的&lt;strong&gt;键&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;next()&lt;/p&gt;

&lt;p&gt;当前位置的&lt;strong&gt;键&lt;/strong&gt;加1。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;rewind()&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;键&lt;/strong&gt;回到第一个位置。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;valid()&lt;/p&gt;

&lt;p&gt;返回当前的&lt;strong&gt;键&lt;/strong&gt;是否是有意义的。如是否是&lt;code&gt;false&lt;/code&gt;/&lt;code&gt;NULL&lt;/code&gt;等。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;实例&#34;&gt;实例&lt;/h4&gt;

&lt;p&gt;还是来具体写个例子理解一下吧。通常写这种例子的作者都会举一个类，它的一个属性是个数组，然后实现&lt;code&gt;Iterator&lt;/code&gt;的5个方法，来让这个类可以使用&lt;code&gt;foreach&lt;/code&gt;，这个例子没意思，因为数组本身就带&lt;code&gt;current&lt;/code&gt;、&lt;code&gt;key&lt;/code&gt;这些方法。让我来举一个&lt;code&gt;pdo_mysql&lt;/code&gt;从数据库中取数据的例子吧。&lt;/p&gt;

&lt;p&gt;从数据库取出一一个数组，数组中的元素是&lt;code&gt;User&lt;/code&gt;类的实例，我们需要&lt;code&gt;Users&lt;/code&gt;类的方法，它又要有一些方法。所以，就产生了这样的用法了。这个例子可能有些牵强，但起码描述了一个使用场景，比单纯的迭代一个类的类型为数组的属性要有意义。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://git.coding.net/lovelock/iterator_example.git&#34;&gt;代码地址&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;generator&#34;&gt;Generator&lt;/h3&gt;

&lt;p&gt;只有真正理解了&lt;code&gt;Iterator&lt;/code&gt;才能再来谈&lt;code&gt;Generator&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;还是举例来说，前面已经说了一个比较复杂的例子，这里为了说明二者的区别，举个简单的例子。&lt;/p&gt;

&lt;p&gt;假定有一个日志文件，1000000行吧，很大了？或许吧。现在我们要遍历这个文件，找到我们需要的东西。如果使用&lt;code&gt;Iterator&lt;/code&gt;，可能需要这样&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;&amp;lt;?php

class LinesIterator implements Iterator
{
	private $_fp;
	private $_currentLine;
	private $_lineNum;

	public function __construct($filename)
	{
		$this-&amp;gt;_fp = fopen($filename, &#39;r&#39;);
		$this-&amp;gt;_lineNum = 0;
	}

	public function current()
	{
		$this-&amp;gt;_currentLine = fgets($this-&amp;gt;_fp);
		return $this-&amp;gt;_currentLine;
	}

	public function key()
	{
		return $this-&amp;gt;_lineNum;
	}

	public function valid()
	{
		return $this-&amp;gt;_currentLine === false;
	}

	public function next()
	{
		fgets($this-&amp;gt;_fp);
		$this-&amp;gt;_lineNum++;
	}

	public function rewind()
	{
	}

	public function __destruct()
	{
		fclose($this-&amp;gt;_fp);
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要遍历文件时，可以这样&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;$file = new LinesIterator(&#39;file&#39;);

foreach ($file-&amp;gt;current() as $line) {
	echo $line;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这没有问题，但也太复杂了吧！！！重点是即使我实现了这些，但还是无法随便定位到某一行（这需要&lt;code&gt;fseek&lt;/code&gt;）。所以这种场景下，&lt;code&gt;Generator&lt;/code&gt;出现了。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;function getLine($fileName)
{
	$fp = fopen($fileName, &#39;r&#39;);	

	while ($line = fgets($fp) !== false) {
		yield $line;
	}

	fclose($fp);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就简明多了。&lt;code&gt;Generator&lt;/code&gt;的标志就是&lt;code&gt;yield&lt;/code&gt;，这点在所有编程语言里都一样。&lt;/p&gt;

&lt;p&gt;正常如果在用&lt;code&gt;yield&lt;/code&gt;的地方用了&lt;code&gt;return&lt;/code&gt;，那么代码执行到这里就结束了，下次再执行这个函数时，还是从头开始，我们永远得不到文件的第二行。那么怎么办呢？我的理解是&lt;code&gt;Generator&lt;/code&gt;把这行内容返回的同时，也把文件句柄所在的指针向后移动了一个单位，下次再次执行该函数时，就会从上次的位置继续执行。&lt;/p&gt;

&lt;p&gt;这个函数的功能和上面那个类的效果完全相同。&lt;/p&gt;

&lt;p&gt;还有一点要提一下，&lt;code&gt;Generator&lt;/code&gt;通常用来处理文件特别大的情况，比如上面这样，文件太大，如果直接用&lt;code&gt;file&lt;/code&gt;读进来保存成为一个数组，很可能就会报错。而如果用&lt;code&gt;Generator&lt;/code&gt;就没有这个问题了。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
