<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Me &amp; Web on Me &amp; Web</title>
    <link>http://lovelock.coding.me/index.xml</link>
    <description>Recent content in Me &amp; Web on Me &amp; Web</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>(c) 2013-2016 Frost Wong. All rights reserved.</copyright>
    <lastBuildDate>Tue, 28 Feb 2017 14:59:40 +0800</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Slim 获取Postman发送的PUT请求的body</title>
      <link>http://lovelock.coding.me/http/slim-put-with-postman/</link>
      <pubDate>Tue, 28 Feb 2017 14:59:40 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/http/slim-put-with-postman/</guid>
      <description>&lt;p&gt;刚才用Postman测试一个接口发现用&lt;strong&gt;form-data&lt;/strong&gt;格式发送PUT请求给Slim应用时，在应用中用&lt;code&gt;$request-&amp;gt;getParsedBody()&lt;/code&gt;获取不到请求的body，搜索到了&lt;a href=&#34;StackOverFlow页面&#34;&gt;http://stackoverflow.com/questions/23761425/get-put-params-with-slim-php&lt;/a&gt;，  简单说就是一般&lt;code&gt;form-data&lt;/code&gt;格式用来上传文件，而一般情况下应该用&lt;code&gt;x-www-form-urlencoded&lt;/code&gt;，改一下这里的发送body的格式就可以了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>排序算法 &lt;一&gt;</title>
      <link>http://lovelock.coding.me/algo/sorting-algorithms/</link>
      <pubDate>Mon, 13 Feb 2017 15:21:01 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/algo/sorting-algorithms/</guid>
      <description>

&lt;p&gt;就让我再啃一下一直以来最头疼的问题吧。&lt;/p&gt;

&lt;h2 id=&#34;冒泡排序-bubble-sorting&#34;&gt;冒泡排序(bubble sorting)&lt;/h2&gt;

&lt;p&gt;刚才突然想通了，之前竟然不知道为什么大家都说冒泡是最简单的。。。难道是我智商不够了么&lt;/p&gt;

&lt;p&gt;假设有这样一组数字$a = [2, 3, 8, 1, 5, 7]$。要对它进行排序，按照冒泡排序的做法最终是要这样做：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;设数组的索引是$i$，如果$a[i] &amp;gt; a[i+1]$，那么就让二者交换位置&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;紧接着让$a[i+1]$和$a[i+2]$做比较，要知道这时$a[i+1]$已经是$a[i]$和$a[i+1]$中较大的了，按照前面的做法把二者中较大的放在后面&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;这样做一轮最大的数字就会在新数组最后了&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;但前面5位的位置依然是乱序的，要按前面3步的规则重新排一遍。因为最后一位已经是最大无疑，就不需要参与排序了&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;第一轮排序得到一个最大的，第二轮得到第二大，当第二小的确定以后，第一小的也随之确定，所以一共需要做$n-1$轮排序&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;​&lt;/p&gt;

&lt;p&gt;原理清楚了，用代码把它描述出来就是这样了（为了突出一个逼格，一定要用C啊）：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;   #include &amp;lt;stdio.h&amp;gt;

   void swap(int a[], int i, int j)
   {
       int tmp = a[i];
       a[i] = a[j];
       a[j] = tmp;
   }

   void bubble_sort(int a[], int len)
   {
       for (int j = 0; j &amp;lt; len - 1; j++) {
           for (int i = 0; i &amp;lt; len - 1 - j; i++) {
               if (a[i] &amp;gt; a[i+1]) {
                   swap(a, i, i+1);
               }
           }
       }
   }

   int main()
   {
       int a[] = {2, 3, 8, 1, 5, 7};
       int n = sizeof(a) / sizeof(int);
       int i;

       puts(&amp;quot;原始数组: &amp;quot;);
       for (i = 0; i &amp;lt; n; i++) {
           printf(&amp;quot;%d\t&amp;quot;, a[i]);
       }
       puts(&amp;quot;&amp;quot;);
       printf(&amp;quot;数组长度: %d\t&amp;quot;, n);

       bubble_sort(a, n);

       puts(&amp;quot;排序后数组: &amp;quot;);
       for (i = 0; i &amp;lt; n; i++) {
           printf(&amp;quot;%d\t&amp;quot;, a[i]);
       }
       puts(&amp;quot;&amp;quot;);

       return 0;
   }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;​&lt;/p&gt;

&lt;p&gt;为了让自己不忘记最核心的代码，这里详细的描述一下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;最外层循环是说要进行&lt;code&gt;n-1&lt;/code&gt;轮排序才能完成&lt;/li&gt;
&lt;li&gt;内层循环是说外层循环每进行一轮，需要进行比较的数字就会少一组，也就是前面提到的，最大值已经确定了，后面的排序它就不需要参与了&lt;/li&gt;
&lt;li&gt;然后就是最简单的交换顺序了&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这样理解下来，冒泡排序果然是最简单的了。&lt;/p&gt;

&lt;p&gt;再呈上PHP版本：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;   &amp;lt;?php

   function swap(array $a, $i, $j)
   {
       $tmp = $a[$i];
       $a[$i] = $a[$j];
       $a[$j] = $tmp;

       return $a;
   }

   function bubbleSort(array $a, $n)
   {
       for ($i = 0; $i &amp;lt; $n; $i++) {
           for ($j = 0; $j &amp;lt; $n - 1 - $i; $j++) {
               if ($a[$j] &amp;gt; $a[$j+1]) {
                   $a = swap($a, $j, $j+1);
               }
           }
       }

       return $a;
   }

   $arr = [2, 3, 8, 1, 5, 7];
   $b = bubbleSort($arr, 6);
   var_export($b);

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最近新学了golang，顺道也写一遍：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;   package main

   import &amp;quot;fmt&amp;quot;

   func swap(a []int, i int, j int) {
   	tmp := a[i]
   	a[i] = a[j]
   	a[j] = tmp
   }

   func bubbleSort(a []int, n int) {
   	for i := 0; i &amp;lt; n-1; i++ {
   		for j := 0; j &amp;lt; n-1-i; j++ {
   			if a[j] &amp;gt; a[j+1] {
   				swap(a, j, j+1)
   			}
   		}
   	}
   }

   func main() {
   	a := []int{2, 3, 8, 1, 5, 7}
   	bubbleSort(a, 6)
   	fmt.Println(a)
   }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;鸡尾酒排序-cocktail-sorting&#34;&gt;鸡尾酒排序(cocktail sorting)&lt;/h2&gt;

&lt;p&gt;鸡尾酒排序是冒泡排序的一种改进。前面说了，冒泡排序每轮排序仅仅选出其中最大的，而鸡尾酒排序则是在选出最大的以后，把最小的也选出来放在最前面。冒泡排序的时间复杂度是$(O(n^2)$，这样看起来鸡尾酒排序的时间复杂度应该是$O(\frac{n^2}{2})$，但没有那么记复杂度的，它和冒泡排序的时间复杂度是同一个数量级，但当需要排序的数字比较少时，通常鸡尾酒排序能获得更好的性能。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;

void swap(int a[], int i, int j)
{
    int tmp = a[i];
    a[i] = a[j];
    a[j] = tmp;
}

void cocktailSort(int a[], int n)
{
    int left = 0;
    int right = n - 1;
    while (left &amp;lt; right) {
        for (int i = left; i &amp;lt; right; i++) {
            if (a[i] &amp;gt; a[i+1]) {
                swap(a, i, i+1);
            }
        }
        right--;

        for (int i = right; i &amp;gt; left; i--) {
            if (a[i-1] &amp;gt; a[i]) {
                swap(a, i-1, i);
            }
        }
        left++;
    }
}

int main()
{
    int a[] = {2, 3, 8, 1, 5, 7};
    int n = sizeof(a) / sizeof(int);
    int i;

    puts(&amp;quot;原始数组: &amp;quot;);
    for (i = 0; i &amp;lt; n; i++) {
        printf(&amp;quot;%d\t&amp;quot;, a[i]);
    }
    puts(&amp;quot;&amp;quot;);
    printf(&amp;quot;数组长度: %d\n&amp;quot;, n);

    cocktailSort(a, n);

    puts(&amp;quot;排序后数组: &amp;quot;);
    for (i = 0; i &amp;lt; n; i++) {
        printf(&amp;quot;%d\t&amp;quot;, a[i]);
    }
    puts(&amp;quot;&amp;quot;);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;老规矩，PHP版本&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;&amp;lt;?php

function swap(array $a, $i, $j)
{
    $tmp = $a[$i];
    $a[$i] = $a[$j];
    $a[$j] = $tmp;

    return $a;
}

function cocktailSort(array $a, $len)
{
    $left = 0;
    $right = $len - 1;

    while ($left &amp;lt; $right) {
        for ($i = $left; $i &amp;lt; $right; $i++) {
            if ($a[$i] &amp;gt; $a[$i+1]) {
                $a = swap($a, $i, $i+1);
            }
        }
        $right--;

        for ($i = $right; $i &amp;gt; $left; $i--) {
            if ($a[$i-1] &amp;gt; $a[$i]) {
                $a = swap($a, $i-1, $i);
            }
        }
        $left++;
    }

    return $a;
}


$arr = [2, 3, 8, 1, 5, 7];

$b = cocktailSort($arr, 6);
var_export($b);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;golang版本：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import &amp;quot;fmt&amp;quot;

func swap(a []int, i int, j int) {
	tmp := a[i]
	a[i] = a[j]
	a[j] = tmp
}

func cocktailSort(a []int, len int) {
	left := 0
	right := len - 1

	for left &amp;lt; right {
		for i := left; i &amp;lt; right; i++ {
			if a[i] &amp;gt; a[i+1] {
				swap(a, i, i+1)
			}
		}
		right--

		for i := right; i &amp;gt; left; i-- {
			if a[i-1] &amp;gt; a[i] {
				swap(a, i-1, i)
			}
		}
		left++
	}
}

func main() {
	arr := []int{2, 3, 8, 1, 5, 7}
	cocktailSort(arr, 6)
	fmt.Println(arr)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;选择排序-selection-sorting&#34;&gt;选择排序（selection sorting)&lt;/h2&gt;

&lt;p&gt;这个现在看起来好像也很直观了（下面我按大家通常说的『趟』来替代前面说的『轮』）。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;每趟找出一个最小的放在最前面&lt;/li&gt;
&lt;li&gt;如果有$n$个数，就要排$n-1$趟&lt;/li&gt;
&lt;li&gt;对于每趟排序而言，设置一个flag $min$，用它标识该趟排序最小数的下标，第$i$趟排序开始时，前第$i-1$个数已经确定了，所以把$min = i$，后面把第$min$位数和它后面的所有数字比较，如果$a[min] &amp;gt; a[min+1]$就把$min$设置为$min+1$&lt;/li&gt;
&lt;li&gt;这一步最为关键，第3步找到了这趟排序的最小数，这步就要把放在第$i$位了，那原来第$i$位的数就当然和它交换位置了&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;不多说，直接上代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;

void swap(int a[], int i, int j)
{
    int tmp = a[i];
    a[i] = a[j];
    a[j] = tmp;
}

void selection_sort(int a[], int n)
{
    int min, i, j;

    for (i = 0; i &amp;lt; n - 1; i++) { // 0 -&amp;gt; (n-2) 一共(n-1)趟
        min = i;
        for (j = min + 1; j &amp;lt; n; j++) {
            if (a[min] &amp;gt; a[j]) {
                min = j;
            }
        }
        if (min != i) {
            swap(a, min, i);
        }
    }
}

int main()
{
    int a[] = {2, 3, 8, 1, 5, 7};
    int n = sizeof(a) / sizeof(int);
    int i;

    puts(&amp;quot;原始数组: &amp;quot;);
    for (i = 0; i &amp;lt; n; i++) {
        printf(&amp;quot;%d\t&amp;quot;, a[i]);
    }
    puts(&amp;quot;&amp;quot;);
    printf(&amp;quot;数组长度: %d\t&amp;quot;, n);

    selection_sort(a, n);

    puts(&amp;quot;排序后数组: &amp;quot;);
    for (i = 0; i &amp;lt; n; i++) {
        printf(&amp;quot;%d\t&amp;quot;, a[i]);
    }
    puts(&amp;quot;&amp;quot;);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;PHP和golang版本的这里就不贴了，写完这篇文章单独搞一个github的repo来存放。&lt;/p&gt;

&lt;h2 id=&#34;插入排序-insertion-sorting&#34;&gt;插入排序(insertion sorting)&lt;/h2&gt;

&lt;p&gt;这个就像玩扑克抓牌一样，以下是步骤：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;抓出一张牌，放在左手&lt;/li&gt;
&lt;li&gt;再抓出一张牌，从老牌的第一张开始扫描，如果新牌小于老牌，老牌往后移动一位，新牌替换老牌的位置&lt;/li&gt;
&lt;li&gt;在上面的扫描过程中，如果新牌大于老牌，则把新牌放在老牌下一位&lt;/li&gt;
&lt;li&gt;重复以上步骤&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;来看代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;

void insertion_sort(int a[], int n)
{
    int i, j, get;

    for (i = 1; i &amp;lt; n; i++) {
        get = a[i];
        j = i - 1;
        while (j &amp;gt;= 0 &amp;amp;&amp;amp; get &amp;lt; a[j]) {
            if (get &amp;lt; a[j]) {
                a[j+1] = a[j];
                j--;
            }
        }
        a[j+1] = get;
    }
}

int main()
{
    int a[] = {2, 3, 8, 1, 5, 7};
    int n = sizeof(a) / sizeof(int);
    int i;

    puts(&amp;quot;原始数组: &amp;quot;);
    for (i = 0; i &amp;lt; n; i++) {
        printf(&amp;quot;%d\t&amp;quot;, a[i]);
    }
    puts(&amp;quot;&amp;quot;);
    printf(&amp;quot;数组长度: %d\t&amp;quot;, n);

    insertion_sort(a, n);

    puts(&amp;quot;排序后数组: &amp;quot;);
    for (i = 0; i &amp;lt; n; i++) {
        printf(&amp;quot;%d\t&amp;quot;, a[i]);
    }
    puts(&amp;quot;&amp;quot;);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个排序貌似比较难理解一些，我再详细的解释一下。&lt;/p&gt;

&lt;p&gt;还是把这种排序类比成抓扑克牌。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;假设手里有一把牌($n$张），我们一般不会去移动第一张牌吧，所以从第二张牌开始，后面的每一张都需要被抓一下，所以外层循环是$n-1$。&lt;/li&gt;
&lt;li&gt;第一次以第一张作为基准，取第二张牌，所以内层循环从1开始而不是0。&lt;/li&gt;
&lt;li&gt;$get$这个变量是为了暂存取出牌的值&lt;/li&gt;
&lt;li&gt;有一个很重要的前提&lt;strong&gt;位于新取出的位置之前的所有牌都是已经排好序的&lt;/strong&gt;。所以我们拿新牌去和前面所有已经排序的牌做比较。假设$get = a[i]$，那么如果$a[i-1] &amp;gt; a[i]$，就需要让$a[i-1]$向后移动一位，也就是$a[i] = a[i-1]$，这就是需要$get$这个变量来暂存$a[i]$的原因了。如果前面若干位都大于$get$，那就一直移动到不大于它的为止。这时就会出现一个空缺，这个空缺就需要$get$来填充了&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;看看前面的代码是不是完美的诠释了这个过程？&lt;/p&gt;

&lt;h2 id=&#34;二分插入排序&#34;&gt;二分插入排序&lt;/h2&gt;

&lt;p&gt;二分插入排序本质上和（直接）插入排序是一样的，只是在寻找$a[i]$时采用了二分查找法，二分查找发具体算法如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;给定的已排序的序列$b$，长度为$n$，$left$和$right$分别是它的起点和终点，即$left=0;right=n-1$，中间位置$mid=\frac{left+right}{2}$,给定的值$k$。&lt;/li&gt;
&lt;li&gt;首先拿序列$b$的中间值和$k$做比较，有以下两种情况:

&lt;ul&gt;
&lt;li&gt;$k &amp;gt; b[mid]$，则$k$的下标位于$b$的后半部分，$left = mid + 1$&lt;/li&gt;
&lt;li&gt;$k &amp;lt; b[mid]$，则$k$的下标位于$b$的前半部分，$right = mid - 1$&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;如果$left &amp;gt; right$，则查找失败&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在我们插值的场景中当然是查找失败的，但这却是退出whilex循环的条件，也就是在while循环退出时,$left = right + 1$，而$b[left]$是第一个大于$k$的数。这时就要把$[left, i-1]$位置的所有元素都向后移动一位，然后把$a[left] = k$。好了，这样整个算法就很清晰了。上C代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;

void binary_sort(int a[], int n)
{
    int i, j, right, left, get;

    for (i = 1; i &amp;lt; n; i++) {
        left = 0;
        right = i - 1;
        get = a[i];

        while (left &amp;lt;= right) {
            int mid = (left + right) / 2;
            if (a[mid] &amp;gt; get) {
                right = mid - 1;
            } else {
                left = mid + 1;
            }
        }

        for (j = i - 1; j &amp;gt;= left; j--) {
            a[j+1] = a[j];
        }

        a[left] = get;
    }
}

int main()
{
    int a[] = {2, 3, 8, 1, 5, 7};
    int n = sizeof(a) / sizeof(int);
    int i;

    puts(&amp;quot;原始数组: &amp;quot;);
    for (i = 0; i &amp;lt; n; i++) {
        printf(&amp;quot;%d\t&amp;quot;, a[i]);
    }
    puts(&amp;quot;&amp;quot;);
    printf(&amp;quot;数组长度: %d\t&amp;quot;, n);

    binary_sort(a, n);

    puts(&amp;quot;排序后数组: &amp;quot;);
    for (i = 0; i &amp;lt; n; i++) {
        printf(&amp;quot;%d\t&amp;quot;, a[i]);
    }
    puts(&amp;quot;&amp;quot;);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;有了前面铺垫的描述，这代码写下来就是顺理成章啊。&lt;/p&gt;

&lt;h2 id=&#34;希尔排序-shell-sorting&#34;&gt;希尔排序（shell sorting)&lt;/h2&gt;

&lt;p&gt;上面都是很直观的排序方法，下面介绍的几种就没那么直观了。首先是希尔排序。&lt;/p&gt;

&lt;p&gt;希尔排序本质上还是插入排序的一种推广，它基于以下两条事实：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;插入排序在对&lt;strong&gt;几乎已经排好序的数据&lt;/strong&gt;操作时，效率高，即可以达到&lt;strong&gt;线性排序&lt;/strong&gt;的效率&lt;/li&gt;
&lt;li&gt;但插入排序一般来说是低效的，因为插入排序&lt;strong&gt;每次只能将数据移动一位&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;既然知道了插入排序的强项和弱项，就能更好的应用它以提升排序效率了。首先就是要将一个无序的数据构造成&lt;strong&gt;更有序&lt;/strong&gt;的状态，也就是前面说的&lt;strong&gt;几乎已经排好序的数据&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;首先把$n$个数分成$2$队，两队中各有$m$个元素。每个元素在本队中的位置和别的队中同样位置的元素构成一组。这样会产生类似$[A_1, B_1], [A_2, B_2],[A_3, B_3], [A_4, B_4]$这样的数据。然后把每组中的两个数据分别排序，按照&lt;strong&gt;递归&lt;/strong&gt;的分组策略继续重新分组，把每组中的数据分别排序，最终间隔越来越小，变成1时也就完成了排序。&lt;/p&gt;

&lt;p&gt;至于分组策略，一般的实现是从$m = n / 2$开始，持续$m = m / 2$最终$m=1$了。&lt;/p&gt;

&lt;p&gt;然后每个组排序，也就有$m$个组。&lt;/p&gt;

&lt;p&gt;每组中，按间隔为$m$做插入排序。&lt;/p&gt;

&lt;p&gt;不断迭代到$m=1$就完成了排序。&lt;/p&gt;

&lt;p&gt;下面是C代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;

void shell_sort(int a[], int n)
{
    int m, i, j;

    for (m = n / 2; m &amp;gt; 0; m /= 2) {
        printf(&amp;quot;m: %d\n&amp;quot;, m);

        for (i = 0; i &amp;lt; m; i++) {
            for (j = i + m; j &amp;lt; n; j += m) {
                if (a[j] &amp;lt; a[j-m]) {
                    int get = a[j];
                    int k = j - m;
                    while (k &amp;gt;= 0 &amp;amp;&amp;amp; a[k] &amp;gt; get) {
                        a[k+m] = a[k];
                        k -= m;
                    }
                    a[k+m] = get;
                }
            }
        }
    }
}

int main()
{
    int a[] = {2, 3, 8, 1, 5, 7};
    int n = sizeof(a) / sizeof(int);
    int i;

    puts(&amp;quot;原始数组: &amp;quot;);
    for (i = 0; i &amp;lt; n; i++) {
        printf(&amp;quot;%d\t&amp;quot;, a[i]);
    }
    puts(&amp;quot;&amp;quot;);
    printf(&amp;quot;数组长度: %d\t&amp;quot;, n);

    shell_sort(a, n);

    puts(&amp;quot;排序后数组: &amp;quot;);
    for (i = 0; i &amp;lt; n; i++) {
        printf(&amp;quot;%d\t&amp;quot;, a[i]);
    }
    puts(&amp;quot;&amp;quot;);

    return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个虽然说了很明白，但总还是不太好理解，如果能把直接插入排序理解成$m=1$的希尔排序的特殊情况就好理解一些了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Nginx负载均衡分配策略详解</title>
      <link>http://lovelock.coding.me/linux/config-of-nginx-load-balancing/</link>
      <pubDate>Thu, 09 Feb 2017 18:00:47 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/linux/config-of-nginx-load-balancing/</guid>
      <description>

&lt;p&gt;上篇文章配置的负载均衡是『轮询模式』，所以两台后端机器分到的请求数总是一样的。这里就其他分配策略做个详解。&lt;/p&gt;

&lt;h2 id=&#34;分配策略&#34;&gt;分配策略&lt;/h2&gt;

&lt;h3 id=&#34;1-weight&#34;&gt;1. &lt;code&gt;weight&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://ww1.sinaimg.cn/large/006tKfTcly1fcl7d8xu4fj30d503aaa9.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;把前面的配置改成这样，意思是8086端口的这个server被hit的几率会是8085的2倍，实际测试结果如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ww1.sinaimg.cn/large/006tKfTcly1fcl7ee0sglj308802sjrf.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;因为这里面包含前面没有配置weight的数据，所以不太准确，但能说明问题。&lt;/p&gt;

&lt;h3 id=&#34;2-ip-hash&#34;&gt;2. &lt;code&gt;ip_hash&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;这个的作用是把用户的IP映射到固定的一台后端服务器上，可以解决session的问题。这个看起来很不错，但还是无法解决灰度测试的问题。我理解的灰度测试最好是针对一批用户，因为你不能让用户在移动App已经购买的东西到了Web登录后发现没有了吧。所以最好还是根据用户的ID进行Hash。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ww4.sinaimg.cn/large/006tKfTcly1fcld8wy07zj30e10460sw.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-least-conn&#34;&gt;3. &lt;code&gt;least_conn&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;这个功能可以让在有需要长时间才能完成的请求时让请求的分配更公平。简言之就是它可以控制不让单独的一台服务器负载太高，而是会根据其负载动态的分配请求。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ww4.sinaimg.cn/large/006tKfTcly1fcldjacqwtj30bs03fdg0.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-consistent-hash&#34;&gt;4. &lt;code&gt;consistent hash&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;可以根据请求的URL进行Hash，也就是当用户请求同一个URL时永远都会分配到同一台后端服务器，如果后端服务器提供缓存服务这个功能就很有用了。详细用户见&lt;a href=&#34;https://www.nginx.com/resources/wiki/modules/consistent_hash/&#34;&gt;Nginx Wiki&lt;/a&gt;，默认是没有编译这个模块的，可以自行编译安装。&lt;/p&gt;

&lt;h3 id=&#34;5-down&#34;&gt;5. &lt;code&gt;down&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;标记某台应用服务器暂时不参与负载均衡。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ww2.sinaimg.cn/large/006tKfTcly1fcleinzabwj30dp0370sv.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;6-backup&#34;&gt;6. &lt;code&gt;backup&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;这个标记和&lt;code&gt;down&lt;/code&gt;正好相反，它是在其他所有应用服务器全部繁忙或者处于&lt;code&gt;down&lt;/code&gt;状态时才会被启用，所以这台机器的压力会最轻。&lt;/p&gt;

&lt;h2 id=&#34;健康状态检查&#34;&gt;健康状态检查&lt;/h2&gt;

&lt;p&gt;Nginx会自动把返回报错信息的应用服务器标记为『故障』，然后就不再把新的请求分配给它了，这个相关的配置有:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;max_fails&lt;/code&gt; 报错多少次会被标记为&lt;strong&gt;failed&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;fail_timeout&lt;/code&gt; 超时多少次会被标记成&lt;strong&gt;failed&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;​&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>认识正向代理和反向代理</title>
      <link>http://lovelock.coding.me/linux/proxy-and-reverse-proxy/</link>
      <pubDate>Thu, 09 Feb 2017 14:39:09 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/linux/proxy-and-reverse-proxy/</guid>
      <description>

&lt;p&gt;这两个概念平时经常会提到，但我自己好像对它们两个的区别也不是很明白。刚才找了&lt;a href=&#34;http://freeloda.blog.51cto.com/2033581/1288553&#34;&gt;一篇文章&lt;/a&gt;，看起来讲述的挺清楚。这里我再用自己的语言描述一下以加深印象。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;一句话解释：正向代理是为了让防火墙内的用户通过墙外的代理访问原本不可访问的服务；反向代理是为了让防火墙外的用户访问墙内的服务。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;正向代理&#34;&gt;正向代理&lt;/h2&gt;

&lt;p&gt;正向代理就是我们平时提到最多的『代理』，而有科学上网需求的同学可能对这个概念更熟悉。原本无法访问墙外资源的我们买或租一台位于墙外的机器，搭上代理，就可以通过代理来访问『不存在的网站』了。&lt;/p&gt;

&lt;p&gt;为了描述简单，比如我的代理服务器地址为myproxy.com，我要通过它访问twitter.com。&lt;/p&gt;

&lt;p&gt;在这个使用场景下，我在浏览器输入的地址仍是&lt;code&gt;https://twitter.com&lt;/code&gt;，因为本地配置了代理的客户端，其中配置了代理规则，当命中这个规则时，访问该地址的请求就会通过&lt;code&gt;myproxy.com&lt;/code&gt;去访问，代理服务器去目标服务器取回我想要的数据后返回给我。&lt;/p&gt;

&lt;p&gt;正如前面所说，&lt;strong&gt;客户端必须要有一定配置才能使用正向代理&lt;/strong&gt;。因为要保证本来要发往目标服务器的地址会被代理服务器『劫持』。如果我说的不够明白，自行代入一下影梭的用法，就知道我在说什么了。&lt;/p&gt;

&lt;h2 id=&#34;反向代理&#34;&gt;反向代理&lt;/h2&gt;

&lt;p&gt;正向代理我们个人使用比较多，而反向代理可能就更多的出现在工作中了。我理解有两种情况需要用到反向代理。以VPC（Virtual Private Cloud）为例，如果不太了解VPC的特点，可以简单的理解为真实提供服务的机器都位于一个对外不可见的网络环境中，要让外部客户端访问其中的资源，有两种方法：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;给内部机器分配外部可以访问的IP地址&lt;/li&gt;
&lt;li&gt;使用『负载均衡』技术&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其中第一种也就是偶尔会听到的『绑定多网卡』，一个机器有一个内网地址和一个外网地址。内部地址用于访问内网资源，比如云主机提供商通常会有自己的『镜像源』，从外部访问时很慢或者根本不能访问，而用内网访问相当于直连，速度快到飞起。服务器说到底还是要为外部提供服务，所以它还需要一个外部地址供外部的客户端访问。&lt;/p&gt;

&lt;p&gt;这种只需要按照相应的规则配置就可以了，我也只是了解，因为我接触不到这一层。&lt;/p&gt;

&lt;p&gt;接触更多的是『负载均衡』，也叫Load-Balance，简称LB。在VPC的网络环境下，它肯定是需要有两个IP的。我本地没有VPC的环境，下面的实验基于本地的Docker环境。&lt;/p&gt;

&lt;h4 id=&#34;实验条件&#34;&gt;实验条件&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;Ubuntu 16.04 with Docker 1.12.3&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sudo docker pull nginx&lt;/code&gt;官方Nginx Docker镜像&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;实验步骤&#34;&gt;实验步骤&lt;/h4&gt;

&lt;h5 id=&#34;直接访问-通过端口转发&#34;&gt;直接访问（通过端口转发）&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;本地建一个目录，用于存放网站资源文件。如&lt;code&gt;$HOME/Public/web1/index.html&lt;/code&gt;，文件内容如下：&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;   &amp;lt;html&amp;gt;
   	&amp;lt;head&amp;gt;
   		&amp;lt;title&amp;gt;Web1&amp;lt;/title&amp;gt;
   	&amp;lt;/head&amp;gt;
   	&amp;lt;body&amp;gt;
   		&amp;lt;h1&amp;gt;Content of Web1&amp;lt;/h1&amp;gt;
   	&amp;lt;/body&amp;gt;
   &amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;docker run --name web1 -v /home/docker/Public/web1:/usr/share/nginx/html:ro -d -p 8081:80 nginx&lt;/code&gt; 这句命令做了以下几件事：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;给docker容器指定名字web1&lt;/li&gt;
&lt;li&gt;设置一个『共享目录』，从容器中读取&lt;code&gt;/usr/share/nginx/html&lt;/code&gt;目录实际是&lt;strong&gt;以只读方式&lt;/strong&gt;读取宿主本地的&lt;code&gt;/home/docker/Public/web1&lt;/code&gt;目录。&lt;/li&gt;
&lt;li&gt;设置本地端口8081映射到容器的80端口&lt;/li&gt;
&lt;li&gt;启动Nginx容器&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;我的宿主机器IP是&lt;code&gt;192.168.159.3&lt;/code&gt;，所以可以访问&lt;code&gt;http://192.168.159.3:8081&lt;/code&gt;来检查一下是否成功了&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://ww2.sinaimg.cn/large/006tKfTcly1fck90lvtwxj30uq04sq3i.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;等等，这种方式绝对是不可接受的。我虽然不用关心容器的IP，但它竟然用了这么个端口，难道还要让用户记住端口号？&lt;/p&gt;

&lt;h5 id=&#34;反向代理-1&#34;&gt;反向代理&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;配置宿主机的Nginx（类比上面提到的VPC中的LB，因为它既能被外部访问，同时也能访问容器实例）&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;   server {
   	server_name proxy.ubuntu.com;

   	location / {
   		proxy_pass http://localhost:8081;
   	}
   }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的配置做了以下几件事：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;给宿主机配置了一个server_name，这个在测试环境不太需要，这里配置了只是因为我的宿主机已经有了好几个vhost。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;location段指定当访问&lt;code&gt;http://proxy.ubuntu.com/&lt;/code&gt;时会将请求重定向到&lt;code&gt;http://localhost:8081&lt;/code&gt;。这里省略了&lt;code&gt;listen 80;&lt;/code&gt;主要是懒，因为本来就是默认的。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过&lt;code&gt;http://proxy.ubuntu.com&lt;/code&gt;访问，配置hosts什么的不用我说了吧&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ww4.sinaimg.cn/large/006tKfTcly1fck9or3xq6j30js05qdga.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过上面的两个例子，我们已经看到了什么是反向代理和它的实际作用了。但实际上它更重要的应用是『负载均衡』。比如一个服务由2台服务器提供，假设两台服务器配置一样，再起两个容器实例吧，这次要把访问日志打出来。首先要看一下容器里默认的Nginx配置：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ww4.sinaimg.cn/large/006tKfTcly1fck9uzyl4zj317u0410uu.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;执行&lt;code&gt;docker cp 3bcbb1c5df2b:/etc/nginx/nginx.conf nginx.conf&lt;/code&gt;就把其中一个容器实例的&lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt;拷贝到本地的&lt;code&gt;./nginx.conf&lt;/code&gt;文件了。内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;
user  nginx;
worker_processes  1;

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  &#39;$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; &#39;
                      &#39;$status $body_bytes_sent &amp;quot;$http_referer&amp;quot; &#39;
                      &#39;&amp;quot;$http_user_agent&amp;quot; &amp;quot;$http_x_forwarded_for&amp;quot;&#39;;

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    include /etc/nginx/conf.d/*.conf;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;你也许知道Docker中的服务是不能以daemon方式运行的，那这里为什么没有&lt;code&gt;daemon off;&lt;/code&gt;的配置呢？因为它在Dockerfile的CMD段指定过了。。。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;看倒数第二行我们知道了具体的server配置是位于&lt;code&gt;/etc/nginx/conf.d&lt;/code&gt;中的，也就是我们俗称的vhosts配置。根据经验，它一定是包含一个&lt;code&gt;default.conf&lt;/code&gt;的，同样的方式把它拿出来:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker cp 3bcbb1c5df2b:/etc/nginx/conf.d/default.conf default.conf&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;server {
    listen       80;
    server_name  localhost;

    #charset koi8-r;
    #access_log  /var/log/nginx/log/host.access.log  main;

    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
    }

    #error_page  404              /404.html;

    # redirect server error pages to the static page /50x.html
    #
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }

    # proxy the PHP scripts to Apache listening on 127.0.0.1:80
    #
    #location ~ \.php$ {
    #    proxy_pass   http://127.0.0.1;
    #}

    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
    #
    #location ~ \.php$ {
    #    root           html;
    #    fastcgi_pass   127.0.0.1:9000;
    #    fastcgi_index  index.php;
    #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
    #    include        fastcgi_params;
    #}

    # deny access to .htaccess files, if Apache&#39;s document root
    # concurs with nginx&#39;s one
    #
    #location ~ /\.ht {
    #    deny  all;
    #}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;好，从这里我们就看到了Nginx的访问日志所在路径，稍微修改一下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;server {
    listen       80;
    server_name  localhost;

    access_log  /var/log/nginx/log/host.access.log  main;

    location / {
        root   /usr/share/nginx/html;
        index  index.html index.htm;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就确定了日志的位置。执行下面的指令:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --name web5 -v /home/docker/Public/web2:/usr/share/nginx/html:ro -v /home/docker/etc/custom.conf:/etc/nginx/conf.d/default.conf -v /home/docker/etc/log/web5.log:/var/log/nginx/host.access.log -d -p 8085:80 nginx
docker run --name web6 -v /home/docker/Public/web2:/usr/share/nginx/html:ro -v /home/docker/etc/custom.conf:/etc/nginx/conf.d/default.conf -v /home/docker/etc/log/web6.log:/var/log/nginx/host.access.log -d -p 8086:80 nginx
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就起了两个容器实例。然后在宿主机的Nginx配置的http段加入以下配置：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;upstream web_proxy {
		server localhost:8085;
		server localhost:8086;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后在&lt;code&gt;proxy.ubuntu.com&lt;/code&gt;的vhosts中配置&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;server {
	server_name proxy.ubuntu.com;

	location / {
		proxy_pass http://web_proxy;
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;重启宿主Nginx就可以见证一个最简单的Nginx负载均衡了。&lt;/p&gt;

&lt;p&gt;打开&lt;code&gt;http://proxy.ubuntu.com/&lt;/code&gt;，每次出现的页面都是这样：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://ww3.sinaimg.cn/large/006tKfTcly1fckby59r15j30mm04wdgb.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以多刷新几次，关注下两个log文件的变化，你会发现两个log文件总是一样的，比如这次访问web5，下次一定是web6，偶数次之后两个总是相等的。这是因为在上面upstream的设置中，没有配置weight（权重）的情况下，默认两个server的权重是一样的。&lt;/p&gt;

&lt;p&gt;关于Nginx负载均衡的具体分配策略问题，另外开一篇文章来讨论。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>为Docker配置国内加速镜像</title>
      <link>http://lovelock.coding.me/linux/set-docker-image-mirror/</link>
      <pubDate>Thu, 09 Feb 2017 10:31:45 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/linux/set-docker-image-mirror/</guid>
      <description>

&lt;p&gt;今天想着复习一下Nginx的反向代理，又懒得再配置多台机器了，正好手里有已经安装了Docker的台式机，于是就想用Nginx的Docker image来做实验了。&lt;/p&gt;

&lt;p&gt;由于众所周知的原因，我们在圈内访问&lt;a href=&#34;https://hub.docker.com/&#34;&gt;docker官方镜像&lt;/a&gt;是很慢的，好在包括&lt;a href=&#34;https://www.daocloud.io/&#34;&gt;DaoCloud&lt;/a&gt;和&lt;a href=&#34;https://dev.aliyun.com/search.html&#34;&gt;阿里云&lt;/a&gt;为我们提供了而苏稳定的镜像服务。废话不多说，下面总结了一下使用国内镜像加速Docker镜像下载的方式。&lt;/p&gt;

&lt;h2 id=&#34;获取专属的加速地址&#34;&gt;获取专属的加速地址&lt;/h2&gt;

&lt;p&gt;上面提到的两个镜像服务提供者都是需要注册才能用的，注册后你会拿到一个形如&lt;code&gt;http://78a2f85b.m.daocloud.io&lt;/code&gt;的地址（阿里的我没有尝试，应该是类似的），这就是专属你的加速地址了。说是专属，但其实并没有身份认证，任何人都是可以直接用的，除非你要把自己创建的镜像提交到DaoCloud才会做身份认证。&lt;/p&gt;

&lt;h2 id=&#34;本地配置&#34;&gt;本地配置&lt;/h2&gt;

&lt;p&gt;DaoCloud是搞了一个配置脚本来为我们自动搞定这个工作的，怎奈不知道为什么这个脚本一直没有更新，对于用systemd的发行版来说已经不适用了。对于使用systemd的发行版，有以下两种方法实现加速：&lt;/p&gt;

&lt;h3 id=&#34;1-修改service文件&#34;&gt;1. 修改service文件&lt;/h3&gt;

&lt;p&gt;安装docker后，会在&lt;code&gt;/lib/systemd/system&lt;/code&gt;目录下生成一个&lt;code&gt;docker.service&lt;/code&gt;的文件，对于Ubuntu 16.04内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-nginx&#34;&gt;[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target docker.socket
Requires=docker.socket

[Service]
Type=notify
# the default is not to use systemd for cgroups because the delegate issues still
# exists and systemd currently does not support the cgroup feature set required
# for containers run by docker
ExecStart=/usr/bin/dockerd -H fd://
ExecReload=/bin/kill -s HUP $MAINPID
# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0
# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes
# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;找到其中的&lt;code&gt;ExecStart=/usr/bin/dockerd -H fd://&lt;/code&gt;行，改成&lt;code&gt;ExecStart=/usr/bin/dockerd -H fd:// --registry-mirror=http://78a2f85b.m.daocloud.io&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;因为你手动修改了service文件，当然要执行以下命令了:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo systemctl daemon-reload
sudo systemctl restart docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果还想查看一下docker的运行状态，就再执行一下&lt;code&gt;sudo systemctl status docker&lt;/code&gt;即可。&lt;/p&gt;

&lt;h3 id=&#34;2-修改daemon-json文件&#34;&gt;2. 修改daemon.json文件&lt;/h3&gt;

&lt;p&gt;默认是没有这个文件的，可以自行创建：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sudo vim /etc/docker/daemon.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;文件内容如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{
    &amp;quot;registry-mirrors&amp;quot;: [
            &amp;quot;http://78a2f85b.m.daocloud.io&amp;quot;
        ],
    &amp;quot;insecure-registries&amp;quot;: []
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后执行&lt;code&gt;sudo systemctl restart docker&lt;/code&gt;。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;执行上面两种方法中的一种，即可享受国内良心厂商带给我们的加速服务了。注意我在本文中没有区分一个说法：镜像。有的地方镜像指的是Docker 的Image，有的地方是指加速服务的mirrors，请读者自行区分。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>关于PHP接口特性的一个发现</title>
      <link>http://lovelock.coding.me/php/about-php-interface/</link>
      <pubDate>Thu, 19 Jan 2017 15:21:43 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/php/about-php-interface/</guid>
      <description>&lt;p&gt;这两天看一本PHP的进阶书，发现了一些之前没有注意的特性。比如PHP接口的设计方式和它对实现该接口的类的约束就和通常的语言(比如Java）不一样。&lt;/p&gt;

&lt;p&gt;举一个简单的例子，要写一个配置管理类，这个类为了适配不同的配置文件格式，比如&lt;code&gt;ini&lt;/code&gt;,&lt;code&gt;yaml&lt;/code&gt;等，就需要一个接口来约束这些具体的实现。代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;&amp;lt;?php
  
  interface ConfigInterface
  {
    public function get($name);
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;&amp;lt;?php
  class IniConfig implements ConfigInterface
  {
    public function get($name)
      {
        xxxxx;
      }
  
  	public function fetch($name)
      {
        xxxxxx;
      }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;&amp;lt;?php
  class YamlConfig implements ConfigInterface
  {
    public function get($name)
      {
        xxxxxx;
      }
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-php&#34;&gt;&amp;lt;?php
  function check(ConfigInterface $config)
  {
    $config-&amp;gt;fetch(&#39;foo&#39;);
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果你按类似上面的结构写完执行你就会发现一个很神奇的特性，这段代码竟然是可以执行的（忽略我为了偷懒省略了具体实现吧）。&lt;/p&gt;

&lt;p&gt;但是仔细想想，我在方法&lt;code&gt;check&lt;/code&gt;里面用接口解耦的目的是什么呢？就是为了接受不同实现，而如果这些实现自己的独有的方法在这里都可以调用，这个约束的存在还有什么意义呢？所以，我理解的PHP的接口的作用仅仅限于两点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;规定每个实现一定要实现相应的方法&lt;/li&gt;
&lt;li&gt;方便IDE进行自动提示和补全&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;也就是说，PHP的接口更多意义上是一个&lt;strong&gt;约定&lt;/strong&gt;，而不是&lt;strong&gt;规定&lt;/strong&gt;。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>创建变量(PHP5.x扩展)</title>
      <link>http://lovelock.coding.me/php/internals/create-variables/</link>
      <pubDate>Wed, 18 Jan 2017 18:08:53 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/php/internals/create-variables/</guid>
      <description>

&lt;p&gt;这里记录一下如何在PHP5的扩展中创建变量，包括局部变量和全局变量。&lt;/p&gt;

&lt;h2 id=&#34;必备知识&#34;&gt;必备知识&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;PHP内部有符号表的概念，其中局部变量存放在指针&lt;code&gt;active_symbol_table&lt;/code&gt;中，而全局变量存放在非指针（真实值）&lt;code&gt;symbol_table&lt;/code&gt;中。&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;MAKE_STD_ZVAL&lt;/code&gt;宏创建变量。&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;ZVAL_xxxx&lt;/code&gt;宏为创建的变量赋值，当然也可以不赋值，而只是声明。&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;ZEND_SET_SYMBOL&lt;/code&gt;宏设置变量设置成全局还是局部。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-局部变量&#34;&gt;1. 局部变量&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;zval *new_var;
MAKE_STD_ZVAL(new_var);
ZVAL_LONG(new_var, 2000);
ZEND_SET_SYMBOL(EG(active_symbol_table), &amp;quot;aVar&amp;quot;, new_var);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的代码会创建一个名为&lt;code&gt;$aVar&lt;/code&gt;的&lt;strong&gt;局部变量&lt;/strong&gt;，它的值是2000。&lt;/p&gt;

&lt;h3 id=&#34;2-全局变量&#34;&gt;2. 全局变量&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;zval *new_var;
MAKE_STD_ZVAL(new_var);
ZVAL_LONG(new_var, 2000);
ZEND_SET_SYMBOL(&amp;amp;EG(symbol_table), &amp;quot;aVar&amp;quot;, new_var);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的代码会创建一个名为&lt;code&gt;$aVar&lt;/code&gt;的全局变量，它的值是2000。在PHP中没有什么是一个宏实现不了的，如果有，那就两个————所以，你看创建一个全局变量要那么多字符，干脆再包装一个宏算了，于是就可以把最后一行替换成&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;ZEND_SET_GLOBAL_VAR(&amp;quot;aVar&amp;quot;, new_var);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ww3.sinaimg.cn/large/006tNbRwly1fbuyfmvy90j30z403q0tk.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>没有参数的函数（区别于类的方法）</title>
      <link>http://lovelock.coding.me/php/internals/a-function-without-arguments/</link>
      <pubDate>Tue, 17 Jan 2017 15:48:42 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/php/internals/a-function-without-arguments/</guid>
      <description>&lt;p&gt;距离上一次写PHP扩展相关的内容已经很久很久了，这两天又想着写一个真正意义上的扩展了，所以又要重新学习了。&lt;/p&gt;

&lt;p&gt;先从写一个最简单的函数说起，从我现在的理解来说这个函数是全局的。比如我要实现一个最简单的&lt;code&gt;helloworld&lt;/code&gt;函数。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;这里说一个小插曲，最后不要用dash(-)作为扩展名字的一部分，会出现乱七八糟的麻烦。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如图所示，&lt;img src=&#34;https://ww4.sinaimg.cn/large/006tNc79ly1fbtoytl1g7j31ks0jswjf.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;需要注意的是&lt;code&gt;PHP_FUNCTION(helloworld)&lt;/code&gt;这段需要放在&lt;code&gt;const&lt;/code&gt;这段前面，因为相当于前面是定义了&lt;code&gt;helloworld&lt;/code&gt;这个函数名，后面是把它注册到『可用函数列表』中，如果都没有定义，怎么注册呢，对吧？&lt;/p&gt;

&lt;p&gt;至于编译的细节，请看我之前的文章。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>清理HDFS的脏数据</title>
      <link>http://lovelock.coding.me/bigdata/cleanup-dirty-data-in-hdfs/</link>
      <pubDate>Wed, 11 Jan 2017 14:27:46 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/bigdata/cleanup-dirty-data-in-hdfs/</guid>
      <description>

&lt;p&gt;周末同事在群里用由我维护的Hive里查数据，发现完全对不上了，我简单查了一下，发现是预计下一期上的日志格式提前上了，而我的Topology还没有跟上，导致数据字段完全错乱。我马上停掉相应的Topology，避免产生更多的脏数据，周一到公司在给新版的Topology做了严格测试准备上线。&lt;/p&gt;

&lt;p&gt;接下来面对的就是怎么把脏数据清除掉，把被错误处理的数据重新处理一遍，并且后续的数据不受影响。&lt;/p&gt;

&lt;h2 id=&#34;步骤&#34;&gt;步骤&lt;/h2&gt;

&lt;h3 id=&#34;1-找到脏数据的offset-最好向前移动一些-以保证所有脏数据都能被处理&#34;&gt;1. 找到脏数据的offset，最好向前移动一些，以保证所有脏数据都能被处理&lt;/h3&gt;

&lt;p&gt;在数据处理节点（我们这里是core节点）上找到kafka-broker的安装目录，执行&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;sh bin/kafka-simple-consumer-shell.sh --topic online_userbehaviortrack --offset -2 --broker-list 10.68.160.52:6667,10.68.160.53:6667,10.68.160.54:6667 --print-offsets --partition 9
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上面的命令会输出类似&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;next offset = 3381
{&amp;quot;message&amp;quot;:&amp;quot;2017-01-11T14:40:55+0800`1484116855552`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;的结果，从中可以很详细的看到每条message的offset，结合管道和less就可以根据时间找到出现脏数据的offset，然后确定一个时间点，比如下午2点，在每个partition中分别找到2点之前的最后一个offset，找个地方记下来。&lt;/p&gt;

&lt;h3 id=&#34;2-到zookeeper中找到每个对应的partiton-用步骤1的offset结果覆盖partiton中的offset字段&#34;&gt;2. 到ZooKeeper中找到每个对应的Partiton，用步骤1的offset结果覆盖Partiton中的offset字段&lt;/h3&gt;

&lt;p&gt;因为我的KafkaSpout是这么写的&lt;code&gt;SpoutConfig kafkaSpoutConfig = new SpoutConfig(brokerHosts, topic, &amp;quot;/&amp;quot; + topic, client_id);&lt;/code&gt;，所以在我的ZooKeeper中我应该去&lt;code&gt;/mytopic/mytopologyname/&lt;/code&gt;中找到所有的partiton，这个需要根据你自己的代码来确定。&lt;/p&gt;

&lt;p&gt;以partition_9为例，结果如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[zk: localhost:2181(CONNECTED) 2] get /mytopic/fe_analyze/partition_9
{&amp;quot;topology&amp;quot;:{&amp;quot;id&amp;quot;:&amp;quot;c75ac929-1a8e-4958-a637-ead9a95436ca&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;mytopologyname&amp;quot;},&amp;quot;offset&amp;quot;:3384,&amp;quot;partition&amp;quot;:9,&amp;quot;broker&amp;quot;:{&amp;quot;host&amp;quot;:&amp;quot;kmr-9a387314-gn-6bb9c438-core-1-002.ksc.com&amp;quot;,&amp;quot;port&amp;quot;:6667},&amp;quot;topic&amp;quot;:&amp;quot;mytopic&amp;quot;}
cZxid = 0x1017bd837
ctime = Mon Dec 26 15:06:19 CST 2016
mZxid = 0x101cbb4ec
mtime = Wed Jan 11 14:49:40 CST 2017
pZxid = 0x1017bd837
cversion = 0
dataVersion = 2173
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 223
numChildren = 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因为我们只需要设置partiton的offset值，而它接收一个JSON类型的值，所以就需要这样&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[zk: localhost:2181(CONNECTED) 4] set /mytopic/mytopologyname/partition_9 {&amp;quot;topology&amp;quot;:{&amp;quot;id&amp;quot;:&amp;quot;c75ac929-1a8e-4958-a637-ead9a95436ca&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;fe_analyze&amp;quot;},&amp;quot;offset&amp;quot;:3386,&amp;quot;partition&amp;quot;:9,&amp;quot;broker&amp;quot;:{&amp;quot;host&amp;quot;:&amp;quot;kmr-9a387314-gn-6bb9c438-core-1-002.ksc.com&amp;quot;,&amp;quot;port&amp;quot;:6667},&amp;quot;topic&amp;quot;:&amp;quot;mytopic&amp;quot;}
cZxid = 0x1017bd837
ctime = Mon Dec 26 15:06:19 CST 2016
mZxid = 0x101cbba18
mtime = Wed Jan 11 14:54:29 CST 2017
pZxid = 0x1017bd837
cversion = 0
dataVersion = 2176
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 223
numChildren = 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;把其中的offset的值替换成在步骤1中拿到的partiton 9的offset值。&lt;/p&gt;

&lt;h3 id=&#34;3-写脚本删除hdfs中对应topology出现脏数据以后的所有数据&#34;&gt;3. 写脚本删除HDFS中对应Topology出现脏数据以后的所有数据&lt;/h3&gt;

&lt;p&gt;我的设计是每天分成24个partition，类似(yyyymmddhh=2017011010)这种，所以就可以写个类似这样的脚本：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/usr/bin/env bash

DAY=$(date -d &amp;quot;-1 day&amp;quot; +%Y%m%d)

for HH in {00..23}
do
    hdfs dfs -rm -r -f /path/to/topology/yyyymmddhh=${DAY}${HH}
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个脚本可以删除前一天的所有24个partiton的数据。&lt;/p&gt;

&lt;h3 id=&#34;4-如果新的topology对应的hive-table也有变化-需要先修改hive的表结构&#34;&gt;4. 如果新的Topology对应的Hive table也有变化，需要先修改Hive的表结构&lt;/h3&gt;

&lt;p&gt;Hive表结构的修改和MySQL的差不多，不过还是有些差别：比如新添加的列只能放在所有真实列的最后，partiton伪列的前面。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;alter table xxxx add columns (string coln, string colm);&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;注意是&lt;strong&gt;&lt;code&gt;columns&lt;/code&gt;&lt;/strong&gt;而不是&lt;code&gt;column&lt;/code&gt;。而且也不能指定after哪个column。&lt;/p&gt;

&lt;h3 id=&#34;5-重新添加所有受影响的partiton到hive-table&#34;&gt;5. 重新添加所有受影响的partiton到Hive table&lt;/h3&gt;

&lt;p&gt;因为我们这里用的是external table（当我提到HDFS的时候你就应该知道了），所以所有新数据对应的partiton都应该删除后重新添加，以yyyymmddhh=2017011020为例，&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;删除partition &lt;code&gt;alter table xxxx drop if exists partiton (yyyymmddhh= 2017011020);&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;添加partition &lt;code&gt;alter table xxxx add if not exists partition (yyyymmddhh= 2017011020);&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这样就可以对新加进来的数据进行搜索了。你可以试一下，如果少了这步操作，在新的Hive table里新加的列的值会全部是NULL。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;步骤很多，但操作还是挺简单的，而且需要细心，不能出错，尤其这里每一步都是线上的操作，一次微小的出错都可能酿成事故。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;找到每个partiton出现脏数据时的offset&lt;/li&gt;
&lt;li&gt;把当前每个partiton的offset设置成出现脏数据时的offset&lt;/li&gt;
&lt;li&gt;清除出错的脏数据&lt;/li&gt;
&lt;li&gt;修改Hive table（如果需要）&lt;/li&gt;
&lt;li&gt;删除并重新添加受影响的partition(如果需要)&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>不用root修改一加三的DPI</title>
      <link>http://lovelock.coding.me/fxxkmyphone/change-dpi-of-oneplus3/</link>
      <pubDate>Tue, 13 Dec 2016 15:25:03 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/fxxkmyphone/change-dpi-of-oneplus3/</guid>
      <description>&lt;p&gt;之前也听说过有修改DPI的，但不知道修改了会有什么变化。后来直接升级了7.0（官方的OxygenOS OpenBeta version 4.0)，稳定性不行，耗电也非常大。忍了几天实在忍不了，于是乎就刷回目前使用最稳定的稳定版3.2.8了。&lt;/p&gt;

&lt;p&gt;但在用7.0期间，最吸引我的一个特性还是让我怀念不已，就是修改“显示大小”，这就是包装过的修改DPI功能了。但那是7.0及以上才标配的功能，为了解决厂商调整的DPI不符合用户习惯的问题。当然现在这个问题在审美不是一般差劲的一加ROM上是很大的问题了，我简直没有见过字体那么大的手机，但直接修改字体大小其实没什么用的，因为包括列表在内的一些组件的高度和宽度是没有变的，修改字体大小只是让字体在屏幕上显得更小了。而且我还不想解锁，不想root。于是就找到了下面的方法。&lt;/p&gt;

&lt;p&gt;首先开启“开发者选项”。
执行 &lt;code&gt;adb shell wm density 400 &amp;amp;&amp;amp; adb reboot&lt;/code&gt; 其实就够了，不过如果你想直到默认的是多少，我可以告诉你是480，简直太大了。我觉得400是一个比较合理的大小。具体多少你可以自己调整，200-600之间都是可以的，不过200太小了。&lt;/p&gt;

&lt;p&gt;好久没有更新博客了，发现自己好啰嗦啊。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;更新：现在升级了官方的氢3.0 测试版，用了原生的修改DPI功能，相当稳定了，已经快一个月没有刷机了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>用Bash编写漂亮的命令行程序</title>
      <link>http://lovelock.coding.me/linux/handle-with-bash-options/</link>
      <pubDate>Fri, 14 Oct 2016 15:40:58 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/linux/handle-with-bash-options/</guid>
      <description>

&lt;p&gt;我学着写这篇是因为前面写了一个&lt;a href=&#34;http://unixera.com/virtualization/create-a-virtual-machine-with-vboxmanage/&#34;&gt;使用VBoxManage创建虚拟机&lt;/a&gt;，后来我发现这个过程太繁琐，就写了一个脚本，但脚本里面写死太多东西就没有了灵活性，所以就需要支持各种选项和参数。而因为这些命令都是很直观的命令，用Shell脚本就已经很完美的实现了这些功能。&lt;/p&gt;

&lt;p&gt;代码可以在&lt;a href=&#34;https://github.com/lovelock/bash_opts&#34;&gt;这里&lt;/a&gt;下载。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;本文基于&lt;a href=&#34;http://stackoverflow.com/questions/192249/how-do-i-parse-command-line-arguments-in-bash&#34;&gt;StackOverFlow&lt;/a&gt;上的这篇答案。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;首先要知道几个内建变量&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;内建变量&lt;/th&gt;
&lt;th&gt;意义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$0&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;执行的脚本文件名&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$1/$2&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;这些带数字（&amp;gt;0）的表示执行脚本后面对应的第N个参数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$#&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;脚本执行时的参数个数&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$@&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;所有参数作为一个类似数组的结构&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$*&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;和&lt;code&gt;$@&lt;/code&gt;对比，前面的是一个数组结构，这个是用空格分开的多个变量&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$-&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;当前脚本执行时的附加参数，比如&lt;code&gt;-x&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$_&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;最近的参数（或者当前脚本执行时所在的目录）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$IFS&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;输入字段分隔符，一般是空格&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$!&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;最近的后台执行的命令，这个很常用，在vim中按Ctrl-z会把vim放在后台，在同样的终端中按&lt;code&gt;%!&lt;/code&gt;就会把他切回到前台&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$$&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;当前脚本的pid（进程号）&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$?&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;脚本执行后的返回值，一般0代表成功，这个0就是我们用C写程序时&lt;code&gt;main&lt;/code&gt;方法中最后的&lt;code&gt;return 0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;使用空格分隔选项和相应的参数&#34;&gt;使用空格分隔选项和相应的参数&lt;/h2&gt;

&lt;p&gt;用法: &lt;code&gt;bash script.sh -e .php --path .&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/usr/bin/env bash

while [[ $# -gt 1 ]]
do
    KEY=$1

    case $KEY in
        -e|--extension)
            EXTENSION=$2
            shift
            ;;
        -s|--search-path)
            SEARCHPATH=$2
            shift
            ;;
        *)
            ;;
    esac
    shift


done

echo FILE_EXTENSION=${EXTENSION}
echo SEARCH_PATH=${SEARCHPATH}
echo &amp;quot;Number files in ${SEARCH_PATH} with ${EXTENSION}:&amp;quot; $(ls -1 &amp;quot;${SEARCHPATH}&amp;quot;/*.&amp;quot;${EXTENSION}&amp;quot; | wc -l)

if [[ -n $1 ]]; then
    echo &amp;quot;Last line of file specified as non-opt/last argument:&amp;quot;
    tail -1 $1
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该脚本接收两个参数，可以用&lt;strong&gt;长参数(&amp;ndash;extension)&lt;/strong&gt;也可以用&lt;strong&gt;短参数(-e)&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;示例： &lt;code&gt;$ bash space.sh -e py --search-path .&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;使用等号分隔选项和参数&#34;&gt;使用等号分隔选项和参数&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/usr/bin/env bash

for i in $@
do
    case $i in
        -e=*|--extension=*)
            EXTENSION=&amp;quot;${i#*=}&amp;quot;
            shift # past argument=value
            ;;
        -s=*|--searchpath=*)
            SEARCHPATH=&amp;quot;${i#*=}&amp;quot;
            shift # past argument=value
            ;;
        *)
            # unknown option
            ;;
    esac
done

echo &amp;quot;FILE EXTENSION  = ${EXTENSION}&amp;quot;
echo &amp;quot;SEARCH PATH     = ${SEARCHPATH}&amp;quot;
echo &amp;quot;Number files in SEARCH PATH with EXTENSION:&amp;quot; $(ls -1 &amp;quot;${SEARCHPATH}&amp;quot;/*.&amp;quot;${EXTENSION}&amp;quot; | wc -l)

if [[ -n $1 ]]; then
    echo &amp;quot;Last line of file specified as non-opt/last argument:&amp;quot;
    tail -1 $1
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;该脚本接收两个参数，可以用&lt;strong&gt;长参数(&amp;ndash;extension)&lt;/strong&gt;也可以用&lt;strong&gt;短参数(-e)&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;示例： &lt;code&gt;$ bash space.sh -e=php --search-path=.&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;使用-getops&#34;&gt;使用&lt;code&gt;getops&lt;/code&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/usr/bin/env bash

# A POSIX variable
OPTIND=1         # Reset in case getopts has been used previously in the shell.

# Initialize our own variables:
EXTENSION=&amp;quot;&amp;quot;
VERBOSE=&amp;quot;-1&amp;quot;

while getopts &amp;quot;h?ve:&amp;quot; opt; do
    case &amp;quot;${opt}&amp;quot; in
        h|\?)
            show_help
            exit 0
            ;;
        v)  VERBOSE=&amp;quot;-l&amp;quot;
            ;;
        e)  EXTENSION=$OPTARG
            ;;
    esac
done

shift $((OPTIND-1))

[ &amp;quot;$1&amp;quot; = &amp;quot;--&amp;quot; ] &amp;amp;&amp;amp; shift

ls ${VERBOSE} *.${EXTENSION}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这种方式只能使用短参数不支持长参数，其中&lt;code&gt;${OPTARG}&lt;/code&gt;表示对应的这条选项的值。&lt;strong&gt;如果该选项后面会带参数，就要在其后面带&lt;code&gt;:&lt;/code&gt;&lt;/strong&gt;，比如在本例中，&lt;code&gt;-e&lt;/code&gt;选项后面需要带参数，那么&lt;code&gt;while getopts &amp;quot;h?ve:&amp;quot; opt; do&lt;/code&gt;这行&lt;code&gt;e&lt;/code&gt;的后面就有一个冒号了，不然你的在代码中是无法取到参数的。&lt;/p&gt;

&lt;p&gt;示例： &lt;code&gt;bash getopts.sh -v -e php&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;关于getopts的更多内容可以使用&lt;code&gt;help getopts&lt;/code&gt;查看。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用VBoxManage创建虚拟机</title>
      <link>http://lovelock.coding.me/virtualization/create-a-virtual-machine-with-vboxmanage/</link>
      <pubDate>Thu, 13 Oct 2016 16:35:22 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/virtualization/create-a-virtual-machine-with-vboxmanage/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;最近没有产品需求，就深入的研究一下大数据吧，第一步先要搭建一个集群，前面已经写了一篇关于搭建“伪集群”的文章，还是希望更完整的理解这套东西，还是弄一套真正的集群吧。但是没有机器，就只能拿本地的台式机搞起来了。&lt;/p&gt;

&lt;p&gt;本文主要介绍了如何使用VirtualBox命令行工具VBoxManage创建和维护虚拟机。官方文档中说到VBoxManage的功能是比GUI的VirtualBox要更完整的，但其实我也用不到那么完整的功能，我能想到的主要有以下几点，参照官方文档来逐个完成。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;创建一个虚拟机&lt;/li&gt;
&lt;li&gt;给虚拟机配置网络、CPU核心、内存、磁盘驱动器&lt;/li&gt;
&lt;li&gt;复制（clone）虚拟机&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我使用的环境如下：
&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/machine.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;##
&amp;gt; 看到这张图片，我想说一句关于字体的，Windows下绝对是Consolas最耐看；Linux下SourceCodePro最好看；Mac下命令行用Monaco，但IDE里面用Monaco最觉得不能认真写代码了，太花了，还是SourceCodePro比较正常一点，呼呼&lt;/p&gt;

&lt;p&gt;下面开搞吧。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;一定要确认你的VirtualBox安装了Extension Pack， 如果没有马上根据你的发行版或者去官网下载之后安装，否则无法远程连接虚拟机。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;创建虚拟机&#34;&gt;创建虚拟机&lt;/h2&gt;

&lt;h3 id=&#34;知识&#34;&gt;知识&lt;/h3&gt;

&lt;h4 id=&#34;1-vboxmanage-createmedium&#34;&gt;1. &lt;code&gt;VBoxManage createmedium&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;首先要创建一块磁盘。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;--filename &amp;lt;name&amp;gt;&lt;/code&gt; 创建的设备的名字&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--format VDI|VMDK|VHD&lt;/code&gt; 创建的设备的格式，默认是vdi，当年我做云主机运维的时候还测试过各种虚拟化磁盘格式的性能，vdi的性能是所有可选项里面最快的，值得信赖&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--size &amp;lt;megabytes&amp;gt;&lt;/code&gt; 创建的磁盘的大小，以M为单位&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;注意这个命令创建的磁盘是位于你当前所在的目录的，所以为了避免后面的问题，你最好在你想放在的位置执行这个命令。&lt;/p&gt;

&lt;h4 id=&#34;2-vboxmanage-createvm&#34;&gt;2. &lt;code&gt;VBoxManage createvm&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;然后创建一个虚拟机。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;--name &amp;lt;name&amp;gt;&lt;/code&gt; 指定虚拟机的名字，还会在&lt;code&gt;~/.config/VirtualBox/Machines&lt;/code&gt;目录下创建同名的xml文件，如果该虚拟机被重命名，该xml文件也会被自动重命名。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--basefolder &amp;lt;path&amp;gt;&lt;/code&gt; 指定上述的Machines目录，如果指定了这个目录，新创建时还是会在这个目录下产生xml文件，但当虚拟机被重命名时，该xml不会被重命名。所以这里我觉得还是不要改为好，虽然通常也不会去重命名虚拟机。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--groups &amp;lt;group&amp;gt;&lt;/code&gt; 指定虚拟机组，总是从&lt;code&gt;/&lt;/code&gt;开始，可以嵌套，默认是&lt;code&gt;/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--ostype &amp;lt;ostype&amp;gt;&lt;/code&gt; 指定虚拟机的操作系统类型，具体支持的操作系统类型可以使用&lt;code&gt;VBoxManage list ostypes&lt;/code&gt;来查看。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--uuid &amp;lt;uuid&amp;gt;&lt;/code&gt; 指定虚拟机的UUID，这个id在宿主机的命名空间内必须是唯一的，如果指定了虚拟机组，则在组内必须是唯一的，如果不指定，会自动生成，所以这个其实也每必要指定。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;默认情况下，这个命令只会创建一个xml文件，而并不会把虚拟机注册到系统中，可以使用&lt;code&gt;--register&lt;/code&gt;选项或者单独执行&lt;code&gt;VBoxManage register &amp;lt;uuid&amp;gt;&lt;/code&gt;来执行注册。&lt;/p&gt;

&lt;h4 id=&#34;3-vboxmanage-storagectl&#34;&gt;3. &lt;code&gt;VBoxManage storagectl&lt;/code&gt;&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;uuid|vmname&amp;gt;&lt;/code&gt; 指定要操作的虚拟机，可以使用前面创建时指定的名字，或者自动生成的uuid&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--name &amp;lt;name&amp;gt;&lt;/code&gt; 要创建的控制器的名字&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--controller&lt;/code&gt; 控制器，这个我也不太懂，一般电脑上是ACHI，这里就选IntelAHCI吧&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--add&lt;/code&gt; 添加的控制器类型，因为我们要创建的是磁盘驱动器，所以选择sata&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;这里其实是瞎说的，我也不太懂电脑硬件，这些概念不了解，就照着熟悉的来吧。需要创建两种类型的设备控制器，一个是磁盘控制器，用来管理硬盘，一个是光驱，用来管理ISO文件。这个很容易理解，这一步是创建控制器，而而这控制的东西，磁盘是前面创建的，iso是先前下载好的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;4-vboxmanage-storageattach&#34;&gt;4. &lt;code&gt;VBoxManage storageattach&lt;/code&gt;&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;uuid|vmname&amp;gt;&lt;/code&gt; 指定要操作的虚拟机，可以使用前面创建时指定的名字，或者自动生成的uuid&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--storagectl &amp;lt;name&amp;gt;&lt;/code&gt; 这就是上面那个&lt;code&gt;storagectl&lt;/code&gt;命令时的&lt;code&gt;--name&lt;/code&gt;选项指定的参数了&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--port&lt;/code&gt; 端口号&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--device&lt;/code&gt; 设备号&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--type&lt;/code&gt; 设备类型&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--medium&lt;/code&gt; 指定创建磁盘文件，即vdi文件&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;把创建的磁盘驱动器和虚拟机、磁盘连接起来。&lt;/p&gt;

&lt;h4 id=&#34;5-vboxmanage-list-hdds&#34;&gt;5. &lt;code&gt;VBoxManage list hdds&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;这时就可以查看注册过的磁盘了。&lt;/p&gt;

&lt;h3 id=&#34;操作&#34;&gt;操作&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;// 创建磁盘
$ VBoxManage createmedium disk --filename CentOS7.vdi --size 50000
0%...10%...20%...30%...40%...50%...60%...70%...80%...90%...100%
Medium created. UUID: 1cc3b870-7180-4eea-8263-f82a783d1478

// 创建虚拟机配置
$ cd ~/cluster
$ VBoxManage createvm --name CentOS7 --ostype RedHat_64 --register
Virtual machine &#39;CentOS7&#39; is created and registered.
UUID: 4afd6d6d-9cee-4efe-89a6-b752644711f0
Settings file: &#39;/home/hadoop/VirtualBox VMs/CentOS7/CentOS7.vbox&#39;

// 创建磁盘控制器
$ VBoxManage storagectl CentOS7 --add sata --controller IntelAHCI --name &amp;quot;SATA Controller&amp;quot;

// 绑定磁盘控制器
$ VBoxManage storageattach CentOS7 --storagectl &amp;quot;SATA Controller&amp;quot; --port 0 --device 0 --type hdd --medium CentOS7.vdi

// 创建光盘驱动器
$ VBoxManage storagectl CentOS7 --name &amp;quot;IDE Controller&amp;quot; --add ide

// 绑定光盘控制器
$ VBoxManage storageattach CentOS7 --storagectl &amp;quot;IDE Controller&amp;quot; --port 0 --device 0 --type dvddrive --medium ~/Downloads/CentOS-7-x86_64-Minimal-1511.iso

// 设置网络连接方式为桥接
$ VBoxManage modifyvm CentOS7 --nic1 bridged --bridgeadapter1 eno1 --vrde on --vrdeaddress 0.0.0.0 --vrdeport 5010 --memory 1024 --cpus 1

$ VBoxManage startvm CentOS7 --type=headless

&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注意：在我的操作系统下，执行createvm会在~/VirtualBox VMs/目录下生成&lt;code&gt;CentOS7.vbox&lt;/code&gt;文件，其实就是一个xml文件。而所谓的注册操作，就是在&lt;code&gt;~/.config/VirtualBox&lt;/code&gt;目录下生成一个VirtualBox.xml文件，里面有注册过的虚拟机的信息，类似下图所示：&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;http://7xn2pe.com1.z0.glb.clouddn.com/virtualbox.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;连接虚拟机&#34;&gt;连接虚拟机&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;这里我又要牢骚两句，网上有些人啊，觉得用命令行就是为了装13，根本不从问题的出发点去考虑。我为什么要用VirtualBox的命令行来安装虚拟机？图形界面不是更简单么？那是因为我的工作站没有图形界面啊！有些人上来就说连接你新创建的虚拟机要用&lt;code&gt;rdesktop -N localhost:3389&lt;/code&gt;，简直是bullshit，我要是用带图形环境的工作站，就根本就不用费那么大力气搞这个了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;言归正传，现在有了两种选择，Windows可以用自带的“远程桌面连接”应用进行连接，需要注意的是，以上面的命令为例，在填写主机时就需要写&amp;rdquo;192.168.159.3:5010&amp;rdquo;（其中IP是我用的工作站的IP，具体根据你的实际情况写），如果是Linux桌面就用&lt;code&gt;rdesktop -N 192.168.159.3:5010&lt;/code&gt;。至于Mac我好像也没有找到可以用的。&lt;/p&gt;

&lt;h2 id=&#34;复制虚拟机&#34;&gt;复制虚拟机&lt;/h2&gt;

&lt;p&gt;毕竟资源不是无限的，咱们创建虚拟机建集群也不能太浪费资源。我的理解是，如果要赋值虚拟机，最好用&amp;rdquo;link&amp;rdquo;形式，也就是说，复制虚拟机的快照，系统通过两个虚拟机的diff来区分二者。具体到VirtualBox的操作是这样的&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;为模板虚拟机创建一个snapshot&lt;/li&gt;
&lt;li&gt;复制snapshot并命名&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这两步就可以创建一个以前面的虚拟机为基础的虚拟机，而系统又不会占用两套存储空间，也步要求它有多高的性能，只要能说名问题即可。&lt;/p&gt;

&lt;p&gt;先查看一下当前有哪些虚拟机（注意：snapshot是另外一种实体，查看vm的命令是查看不到snapshot的）
&lt;img src=&#34;http://ww1.sinaimg.cn/large/65e4f1e6gw1f8v1dqo36oj20yw05etat.jpg&#34; alt=&#34;&#34; /&gt;
看一下指定的虚拟机是否已经有snapshot(这里只是不想给已经有snapshot的虚拟机再创建新的，其实是没有问题的)
&lt;img src=&#34;http://ww1.sinaimg.cn/large/65e4f1e6gw1f8v1ffm5tcj216002omy7.jpg&#34; alt=&#34;&#34; /&gt;
创建新的snapshot并查看是否创建成功
&lt;img src=&#34;http://ww1.sinaimg.cn/large/65e4f1e6gw1f8v1ig2xsuj21kw07en04.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;VBoxManage clonevm Debian-original --options link --name Debian-cluster-01 --register&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这样就克隆了一个新的虚拟机，并且注册到VirtualBox中，下面启动新的虚拟机的步骤就和前面直接创建新虚拟机一样了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ZooKeeper原理简介和简单使用</title>
      <link>http://lovelock.coding.me/bigdata/zookeeper-simple-practice/</link>
      <pubDate>Wed, 12 Oct 2016 23:36:09 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/bigdata/zookeeper-simple-practice/</guid>
      <description>

&lt;h2 id=&#34;什么是分布式应用&#34;&gt;什么是分布式应用&lt;/h2&gt;

&lt;p&gt;分布式应用运行在其上的一组系统被称为『集群』(cluster)，运行在集群中的每个机器被称为『节点』(node)。&lt;/p&gt;

&lt;h3 id=&#34;分布式应用的优点&#34;&gt;分布式应用的优点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;可靠性 单机或少量机器的故障不会导致整个系统不可用。&lt;/li&gt;
&lt;li&gt;可扩展性 不用停机只需要做很少的配置就可以根据需求通过增加机器来提升系统的性能。&lt;/li&gt;
&lt;li&gt;透明性 隐藏了系统的复杂性，对外值暴露单一的入口/应用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;分布式应用需要解决的难点&#34;&gt;分布式应用需要解决的难点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;竞争条件 两个或多个机器都尝试去执行同一个任务，而该任务在任意时刻都应该只被一台机器执行。比如，共享的资源在某一时刻应该只能被一台机器修改。&lt;/li&gt;
&lt;li&gt;死锁 两个或多个操作无限期的相互等待对方完成。&lt;/li&gt;
&lt;li&gt;不一致性 数据的部分错误。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;zookeeper简介&#34;&gt;ZooKeeper简介&lt;/h2&gt;

&lt;p&gt;ZooKeeper是一个&lt;strong&gt;分布式的&lt;/strong&gt;、用来管理大量主机的&lt;strong&gt;协调服务&lt;/strong&gt;。
在分布式环境中协调和管理一个服务是很复杂的工作，而ZooKeeper用简单的架构和API解决了这个问题，它用&lt;code&gt;fail-safe synchronization&lt;/code&gt;机制解决了竞争和死锁的问题, 用&lt;code&gt;atomicity(原子性)&lt;/code&gt;解决了数据的一致性问题。它屏蔽了分布式环境中的复杂性，让开发人员可以专注于核心应用功能的开发，而不用去关心分布式环境的太多细节。&lt;/p&gt;

&lt;h3 id=&#34;zookeeper提供的服务&#34;&gt;ZooKeeper提供的服务&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;名字服务 在一个集群内根据name找到主机，类似DNS服务&lt;/li&gt;
&lt;li&gt;配置管理 集中管理某个节点的最新配置&lt;/li&gt;
&lt;li&gt;集群管理 管理一个集群中某一节点的加入和离开&lt;/li&gt;
&lt;li&gt;主节点选举 协调一个集群选举中一个新的主节点&lt;/li&gt;
&lt;li&gt;加锁和同步服务 在数据被修改时给其加锁，这种机制可以帮助你在连接到其他如HBase的分布式服务时实现自动错误恢复&lt;/li&gt;
&lt;li&gt;存放高可用数据 可以保证在一个或多个节点出故障时保证数据的可用性&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;zookeeper的优点&#34;&gt;ZooKeeper的优点&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;简单的分布式协调过程&lt;/li&gt;
&lt;li&gt;同步 服务器进程间的互斥和协作&lt;/li&gt;
&lt;li&gt;有序的消息&lt;/li&gt;
&lt;li&gt;序列化 用指定的规则编码数据。保证你的应用一致的运行。这种方式可以用在MapReduce中来协调对来执行线程&lt;/li&gt;
&lt;li&gt;可靠性&lt;/li&gt;
&lt;li&gt;原子性 数据传输要么成功要么失败，不存在中间状态&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;zookeeper的架构&#34;&gt;ZooKeeper的架构&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://ww3.sinaimg.cn/large/006y8mN6jw1f7alv0grqej30fw04zdgg.jpg&#34; alt=&#34;ZooKeeper架构图&#34; /&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;概念&lt;/th&gt;
&lt;th&gt;职责和作用&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Client&lt;/td&gt;
&lt;td&gt;Client定时向Server发送消息通知Server该Client是alive众泰，同时Server会返回Response给Client，如果Client发送Message后没有收到Response，则会自动重定向到其他Server&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Server&lt;/td&gt;
&lt;td&gt;ZooKeeper集群中的一个节点，提供给Clients所有的服务&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Ensemble&lt;/td&gt;
&lt;td&gt;一个可以提供ZooKeeper服务的集群，如果要达到高可用性，至少需要三个节点&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Leader&lt;/td&gt;
&lt;td&gt;节点故障时执行自动恢复的节点，启动时选举出的&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Follower&lt;/td&gt;
&lt;td&gt;根据Leader的指示执行任务&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;层级的命名空间&#34;&gt;层级的命名空间&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8mN6jw1f7ayltmo57j30go0ce0t8.jpg&#34; alt=&#34;ZooKeeper的层级的命名空间&#34; /&gt;&lt;/p&gt;

&lt;p&gt;层级结构中的每个节点叫做znode, 每个znode维护一个&lt;code&gt;stat&lt;/code&gt;结构。这个&lt;code&gt;stat&lt;/code&gt;仅仅提供一个znode的元信息，其中包括版本号(Version number)、行为控制列表(Action Control List, ACL)、时间戳(Timestamp)、数据长度(Data Lenght)。&lt;/p&gt;

&lt;p&gt;下面来就实例看一下一个znode有哪些信息。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww4.sinaimg.cn/large/006y8mN6jw1f8r0ho7jkhj31320h6ad1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这样一看就很明显了吧。&lt;/p&gt;

&lt;h3 id=&#34;znode的类型&#34;&gt;znode的类型&lt;/h3&gt;

&lt;p&gt;znode分为三种类型：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;永久型 永久型节点当客户端断开连接之后仍然存在，默认情况下创建的节点都是永久型节点&lt;/li&gt;
&lt;li&gt;临时型 只有client保持alive时才存在的节点叫临时节点，当client从ZooKeeper集群断开时，节点被自动删除。所以临时节点不允许有子节点。如果一个临时节点被删除了，下一个合适的节点会填充它的位置。临时节点在Leader的选取中起到重要作用。&lt;/li&gt;
&lt;li&gt;顺序型 序列型节点可以是永久的也可以是临时的。当一个znode被创建为顺序型时，ZooKeeper在它原来的name后面加上十位的十进制数字。如果两个顺序型节点是并发创建的，ZooKeeper会保证两个节点的name不同。顺序型节点在锁和同步中起到重要作用。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;会话-sessions&#34;&gt;会话（Sessions）&lt;/h3&gt;

&lt;p&gt;一个会话中的请求是按照FIFO的顺序执行的。当一个client连接上一个server，一个会话就创建成功了并且会生成一个session id给client。&lt;br /&gt;
client会按一个时间间隔给server发送heartbeat来保证session的有效性。如果在一个session的生命周期内没有收到client的heartbeat，它就会认为这个client已经死掉了。&lt;br /&gt;
Session超时通常用ms表示。当一个session不管由于什么原因结束时，在session中创建的临时节点都会被删除掉。&lt;/p&gt;

&lt;h3 id=&#34;watches&#34;&gt;Watches&lt;/h3&gt;

&lt;p&gt;Watches是用来保证client能在znode上的数据发生变化时收到通知的一种简单机制。client在读取znode的数据时可以设置一个watches给一个特定的znode，当这个znode上的数据或者它的子节点发生变化时都会触发watches给client发送通知。&lt;br /&gt;
watches只会被触发一次，如果client还需要通知，那就需要另外一次的读取操作了。当一个client和server之间的会话过期时，它们之间的连接就断开了，同时watches也会被移除。&lt;/p&gt;

&lt;h3 id=&#34;工作流程&#34;&gt;工作流程&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;client读取数据 client发送一个&lt;strong&gt;读取请求&lt;/strong&gt;给ZooKeeper的一个节点，该节点根据请求中的path信息读取&lt;strong&gt;自己数据库中的数据&lt;/strong&gt;返回znode的信息给client。所以读取操作在ZooKeeper集群中是很快的。&lt;/li&gt;
&lt;li&gt;client写数据 如果收到请求的是Follower，它会先把请求转发给Leader，由Leader再发送写请求给Followers。只有&lt;strong&gt;大多数节点&lt;/strong&gt;正确响应时，写请求才会成功并且返回正确的返回码给client。否则写请求就会失败。这个严格的&lt;strong&gt;大多数节点&lt;/strong&gt;被称为&lt;strong&gt;Quorum（法定人数)&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;zookeeper中的节点数量&#34;&gt;ZooKeeper中的节点数量&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;当只有一个节点时，没有大多数&lt;/li&gt;
&lt;li&gt;只有两个节点，一个出故障时，也没有大多数&lt;/li&gt;
&lt;li&gt;当有三个节点，有一个出了故障，那2个就是大多数&lt;/li&gt;
&lt;li&gt;当有四个节点，2个出故障了，那也是没有大多数的&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以，ZooKeeper集群的中节点的数量不要太多，不然写的性能会有下降。同时节点的数量是3/5/7这种奇数，而不要是偶数。&lt;/p&gt;

&lt;h3 id=&#34;小结&#34;&gt;小结&lt;/h3&gt;

&lt;p&gt;看了上面的这么一大套理论，可能还是对ZooKeeper做的事情云里雾里，因为它做的事情太抽象了，好像实际它什么都没做，但又发现好像每个组件比如Kafka/Storm都要和ZooKeeper配合才能用。到底为什么呢？&lt;/p&gt;

&lt;p&gt;上面讲过，ZooKeeper其实是一个配置分发服务，也就是具体的应用如Kafka和Storm都是&lt;strong&gt;无状态&lt;/strong&gt;的，它本身为了保持&lt;strong&gt;容错&lt;/strong&gt;的特性，而容错很重要的一项特性就是应用Down掉之后重启还要能从之前结束时的地方继续。既然是无状态，其实是&lt;strong&gt;自己不存储状态&lt;/strong&gt;，那要实现的这个特性肯定是&lt;strong&gt;需要知道&lt;/strong&gt;应用Down掉之前的状态的，那么好，我就把状态存在ZooKeeper里。&lt;/p&gt;

&lt;p&gt;举个生动的例子，假设有一个很长的（水）槽，Kafka会每秒把一个玻璃球放在槽里，这样的结果就是最先放进去的玻璃球在最前面。而Storm就是&lt;strong&gt;计数工&lt;/strong&gt;，（注意&lt;strong&gt;不是搬运工&lt;/strong&gt;，因为它数了之后并不会真实的改变玻璃球的位置）极端一点这个游戏是在一个战场上，Storm随时会死掉，它怎么保证它的后来者来到之后马上知道它之前数到哪个位置了？自己当然是不可靠的，因为它死掉之后这个信息就丢失了，所以它&lt;strong&gt;每数一个&lt;/strong&gt;就朝ZooKeeper大喊一声（发送写请求）告诉它数到哪个位置了，而Storm又是个健忘症（无状态），刚数完的自己就忘了，更不用说后面来的人了，那么当它把位置信息告诉ZooKeeper之后其实它和自己的后来者就没有区别了，因为不管是谁，在计数之前都需要先去ZooKeeper读取一下前面数到的位置。这样的好处就是每个Storm随时都可以死掉，只要能有新的应用随时可以起来即可。那么存到了ZooKeeper就万无一失了么？考虑前面ZooKeeper处理写请求的特点，它是把相同的信息在集群中所有的机器上都写了一份，即使其中的一台或几台宕掉了，除非在这几台重启之前仅剩的一台也宕掉了，服务是不受影响的。如果全宕掉了，那真的没办法了，你把整个机房的电源拔掉，肯定会丢数据的。&lt;/p&gt;

&lt;p&gt;也可以理解为把状态和应用做的解耦。&lt;/p&gt;

&lt;p&gt;那么问题来了，为什么是在战场上？为什么好好的一个应用会无缘无故的Down掉呢？这就要从分布式应用的特点说起了。我们知道以前的所谓大型机、小型机都是很大很昂贵的特殊机器，是区别于普通的硬件的，包括CPU、内存、硬盘都是特制的，所以一台机器上百万甚至千万的都很常见，这种机器宕机的几率很小，但如果宕机的话影响也会相当严重。所以可以说这些机器的费用里其实也包含了保险费，因为机器宕机导致的损失，供应商是要负责任的。&lt;/p&gt;

&lt;p&gt;但现在不同了，现在是用大量普通（廉价）的机器组成集群来替代之前特殊的机器，既然是普通，那出错的几率当然就更高了，这也就是为什么诸如Storm这些系统在设计之初就特别注重&lt;strong&gt;容错&lt;/strong&gt;和&lt;strong&gt;无状态&lt;/strong&gt;了。&lt;/p&gt;

&lt;h2 id=&#34;zookeeper的使用&#34;&gt;ZooKeeper的使用&lt;/h2&gt;

&lt;h3 id=&#34;安装和配置&#34;&gt;安装和配置&lt;/h3&gt;

&lt;h4 id=&#34;安装&#34;&gt;安装&lt;/h4&gt;

&lt;p&gt;大数据的这套东西安装起来都是很简单，因为都是编译好的包，直接解压之后就可以以默认配置执行了。不过ZooKeeper有点特殊，因为它需要读取的配置文件是&lt;code&gt;conf/zoo.cfg&lt;/code&gt;，而默认的发行包里面是有个&lt;code&gt;conf/zoo_sample.cfg&lt;/code&gt;，不过好在只需要重命名一下即可。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost zookeeper-3.4.8]# cp conf/zoo_sample.cfg conf/zoo.cfg
[root@localhost zookeeper-3.4.8]# bin/zkServer.sh start
ZooKeeper JMX enabled by default
Using config: /root/packages/zookeeper-3.4.8/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED
[root@localhost zookeeper-3.4.8]# bin/zkServer.sh status
Mode: standalone
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注意这里的Mode，表示单点模式，区别于集群模式&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;配置&#34;&gt;配置&lt;/h4&gt;

&lt;p&gt;前面只讲了基础配置，这样的配置是没法跑集群环境的，下面先从默认配置出发，一步一步搭建一个集群环境。
先贴默认配置：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tickTime=2000
initLimit=10
syncLimit=5
dataDir=/tmp/zookeeper
clientPort=2181
#maxClientCnxns=60
#autopurge.snapRetainCount=3
#autopurge.purgeInterval=1
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;tickTime&lt;/code&gt;： ZooKeeper服务器或客户端与服务器之间维持心跳的时间间隔，也就是每个tickTime就会发送一条心跳&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dataDir&lt;/code&gt; 顾名思义就是ZooKeeper保存数据的目录&lt;/li&gt;
&lt;li&gt;&lt;code&gt;clientPort&lt;/code&gt; ZooKeeper对外提供服务的端口，即客户端通过该端口与ZooKeeper通信&lt;/li&gt;
&lt;li&gt;&lt;code&gt;initLimit&lt;/code&gt; ZooKeeper集群中的Leader忍受Follower多少个心跳间隔不发送心跳。从这里的默认配置推算，10个心跳间隔，每个心跳间隔2秒钟，也就是当Leader经过2*10秒还收不到Follower的信条时就认为这个Follower已经挂了&lt;/li&gt;
&lt;li&gt;&lt;code&gt;syncLimit&lt;/code&gt; Leader和Follower之间发送消息时，请求和应答的时间长度，默认5，及10秒&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;从上面的描述就可以看到，从第4条开始就是集群需要的配置了，然而仅仅在每个机器上这样配置并不能变成一个集群，还需要一个重要的配置，形如&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server.1=c1:2888:3888
server.2=c2:2888:3888
server.3=c3:2888:3888
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中的&lt;code&gt;server.n&lt;/code&gt;中的n表示节点的编号，那么问题来了，编号从哪里定义呢？我觉得这个设计其实不太好，当然我也想不到更好的方式来解决这个问题了。我们还需要在&lt;code&gt;dataDir&lt;/code&gt;中写入一个名为&lt;code&gt;myid&lt;/code&gt;的文件，其中填写当前机器的编号，操作如下&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd /path/to/dataDir
echo 1 &amp;gt; myid
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;c1的位置是节点机器的hostname或者IP地址，这样写当然还是不行的，因为它们并不知道c1是什么鬼，所以还需要修改&lt;code&gt;/etc/hosts&lt;/code&gt;，以我当前的本地集群为例，在该文件中添加&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;192.168.1.111 c1
192.168.1.110 c2
192.168.1.112 c3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2888是默认的Follower与Leader交换信息的端口，3888是用于选举Leader的端口，当Leader挂了，当然需要选举一个新的Leader来继续它未竟的事业了。&lt;/p&gt;

&lt;h3 id=&#34;启动集群&#34;&gt;启动集群&lt;/h3&gt;

&lt;p&gt;这时可以在三台机器上同时执行&lt;code&gt;bin/zkServer.sh start&lt;/code&gt;了。如果看到和前面一样的结果（注意把刚才已经启动的服务先关掉，执行&lt;code&gt;bin/zkServer.sh stop&lt;/code&gt;），恭喜你成功了一半了。
这时再执行&lt;code&gt;bin/zkServer.sh status&lt;/code&gt;你会惊奇的发现其中一台会显示&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost zookeeper-3.4.8]# bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /root/packages/zookeeper-3.4.8/bin/../conf/zoo.cfg
Mode: leader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外两台显示&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@localhost zookeeper-3.4.8]# bin/zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /root/packages/zookeeper-3.4.8/bin/../conf/zoo.cfg
Mode: follower
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;为了证明Leader节点是自动选举的，可以把Leader手动关掉，再分别看看另外两台的&lt;code&gt;status&lt;/code&gt;。是不是有一个变成了Leader了？&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;几天前写这篇文章时没有问题，但今天继续编写Kafka部分时，因为之前重启过这几台虚拟机，IP变了，重启所有虚拟机之后发现虽然已经在本地启动了ZooKeeper服务，但执行&lt;code&gt;zkServer.sh status&lt;/code&gt;时总是提示没有运行，而如果你再执行&lt;code&gt;start&lt;/code&gt;指令，它又会提示说进程已经在运行了。根据&lt;a href=&#34;http://stackoverflow.com/questions/29909191/zookeeper-it-is-probably-not-running&#34;&gt;StackOverFlow的答案&lt;/a&gt;，把&lt;code&gt;/root/packages/zookeeper-3.4.8/bin&lt;/code&gt;添加至&lt;code&gt;$PATH&lt;/code&gt;中即可。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ vim /etc/profile.d/zookeeper.sh
export ZK_HOME=/root/packages/zookeeper-3.4.8
export PATH=$PATH:$ZK_HOME/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后执行&lt;code&gt;source /etc/profile.d/zookeeper.sh&lt;/code&gt;即可直接在系统的任何地方执行&lt;code&gt;zkServer.sh start&lt;/code&gt;了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;通过动态的选举Leader节点，就解决了&lt;strong&gt;主从系统的单点故障问题&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&#34;简单使用&#34;&gt;简单使用&lt;/h3&gt;

&lt;p&gt;前面说了启动服务，细心的你可能还发现在bin目录里面还有一个zkCli.sh（请自动无视zkCli.cmd，因为那明显是给Windows用的，而我觉得也没有人会在Windows上跑这些服务），这就是ZooKeeper的命令行客户端。&lt;/p&gt;

&lt;p&gt;而我要说的只有两个最简单的命令。&lt;/p&gt;

&lt;h4 id=&#34;1-ls&#34;&gt;1. &lt;code&gt;ls&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;ls&lt;/code&gt;顾名思义就是查看指定path下的数据，前面我已经演示过了，要注意的一点是&lt;strong&gt;如果&lt;code&gt;ls&lt;/code&gt;后跟的是一个叶子节点，返回的结果是&lt;code&gt;[]&lt;/code&gt;&lt;/strong&gt;，这时你应该很敏锐的意识到应该换用&lt;code&gt;get&lt;/code&gt;来操作这个节点从而查看它的详细信息了。&lt;/p&gt;

&lt;h4 id=&#34;2-get&#34;&gt;2. &lt;code&gt;get&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;get&lt;/code&gt;当然就是用来查看指定节点的详细信息用的了。&lt;/p&gt;

&lt;p&gt;ZooKeeper提供的借口当然远远不止这两个，但起码到目前为止我还没有用到需要自行调用ZooKeeper接口的地方。因为实际上ZooKeeper是一个很底层的服务，它是用来为Storm和Kafka这类系统提供服务的，而我们通常不直接使用它们。在前两天一次查问题的过程中，发现数据一直在重复写入HDFS，查到了一个症状是ZooKeeper中的offset从一次重启发布之后一直没有更新过，导致系统一直反复读取该时间点之后的数据。这期间也就只用了这两个命令，至于对各种语言的binding，这里就不多说了，如果你要使用ZooKeeper给你的应用提供服务，那也不是看我的这篇文章就能搞明白的：）&lt;/p&gt;

&lt;p&gt;Happy Coding!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;本文大量参考了&lt;a href=&#34;https://www.tutorialspoint.com//zookeeper/index.htm&#34;&gt;https://www.tutorialspoint.com/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>一个真实Storm应用源码解析</title>
      <link>http://lovelock.coding.me/java/storm-demo-presentation/</link>
      <pubDate>Tue, 11 Oct 2016 16:41:18 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/storm-demo-presentation/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;这里是Storm分享的内容。我自己也是初学者，这里抛砖引玉，希望大家多多指教。为简单起见，本应用用的是Java实现，没有用到Storm的多语言支持和更高层面的Trident Topology。源码详见&lt;a href=&#34;https://github.com/lovelock/storm-demo&#34;&gt;storm-demo&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;理论&#34;&gt;理论&lt;/h2&gt;

&lt;h3 id=&#34;概述&#34;&gt;概述&lt;/h3&gt;

&lt;p&gt;Apache Storm是一个自由并且开源的&lt;strong&gt;分布式实时&lt;/strong&gt;计算系统.它使得像Hadoop做批处理一样做&lt;strong&gt;实时的&lt;/strong&gt;、&lt;strong&gt;无限量&lt;/strong&gt;的&lt;strong&gt;流数据&lt;/strong&gt;处理变得简单可靠.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://storm.apache.org/images/storm-flow.png&#34; alt=&#34;Apache Storm工作流程&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;概念解释&#34;&gt;概念解释&lt;/h3&gt;

&lt;h4 id=&#34;工作原理&#34;&gt;工作原理&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://www.tutorialspoint.com/apache_storm/images/zookeeper_framework.jpg&#34; alt=&#34;Apache Storm组件间关系&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Nimbus&lt;br /&gt;
 Nimbus是Storm集群的&lt;strong&gt;主节点master node&lt;/strong&gt;。Storm集群中除Nimbus节点之外的所有节点叫做&lt;strong&gt;工作节点worker nodes&lt;/strong&gt;。&lt;br /&gt;
 Nimbus负责三项工作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;向worker nodes分发数据&lt;/li&gt;
&lt;li&gt;向worker nodes分配tasks&lt;/li&gt;
&lt;li&gt;监控失败&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Supervisor&lt;br /&gt;
 接受Nimbus的指令的节点叫做Supervisors（监工），它有&lt;strong&gt;多个worker process&lt;/strong&gt;，并控制worker process完成Nimbus分配的tasks&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Worker Process&lt;br /&gt;
 Worker process执行指定Topology的tasks。&lt;strong&gt;worker process自己并不实际执行tasks，而是创建executors并由executors执行指定的task。&lt;/strong&gt;一个worker process可以由多个executor。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Executor&lt;br /&gt;
 Executor是由worker process创建的线程。一个executor执行一个或多个tasks，但只为&lt;strong&gt;一个指定的Spout或者Bolt工作&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Task&lt;br /&gt;
 Task是实际的数据处理工作，所以它可能是一个Spout或者Bolt。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;配套服务&#34;&gt;配套服务&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;ZooKeeper&lt;br /&gt;
&lt;a href=&#34;http://zookeeper.apache.org/&#34;&gt;ZooKeeper&lt;/a&gt;是一个分布式的配置分发服务。Storm和Kafka都是无状态的，它们的工作需要外部服务为其维持状态，如Storm从Kafka中取数据时需要的partition编号和offset偏移量等诸如此类的信息。ZooKeeper会综合分析Spout和Bolt发送来的ack或者fail请求来决定是否更新offset。如下图所示&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww3.sinaimg.cn/large/65e4f1e6jw1f8wd8tm94ij21kw097q5h.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Kafka&lt;br /&gt;
&lt;a href=&#34;http://kafka.apache.org/&#34;&gt;Kafka&lt;/a&gt;是一个分布式的消息系统。支持&lt;strong&gt;点对点&lt;/strong&gt;和&lt;strong&gt;发布-订阅&lt;/strong&gt;两种消息模式。在和Storm配合中，充当&lt;strong&gt;数据来源&lt;/strong&gt;的角色。用&lt;a href=&#34;https://github.com/apache/storm/tree/master/external/storm-kafka&#34;&gt;KafkaSpout&lt;/a&gt;和Storm进行组合。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;本文只关注Storm，有关ZooKeeper和Kafka的介绍，可以访问&lt;a href=&#34;http://apache.org/&#34;&gt;官网&lt;/a&gt;、&lt;a href=&#34;http://www.tutorialspoint.com/&#34;&gt;TutorialsPoint&lt;/a&gt;或本博客的其他相关文章。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;拓扑作业&#34;&gt;拓扑作业&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Tuple&lt;br /&gt;
 Tuple是Topology中数据流的传输格式。它是&lt;strong&gt;不可变的键值对组&lt;/strong&gt;。既然是键值对，就需要设置键和值，典型的设置方式如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; // 设置键
 outputFieldsDeclarer.declare(new Fields(&amp;quot;timestamp&amp;quot;, &amp;quot;fieldvalues&amp;quot;));
 // 设置值
 collector.emit(tuple, new Values(timestamp, stringBuilder.toString()));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样就会得到一个形如&lt;code&gt;(&amp;quot;timestamp&amp;quot;: timestamp, &amp;quot;fieldvalues&amp;quot;: xxxx&amp;quot;)&lt;/code&gt;这样的Tuple。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Spout&lt;br /&gt;
 Spout是Topology的数据来源，输出的数据以Tuple的形式传入下一个Bolt。具体到本例中，KafkaSpout会把它接收到的数据以类似&lt;code&gt;(0: message)&lt;/code&gt;这样的形式发射(emit)出来。所以，在KafkaSpout下游的Bolt需要这样获取整条数据(其实这里是可配置的)：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt; String message = tuple.getString(0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对KafkaSpout而言，它也实现了多个方法，但我们这里只需要了解两个&lt;code&gt;ack&lt;/code&gt;和&lt;code&gt;fail&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ww3.sinaimg.cn/large/65e4f1e6jw1f8wdqv4tuqj218y0ji41l.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这两个是回调方法，分别在acker向其发送ack或fail请求时被触发，一般而言，ack方法由于通知Kafka发送下一条数据，fail方法用于通知Kafka重发上一条数据。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Storm中有个特殊的task名叫acker，它们负责跟踪Spout发出的每一个Tuple的Tuple树（因为一个Tuple通过Spout发出了，经过每一个Bolt处理后，会生成一个新的Tuple发送出去）。当acker（框架自启动的task）发现一个Tuple树已经处理完成了，它会发送一个消息给产生这个Tuple的那个task。&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bolt&lt;br /&gt;
 Bolt是真正写处理逻辑的地方，比如在本例中，我们要做以下几件事：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;把message中的每个字段提取出来，&lt;/li&gt;
&lt;li&gt;从message的domain字段中过滤出以&lt;code&gt;.api.ksyun.com&lt;/code&gt;结尾的，其他的舍弃&lt;/li&gt;
&lt;li&gt;把domain字段的值以&lt;code&gt;.&lt;/code&gt;分割，取出index为0的部分，也就是第一段作为service字段&lt;/li&gt;
&lt;li&gt;把service最终输出Tuple的一个field写入输出结果&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一般情况下，要实现一个Bolt有几种方式&lt;/p&gt;

&lt;p&gt;​&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;实现&lt;code&gt;IRichBolt&lt;/code&gt;接口&lt;br /&gt;
  因为这个比较低级，要实现的方法有很多，而其中多数的方法不需要做特殊处理，所以一般会用第二种方式&lt;/li&gt;

&lt;li&gt;&lt;p&gt;集成&lt;code&gt;BaseRichBolt&lt;/code&gt;类&lt;br /&gt;
  这个基类实现了&lt;code&gt;IRichBolt&lt;/code&gt;中定义的几个不常用的方法，让我们只需要关注重点的几个方法即可。在这种方式中，我们需要自己实现三个方法：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;public void prepare(Map map, TopologyContext topologyContext, OutputCollector outputCollector)&lt;/code&gt;&lt;br /&gt;
  这个方法&lt;strong&gt;类似构造函数&lt;/strong&gt;，用来做一些准备工作，通常用于&lt;strong&gt;把上游传来的collector赋值给成员变量&lt;/strong&gt;。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;public void execute(Tuple tuple)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这是最核心的方法。它负责：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;从上游传来的Tuple中读取感兴趣的字段&lt;/li&gt;
&lt;li&gt;把这些字段做一些处理后产生一组新的字段&lt;/li&gt;
&lt;li&gt;把这些值通过&lt;code&gt;OutputCollector::emit(new Values())&lt;/code&gt;方法发射出去&lt;/li&gt;
&lt;li&gt;向上游发送&lt;code&gt;OutputCollector::ack(Tuple tuple)&lt;/code&gt;或&lt;code&gt;OutputCollector::fail(Tuple tuple)&lt;/code&gt;，以告知上游本次Tuple处理是否成功。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;public void declareOutputFields(OutputFieldsDeclarer outputFieldsDeclarer)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;前面已经说过，Tuple是数据交流的格式，这个方法就是用来定义发送到下游的Tuple的字段名的。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Topology&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://storm.apache.org/releases/0.10.0/images/topology.png&#34; alt=&#34;一个典型的Topology&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上面这张图中有4个Topology，说明了几个问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一个Spout就是一个Topology的入口，从Spout分出几条线就有几个Topology&lt;/li&gt;
&lt;li&gt;一个Topology由一个Spout和若干个Bolt组成&lt;/li&gt;
&lt;li&gt;Topology之间可以共享Spout或者Bolt&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;创建一个Topology的典型过程：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    TopologyBuilder topologyBuilder = new TopologyBuilder();
    topologyBuilder.setSpout(KAFKA_SPOUT_ID, kafkaSpout, 10);
    topologyBuilder.setBolt(CROP_BOLT_ID, new CropBolt(), 10).shuffleGrouping(KAFKA_SPOUT_ID);
    topologyBuilder.setBolt(SPLIT_FIELDS_BOLT_ID, new SplitFieldsBolt(), 10).shuffleGrouping(CROP_BOLT_ID);
    topologyBuilder.setBolt(STORM_HDFS_BOLT_ID, hdfsBolt, 10).fieldsGrouping(SPLIT_FIELDS_BOLT_ID, new Fields(&amp;quot;timestamp&amp;quot;, &amp;quot;fieldvalues&amp;quot;));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上面的代码可以看到，&lt;code&gt;TopologyBuilder&lt;/code&gt;类通过&lt;code&gt;setSpout()&lt;/code&gt;和&lt;code&gt;setBolt()&lt;/code&gt;两个方法生动的反映了上图的工作流程。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;源码分析&#34;&gt;源码分析&lt;/h2&gt;

&lt;h3 id=&#34;cropbolt-java&#34;&gt;&lt;code&gt;CropBolt.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;主要关注&lt;code&gt;execute&lt;/code&gt;方法，它首先从上游发射来的Tuple中取出第一个字段，也就是整条消息作为一个字符串。根据对字符串的分析，我们知道该字符串是以&lt;code&gt;\t\t&lt;/code&gt;作为字段间分隔符，以&lt;code&gt;:&lt;/code&gt;作为键值分隔符的字符串，所以可以写一个方法来用这种规则解析出消息中的所有字段，并把它放在一个HashMap里。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    private HashMap makeMapOfMessage(String message) {
    String[] fields = message.split(ServerConfig.getFieldSeparator());
    HashMap&amp;lt;String, String&amp;gt; map = new HashMap&amp;lt;&amp;gt;();

    try {
        for (String field : fields) {
            String[] pair = field.split(ServerConfig.getPairSeparator(), 2);
            map.put(pair[0], pair[1]);
        }
    } catch (ArrayIndexOutOfBoundsException e) {
        LOG.warn(&amp;quot;makeMapOfMessage failed {}&amp;quot;, message);
        e.printStackTrace();
    }

    return map;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中&lt;code&gt;ServerConfig&lt;/code&gt;是一个工具类，它提供了简单的API，把处理逻辑和配置信息分离。在本例中我用的分隔符和实际项目并不一样，这个差别只需要在相应的properties配置文件中做修改即可。还需要注意异常处理，这个方法的返回值有可能是null，在调用该方法的地方需要做相应的判断。&lt;/p&gt;

&lt;p&gt;在&lt;code&gt;execute&lt;/code&gt;方法中，从上述方法的返回值取出关心的字段，并按需求解析出需要的&lt;code&gt;service&lt;/code&gt;字段，并通过&lt;code&gt;collector.emit&lt;/code&gt;发送给下游的Bolt。&lt;/p&gt;

&lt;p&gt;这个方法中有三点需要注意：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;没有在&lt;code&gt;try&lt;/code&gt;子句中调用&lt;code&gt;ack&lt;/code&gt;方法&lt;/li&gt;
&lt;li&gt;没有在&lt;code&gt;catch&lt;/code&gt;子句中调用&lt;code&gt;fail&lt;/code&gt;方法&lt;/li&gt;
&lt;li&gt;在&lt;code&gt;finally&lt;/code&gt;子句中调用了&lt;code&gt;ack&lt;/code&gt;方法&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因为我们catch住的这种情况，是只有在输入的数据不满足我们约定要求的情况下才会发生的，比如某些必要的字段不存在等，而这种情况在当前的Topology中是不需要处理的，并且也不需要重试，因此，不需要调用&lt;code&gt;fail&lt;/code&gt;。同时，不管数据是否符合要求，我们都是需要通知Spout&lt;strong&gt;这里的处理已经完成&lt;/strong&gt;这个信息的，所以在&lt;code&gt;finally&lt;/code&gt;中调用&lt;code&gt;ack&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;splitfieldsbolt-java&#34;&gt;&lt;code&gt;SplitFieldsBolt.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;这步的功能很简单，就是把前面传过来的所有字段用一个特定的分隔符连接起来，变成一行数据。只有一个特殊，也就是&lt;code&gt;service&lt;/code&gt;字段，它不是直接取出来的，而是前面的Bolt通过一些处理得到的，所以这是&lt;code&gt;stringBuilder&lt;/code&gt;需要处理的一种特殊情况。&lt;/p&gt;

&lt;p&gt;最后把『时间戳』和『各个字段的值』发射给下游的&lt;code&gt;HdfsBolt&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;hdfsbolt&#34;&gt;&lt;code&gt;HdfsBolt&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;HdfsBolt&lt;/code&gt;是Storm到HDFS的一个中转层，配置一些规则，把Storm输出的数据写入HDFS。其中比较重要的配置有：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;DelimitedRecordFormat&lt;/code&gt; 要写入的字段 在本例中，『时间戳』只是用来划分目录的，所以不需要写入HDFS中&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CountSyncPolicy&lt;/code&gt; 指定当内存中超过多少条数据时cache到磁盘中&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FileSizeRotationPolicy&lt;/code&gt; 指定cache的文件超过多大时将文件写入文件系统，如果该值设置的较大，而数据流量又不太大的情况下，文件通常不会达到设置的值，因为当等待写入的文件未达到限制大小而先达到超时时间时，也会创建一个新的文件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DefaultFileNameFormat&lt;/code&gt; 指定文件写入HDFS中的根目录和文件后缀&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Partitioner&lt;/code&gt; 指定分块规则，在本例中，我们根据日志中&lt;code&gt;time_local&lt;/code&gt;字段划分相应的消息应该写入的HDFS目录，比如&lt;code&gt;31/Aug/2016:13:08:12 +0800&lt;/code&gt;，相应的记录就会写入&lt;code&gt;root/20160831/13&lt;/code&gt;目录中。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;FsURL&lt;/code&gt; 当然需要指定正确的&lt;code&gt;HDFS&lt;/code&gt;服务。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;其实我们的KMR对应的Storm 0.10.0是不支持HDFS 的partition的，这里我是把Storm最新版的2.0.0-SNAPSHOT中相应的代码移植过来用的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;logstatisticstopology-java&#34;&gt;&lt;code&gt;LogStatisticsTopology.java&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;前面讲过，这是拓扑作业的入口，这里指定了一条消息要通过的路径。需要注意的有以下几点：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;setSpout&lt;/code&gt;和&lt;code&gt;setBolt&lt;/code&gt;方法中的parallelism_hint(并行度建议)，前面说了，Spout和Bolt在Storm中是以executor的形式存在的，而这个值就是指定executor的数量。但又没有那么绝对，比如在KafkaSpout中，如果指定的Topic在Kafka中有10个partition，但这里的KafkaSpout指定了15个并行度，实际还是只有10个executor有意义，因为剩余的5个在前面10个都正常工作的情况下是分配不到任何数据的，由于ZooKeeper做了中间人，它是知道每个Topic有多少个partition的，所以这里设置多于partition数量的并行度也是不起作用的。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;grouping类型 Storm目前支持4种分组形式。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;随机分组 等量tuples随机分发给执行bolt的所有workers&lt;/li&gt;
&lt;li&gt;字段分组 把指定字段值相同的分配给同一个task,在wordCount应用中比较重要&lt;/li&gt;
&lt;li&gt;广播分组 给每个executor发送一个这个tuple的副本&lt;/li&gt;
&lt;li&gt;全局分组 把所有数据分发给bolt的executor中id最小的&lt;strong&gt;一个&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;无分组   目前基本等同于随机分组，会把tuple交给和它上游同一个线程内的下游bolt，以减少数据传递的开销&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;根据我们的需求，其实是不需要太关心分组的事情。&lt;/p&gt;

&lt;p&gt;关于优化，有几个方面可以考虑：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;考虑到后面需要用Hive分析数据，如果产生很多小的文件，就会产生过多的Map过程，影响性能，可以考虑同一小时的文件交给同一个executor来写，因为每个executor会打开一个hdfs文件，但这样可能会导致并发数过少&lt;/li&gt;
&lt;li&gt;既然这样，可以减少executor的数量，比如现在是10个，可以改成5个，在不触发FileSizeRotationPolicy的情况下，把生成的文件数量减少了一半，也就把Hive查询时Map过程的数量减少了一半&lt;/li&gt;
&lt;li&gt;分析需求，如果没有按照小时分组的需求，可以直接删除这个级别，直接用天作为区分，这样，在不触发FileSizeRotationPolicy的情况下产生的文件数量会变成1/24,相应的Hive查询中Map的过程也会变成1/24.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;本文主要介绍了Storm的工作流程，以及其与Kafka和HDFS的配合来进行日志分析的工作流程，并简单介绍了一些需要注意的点。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>在本地单机部署Hadoop/Storm运行环境</title>
      <link>http://lovelock.coding.me/java/deploy-pseudo-distributed-mode-hadoop/</link>
      <pubDate>Mon, 10 Oct 2016 17:53:14 +0800</pubDate>
      
      <guid>http://lovelock.coding.me/java/deploy-pseudo-distributed-mode-hadoop/</guid>
      <description>

&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;

&lt;p&gt;由于要在小组内做一个关于Storm的分享，涉及到我负责开发的大数据项目，本着开放的原则，把我做的准备工作记录下来，提前发给可能参会的同事。&lt;br /&gt;
要演示的项目目前为止用到了Apache的多个项目，包括Kafka, Storm, Hadoop(HDFS, Hive), ZooKeeper等，项目刚刚起步，很多基础设施还不完善，比如现在是在本地开发完成之后直接部署到线上环境的，这次演示可不能直接在线上环境做了，故而在本地的台式机上部署了一下&lt;strong&gt;伪集群&lt;/strong&gt;，用来作为演示和以后开发测试用的环境。&lt;/p&gt;

&lt;h2 id=&#34;准备工作&#34;&gt;准备工作&lt;/h2&gt;

&lt;p&gt;说明：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;以下工作全部基于Ubuntu 16.04。用其他的发行版或版本理论上应该都是可行的，可能有些命令需要微调。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;所有需要执行的命令前面都有一个&lt;code&gt;$&lt;/code&gt;，表示的是Bash的命令提示符。&lt;/li&gt;
&lt;li&gt;下载安装包时我使用了速度相对较快的国内镜像，如果你对此有任何异议，可以自行去中心镜像站点下载。&lt;/li&gt;

&lt;li&gt;&lt;p&gt;默认情况下文中提到的所有如StormUI等控制后台访问的路径都是localhost，如果你需要从Linux主机外部访问，需要iptables放行相应的端口。在本文中，用的Web端口有三个，具体如下表：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;服务描述&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;端口号&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Storm UI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8080&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hadoop UI&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;50070&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Hadoop Applications&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8088&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;以Ubuntu为例，需要执行以下命令&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo ufw allow 8080/tcp
$ sudo ufw allow 50070/tcp
$ sudo ufw allow 8088/tcp
$ sudo ufw reload
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CentOS/RHEL 7.0以下可能需要直接操作iptables，7.0以上可以使用&lt;code&gt;firewall-cmd&lt;/code&gt;进行类似的操作。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-创建独立的用户并赋予合适的权限&#34;&gt;1. 创建独立的用户并赋予合适的权限&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ sudo useradd hadoop
$ sudo passwd hadoop
$ sudo chsh hadoop
$ sudo mkdir /home/hadoop
$ sudo chown -R hadoop:hadoop /opt/apache
$ sudo chown -R hadoop:hadoop /home/hadoop
$ su - hadoop
$ ssh-keygen
$ cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys
$ chmod 0600 ~/.ssh/authorized_keys
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;FAQ：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;为什么需要chsh并且手动为用户创建家目录？&lt;br /&gt;
不知道为什么在 Ubuntu 环境中执行&lt;code&gt;useradd&lt;/code&gt;命令之后并不会给新建的用户创建家目录和设置shell，可能是为了安全吧，要稍微麻烦一些。&lt;/li&gt;
&lt;li&gt;为什么不给新用户赋予root权限？&lt;br /&gt;
这里是测试环境倒还好，如果你需要搭建生产环境，记住千万不要给hadoop用户赋予root权限，它需要哪些目录的权限就单独赋予即可，它需要运行的端口都是1024以上的，都不需要root权限。如果需要，执行&lt;code&gt;sudo gpasswd -a hadoop sudo&lt;/code&gt;即可。&lt;/li&gt;
&lt;li&gt;为什么要做一个密钥认证？&lt;br /&gt;
这是因为在后续的步骤中会有&lt;strong&gt;从本地用户登录本地用户&lt;/strong&gt;的需求，也就是执行了&lt;code&gt;ssh hadoop@localhost&lt;/code&gt;这个命令，如果不做密钥信任，会需要多次输入密码。&lt;/li&gt;
&lt;li&gt;为什么会有一个&lt;code&gt;/opt/apache&lt;/code&gt;目录？&lt;br /&gt;
往下看。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;1-下载所需安装包&#34;&gt;1. 下载所需安装包&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;下载Java&lt;br /&gt;
到&lt;a href=&#34;http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html&#34;&gt;Java官网&lt;/a&gt;下载适用于Linux的Java安装包（这里下载了jdk-8u101-linux-x64.tar.gz）。&lt;/li&gt;
&lt;li&gt;下载maven&lt;br /&gt;
点击&lt;a href=&#34;http://mirrors.aliyun.com/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.zip&#34;&gt;阿里云镜像站&lt;/a&gt;下载最新版Maven。&lt;/li&gt;
&lt;li&gt;下载Apache的Storm Hadoop Kafka ZooKeeper&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/storm/apache-storm-0.10.2/apache-storm-0.10.2.tar.gz&#34;&gt;点击下载Storm-0.10.2&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/hadoop/core/hadoop-2.6.4/hadoop-2.6.4.tar.gz&#34;&gt;点击下载Hadoop-2.6.4&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/kafka/0.8.2.2/kafka_2.10-0.8.2.2.tgz&#34;&gt;点击下载Kafka_2.10-0.8.2.2&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz&#34;&gt;点击下载ZooKeeper-3.4.6&lt;/a&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;2-创建所需目录&#34;&gt;2. 创建所需目录&lt;/h3&gt;

&lt;p&gt;把所有和此项目相关的文件都放在统一的位置。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ sudo mkdir -p /opt/apache/{jdk, storm,hadoop,kafka,zookeeper}&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-解压所有安装包-将相应的安装包放在对应的位置&#34;&gt;3. 解压所有安装包，将相应的安装包放在对应的位置&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ sudo mv jdk1.8.0_101/* /opt/jdk/.
$ sudo mv apache-storm-0.10.0/* /opt/apache/storm/.
$ sudo mv hadoop-2.6.4/* /opt/apache/hadoop/.
$ sudo mv kafka_2.10-0.8.2.2/* /opt/apache/kafka/.
$ sudo mv zookeeper-3.4.6/* /opt/apache/zookeeper
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-配置环境变量&#34;&gt;4. 配置环境变量&lt;/h3&gt;

&lt;p&gt;在~/.bashrc中添加下面的片段&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export JAVA_HOME=/opt/jdk
export APACHE_HOME=/opt/apache
export STORM_HOME=$APACHE_HOME/storm
export ZK_HOME=$APACHE_HOME/zookeeper
export KAFKA_HOME=$APACHE_HOME/kafka

export HADOOP_HOME=$APACHE_HOME/hadoop
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_INSTALL=$HADOOP_HOME

export PATH=$PATH:$JAVA_HOME/bin
export PATH=$PATH:$STORM_HOME/bin
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export PATH=$PATH:$ZK_HOME/bin
export PATH=$PATH:$KAFKA_HOME/bin
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;之后执行&lt;code&gt;$ source ~/.bashrc&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;5-安装java&#34;&gt;5. 安装Java&lt;/h4&gt;

&lt;p&gt;Apache的这些东西都是直接放在对的地方就可以运行的，但Java需要稍微的配置一下，因为可能你的机器上已经装了OpenJDK。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ sudo update-alternatives --install /usr/local/bin/java java /opt/jdk/bin/java 10000&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这时再执行&lt;code&gt;$ java -version&lt;/code&gt;验证一下是否使用的时最新安装的JDK。&lt;/p&gt;

&lt;h2 id=&#34;2-启动服务&#34;&gt;2. 启动服务&lt;/h2&gt;

&lt;h3 id=&#34;1-启动zookeeper&#34;&gt;1. 启动ZooKeeper&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ cp $ZK_HOME/conf/zoo_sample.cfg $ZK_HOME/conf/zoo.cfg
$ zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-启动storm&#34;&gt;2. 启动Storm&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ storm nimbus
$ storm supervisor
$ storm ui
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在可以访问&lt;a href=&#34;http://localhost:8080&#34;&gt;Storm UI&lt;/a&gt;了。&lt;/p&gt;

&lt;h3 id=&#34;3-启动kafka-broker&#34;&gt;3. 启动Kafka Broker&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;$ cd $KAFKA_HOME
$ bin/kafka-server-start.sh -daemon config/server.properties
$ bin/kafka-topics.sh --list --zookeeper localhost:2181
$ bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 10 --topic storm-demo-topic
Created topic &amp;quot;storm-demo-topic&amp;quot;.
$ bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic storm-demo-topic
Topic:storm-demo-topic  PartitionCount:10       ReplicationFactor:1     Configs:
        Topic: storm-demo-topic Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 2    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 3    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 4    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 5    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 6    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 7    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 8    Leader: 0       Replicas: 0     Isr: 0
        Topic: storm-demo-topic Partition: 9    Leader: 0       Replicas: 0     Isr: 0
$ kafka-console-producer.sh --broker-list localhost:9092 --topic storm-demo-topic
$ kafka-console-consumer.sh --zookeeper localhost:2181 --topic storm-demo-topic --from-beginning
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;注意前面有些命令仅仅是为了测试kafka broker运行的情况。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;4-启动hadoop-hdfs&#34;&gt;4. 启动Hadoop(HDFS)&lt;/h3&gt;

&lt;h4 id=&#34;1-修改hadoop的配置文件&#34;&gt;1. 修改Hadoop的配置文件&lt;/h4&gt;

&lt;p&gt;在&lt;code&gt;$HADOOP_HOME/etc/hadoop&lt;/code&gt;目录下有5个文件需要修改:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;core-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;fs.default.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;hdfs://localhost:9000&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;hdfs-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.name.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/hadoop/hadoopinfra/hdfs/namenode&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;dfs.data.dir&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;file:///home/hadoop/hadoopinfra/hdfs/datanode&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;

&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;yarn-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;mapred-site.xml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;configuration&amp;gt;
    &amp;lt;property&amp;gt;
        &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
        &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
    &amp;lt;/property&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;hadoop-env.sh&lt;/code&gt;
把hadoop-env.sh中的${JAVA_HOME}替换成路径,这里是&lt;code&gt;/opt/jdk&lt;/code&gt;，因为貌似会找不到正确的&lt;code&gt;JAVA_HOME&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;2-验证是否安装成功&#34;&gt;2. 验证是否安装成功&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ hadoop namenode -format
$ start-dfs.sh
$ start-yarn.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行上面三行语句，观察有没有明显的报错信息。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://localhost:50070&#34;&gt;检查HadoopUI&lt;/a&gt;运行是否正常。&lt;br /&gt;
&lt;a href=&#34;http://localhost:8088&#34;&gt;检查Hadoop Applications&lt;/a&gt;(我自己取的名字)运行是否正常。&lt;/p&gt;

&lt;p&gt;至此已经搭建了一个可以运行的hadoop环境，可以移步这里查看关于Storm入门分享详情。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
